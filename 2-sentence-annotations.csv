,paper_id,sentence,forecite_concepts,is_relational,relation,formatted_statement,concept_a,concept_b,is_conceptb_forecite
0,12205351.0,"partially labeled lda (plda) extends labeled lda to incorporate per-label latent topics (ramage et al., 2011) . the df-lda model (andrzejewski et al., 2009 ) employs must-link and cannot-link constraints as dirichlet forest priors for lda learning, but it suffers the scalability issue.","{'plda', 'dirichlet forest prior'}",1.0,is-a,plda is a partially labeled lda that extends labeled lda to incorporate per-label latent topics.,plda,partially labeled lda,no
1,12205351.0,,,,compare,"plda is like the df-lda model, except plda extends labeled lda to incorporate per-label latent topics and df-lda employs must-link and cannot-link constraints as dirichlet forest priors for lda learning, but it suffers the scalability issue.",plda,the df-lda model,no
2,12205351.0,,,,used-for,dirichlet forest priors are used for lda learning that suffer the scalability issue when employed as must-link and cannot-link constraints in the df-lda model.,dirichlet forest prior,lda learning,no
3,12205351.0,"the df-lda model (andrzejewski et al., 2009 ) employs must-link and cannot-link constraints as dirichlet forest priors for lda learning, but it suffers the scalability issue. most recently, the aspect extraction model for sentiment analysis (mukherjee and liu, 2012) assumes that a seed set is given which consists of words together with their respective aspect category.","{'seed set', 'dirichlet forest prior'}",1.0,used-for,dirichlet forest priors are used for lda learning that suffer the scalability issue when employed as must-link and cannot-link constraints in the df-lda model.,dirichlet forest prior,lda learning,no
4,12205351.0,"most recently, the aspect extraction model for sentiment analysis (mukherjee and liu, 2012) assumes that a seed set is given which consists of words together with their respective aspect category. then depending on whether a word is a seed or non-seed word, a different route of multinomial distribution will be taken to emit the word.","{'seed set', 'multinomial distribution'}",1.0,is-a,a seed set is a set of words together with their respective aspect category that is assumed to be given in the aspect extraction model for sentiment analysis.,seed set,a set of words together with their respective aspect category,no
5,12205351.0,,,,part-of,"a seed set is a part of the aspect extraction model for sentiment analysis that is assumed to be given and depending on whether a word is a seed or non-seed word, a different route of multinomial distribution is taken to emit the word.",seed set,the aspect extraction model for sentiment analysis,no
6,12205351.0,,,,used-for,"multinomial distribution is used for the aspect extraction model for sentiment analysis that emits a word from a seed set, depending on whether a word is a seed or non-seed word.",multinomial distribution,the aspect extraction model for sentiment analysis,no
7,4905841.0,"changing user pseudonyms while the users pass through pre-defined spots, called mix zones [22] , makes it difficult to track the users along their trajectories. however, users must remain silent inside the mix zones, which means that they cannot use the lbs.",{'mix zone'},1.0,is-a,"mix zones are pre-defined spots that users pass through and must remain silent inside, which means that they cannot use the lbs.",mix zone,pre-defined spots,no
8,4905841.0,"however, users must remain silent inside the mix zones, which means that they cannot use the lbs. to mitigate this problem, the size of the mix zones is kept small, which in turn limits the unlinkability of users' queries.",{'mix zone'},0.0,,,,,
9,4905841.0,"to mitigate this problem, the size of the mix zones is kept small, which in turn limits the unlinkability of users' queries. even if the mix zones are optimally placed, the adversary's success is relatively high [23] .",{'mix zone'},0.0,,,,,
10,4905841.0,"in [24] , for example, the need to construct the cloaking regions and to receive the responses from the server through other users can considerably degrade the service. many obfuscation-based techniques are based on k-anonymity, which has been shown inadequate to protect privacy [8] , [25] .",{'cloaking region'},1.0,used-for,"k-anonymity is used for many obfuscation-based techniques, which has been shown inadequate to protect privacy.",k - anonymity,many obfuscation-based techniques,not
11,27044448.0,"epidemic routing introduced in [2] is an improvement of flooding based technique. in original form [2] , instead of passing information to all known neighbours, it uses information index (summary vector) exchange process to avoid sending the same information to same nodes.",{'epidemic routing'},1.0,is-a,"epidemic routing is an improvement of flooding based technique that in original form, instead of passing information to all known neighbours, it uses information index (summary vector) exchange process to avoid sending the same information to same nodes.",epidemic routing,improvement of flooding based technique,no
12,27044448.0,,,,is-a,summary vector is an information index exchange process that is used in the original form of flooding based technique to avoid sending the same information to same nodes.,summary vector,information index exchange process,no
13,53460604.0,"a well-known model aiming to explain and predict individual adoption and use of information technologies (it) is technology acceptance model (tam), developed and validated by davis [11] , and davis, bagozzi and warshaw [12] . tam has three key variables: perceived usefulness (pu), perceived ease of use (peou), and behavioural intention (bi) to use.",{'technology acceptance model'},1.0,is-a,"technology acceptance model is a well-known model aiming to explain and predict individual adoption and use of information technologies (it) that has three key variables: perceived usefulness (pu), perceived ease of use (peou), and behavioural intention (bi) to use.",technology acceptance model,a well-known model aiming to explain and predict individual adoption and use of information technologies (it),no
14,53460604.0,,,,part-of,perceive usefulness is a part of the technology acceptance model that is a key variable.,perceive usefulness,technology acceptance model,yes
15,53460604.0,,,,part-of,perceived ease of use is a part of the technology acceptance model that is a key variable.,perceive ease,technology acceptance model,yes
16,53460604.0,,,,is-a,perceive usefulness is a key variable of the technology acceptance model.,perceive usefulness,key variable of the technology acceptance model,no
17,53460604.0,,,,is-a,perceived ease of use is a key variable of the technology acceptance model.,perceive ease,key variable of the technology acceptance model,no
18,53460604.0,,,,compare,percieve usefulness is like perceived ease of use in that they are both key variables of the technology acceptance model.,perceive usefulness,perceive ease,yes
19,17360106.0,"in face detectors and similar classifiers, haar-like wavelets [3] , [8] , [9] , [10] are frequently used, since they provide good amount of discriminative information and they provide excellent performance. other features are used in different contexts, such as the local binary patterns [5] .",{'face detector'},1.0,is-a,"face detectors are a classifier that frequently uses haar-like wavelets, since they provide good amount of discriminative information and they provide excellent performance.",face detector,classifier,no
20,17360106.0,,,,is-a,local binary patterns are a feature used in face detectors and similar classifiers.,local binary pattern,feature used in face detectors and similar classifiers,no
21,17360106.0,,,,compare,local binary patterns are an alternative to haar-like wavelets in that they are features used in different contexts for face detectors and similar classifiers.,local binary pattern,haar-like wavelets,no
22,403627.0,"therefore, the computational goal is to estimate an ideal binary mask which selects t-f units where the target energy dominates [1] . such ideal binary masks have been shown to be effective front-ends for robust automatic speech recognition [2] [3] and to provide speech intelligibility improvements for normal listeners under noisy conditions [3] .",{'ideal binary mask'},1.0,used-for,ideal binary masks are used to select t-f units where the target energy dominates.,ideal binary mask,select t-f units where the target energy dominates,no
23,403627.0,,,,is-a,ideal binary masks are effective front-ends for robust automatic speech recognition that provide speech intelligibility improvements for normal listeners under noisy conditions.,ideal binary mask,effective front-ends for robust automatic speech recognition,no
24,10213642.0,"remark that this approach assumes that an edit path may be deduced from a sequence of edit operations applied on nodes only. as we will see in this paper, this is possible because there is an equivalence relation between assignments and edit paths.",{'edit path'},0.0,,,,,
25,10213642.0,"more generally, any mapping between the nodes of two graphs induces an edit path which substitutes all mapped nodes together with all their incident edges, and inserts or removes the non-mapped nodes/edges. conversely, given an edit path between two graphs, such that each node and each edge is substituted only once, one can define a mapping between the substituted nodes and edges of both graphs.",{'edit path'},1.0,is-a,"an edit path is any mapping between the nodes of two graphs, which substitutes all mapped nodes together with all their incident edges, and inserts or removes the non-mapped nodes/edges. ",edit path,any mapping between the nodes of two graphs,no
26,189927804.0,"recently, hashing methods have been widely used in ann search. they usually learn a hamming space which is refined to maintain similarity between features song et al., 2018c;",{'hashing method'},1.0,used-for,hashing methods are used in ann search to usually learn a hamming space which is refined to maintain similarity between features.,hashing method,ann search,no
27,189927804.0,,,,based-on,"a hamming space is based on hashing methods, that is refined to maintain similarity between features in ann search.",hamming space,hashing method,yes
28,189927804.0,"since the computation of hamming distance is super fast, hashing methods have huge advantages on ann search. however, hashing methods lack accuracy on feature restoration.",{'hashing method'},1.0,used-for,"hashing methods are methods used for ann search that have huge advantages since the computation of hamming distance is super fast, but they lack accuracy on feature restoration. ",hashing method,method,no
29,189927804.0,"deep visual-semantic quantization [cao et al., 2017] and deep triplet quantization quantize features by cq. different from these works, deep product quantization [klein and wolf, 2017] , product quantization network [yu et al., 2018b] and generative adversarial product quantization [yu et al., 2018a] of neural network, so that gradient descent can be applied to quantization.",{'deep visual - semantic quantization'},1.0,compare,deep visual-semantic quantization is like deep triplet quantization in that they quantize features by cq.,deep visual - semantic quantization,deep triplet quantization,no
30,189927804.0,,,,compare,"product quantization network is an alternative to [deep visual-semantic quantization, deep triplet quantization], that can apply gradient descent to quantization.",product quantization network,"deep visual-semantic quantization, deep triplet quantization",yes
31,189927804.0,,,,compare,"product quantization network is like [deep product quantization, generative adversarial product quantization of neural network] in that they can apply gradient descent to quantization.",product quantization network,"deep product quantization, generative adversarial product quantization of neural network",no
32,59368612.0,"existing researches have proved that mouse dynamics are more effective in authenticating users in real time. existing researches about mouse dynamics have some common shortages: most of them need more than five international workshop on cloud computing and information security (ccis 2013) minutes to authenticate, some of them can only get satisfactory experimental result in a fixed application and some others ask the users to do some operations for a long time like playing a memory games.",{'mouse dynamic'},1.0,used-for,mouse dynamics are used for authenticating users in real time.,mouse dynamic,authenticating users in real time,no
33,5686072.0,"in the midst of this trend, computational thinking (ct) has quickly become a prerequisite skill for many endeavors of the 21st century [wing 2008 ]. computational thinking has a long history within computer science, dating back to the 1950s and 1960s, when it was labeled as ""algorithmic thinking"" [denning 2009 ].",{'computational thinking'},1.0,is-a,"computational thinking (ct) is a prerequisite skill for many endeavors of the 21st century that has a long history within computer science, dating back to the 1950s and 1960s, when it was labeled as ""algorithmic thinking"".",computational thinking,prerequisite skill for many endeavors of the 21st century,no
34,5686072.0,"similarly, computational thinking could be applied to language arts by having students do linguistic analysis of sentences and identifying and representing patterns for different sentence structures. computational thinking also has the potential to foster creativity in the classroom by allowing students to move from consumers of technology to building tools that benefit society [mishra et al. 2013] .",{'computational thinking'},1.0,used-for,computational thinking could be used for language arts by having students do linguistic analysis of sentences and identifying and representing patterns for different sentence structures.,computational thinking,language arts,no
35,5686072.0,,,,used-for,computational thinking could be used to foster creativity in the classroom by allowing students to move from consumers of technology to building tools that benefit society.,computational thinking,foster creativity in the classroom,no
36,5686072.0,"wing advocated the necessity of computational thinking in k-12 education by stating, ""to reading, writing, and arithmetic, we should add computational thinking to every child's analytical ability"" [wing 2006, p. 33] . a recent report on computational thinking by the national council for research advanced a similar idea: ct is a cognitive skill that an average person is expected to possess [nrc 2010 ].",{'computational thinking'},1.0,part-of,"computational thinking is a part of k-12 education that should be added to every child's analytical ability for reading, writing, and arithmetic.",computational thinking,k-12 education,no
37,5686072.0,,,,is-a,computational thinking is a cognitive skill that an average person is expected to posses based on a recent report by the national council for research.,computational thinking,cognitive skill,no
38,5686072.0,"a recent report on computational thinking by the national council for research advanced a similar idea: ct is a cognitive skill that an average person is expected to possess [nrc 2010 ]. the nrc report highlighted ""(1) that students can learn thinking strategies such as computational thinking as they study a discipline, (2) that teachers and curricula can model these strategies for students, and (3) that appropriate guidance can enable students to learn to use these strategies independently"" (p. 62).",{'computational thinking'},1.0,is-a,"computational thinking is a thinking strategy that students can learn as they study a discipline, teachers and curricula can model for students, and that appropriate guidance can enable students to learn independently.",computational thinking,thinking strategy,no
39,46821682.0,we formalize the concept of probabilistic movement primitives (promps) as a general probabilistic framework for representing and learning mps. a promp represents a distribution over trajectories.,{'probabilistic movement primitive'},1.0,is-a,probabilistic movement primitives (promps) is a general probabilistic framework for representing and learning mps that represents a distribution over trajectories.,probabilistic movement primitive,general probabilistic framework for representing and learning mps,no
40,46821682.0,"in this paper, we unify and complement our prior work [33, 36, 37] on promps. note that the reference [33] contains only a brief summary of our work on promps presented in the context of an overview paper that spans over multiple topics.",{'promp'},0.0,,,,,
41,5260346.0,"it was first proposed for lexicalized tree adjoining grammar (ltag) (bangalore and joshi, 1999) , then extended to combinatory categorial grammar (ccg) (clark, 2002) and head-driven phrase structure grammar (hpsg)",{'combinatory categorial grammar'},0.0,,,,,
42,5260346.0,"in practice, the multi-tagging technique proposed by clark (2002) assigned more than one supertag to each word and let the ambiguous supertags be selected by the parser. as for other nlp applications which use supertags, resolving more supertag ambiguities in supertagging stage is preferred.",{'supertag'},1.0,used-for,supertags are used for the multi-tagging technique that assigns more than one supertag to each word and lets the ambiguous supertags be selected by the parser.,supertag,the multi-tagging technique,no
43,5260346.0,,,,used-for,"supertags are used for nlp applications other than the multi-tagging technique, that prefer resolving more supertag ambiguities in supertagging stage.",supertag,nlp applications other than the multi-tagging technique,no
44,204960759.0,"thompson sampling is an efficient algorithm for sequential decision making, which exploits the posterior uncertainty to solve the exploration-exploitation dilemma. there has been significant recent interest in integrating bayesian neural networks into thompson sampling.",{'thompson sampling'},1.0,used-for,"thompson sampling is an efficient algorithm for sequential decision making, that exploits the posterior uncertainty to solve the exploration-exploitation dilemma.",thompson sampling,efficient algorithm for sequential decision making,no
45,204960759.0,,,,used-for,bayesian neural networks can be used for thompson sampling.,bayesian neural network,thompson sampling,no
46,204960759.0,"variational inference is used to approximate the posterior of the local variable, and semi-implicit structure is further introduced to enhance its expressiveness. our experimental results on eight contextual bandits benchmark datasets show that thompson sampling guided by local uncertainty achieves state-of-the-art performance while having low computational complexity.",{'variational inference'},1.0,used-for,variational inference is used to approximate the posterior of the local variable.,variational inference,approximate the posterior of the local variable,no
47,204960759.0,"therefore, significant effort has been dedicated to posterior approximation. a recent development along this direction is empowering ts with bayesian neural networks (hinton & van camp, 1993; bishop, 2006; graves, 2011; neal, 2012; hernndez-lobato & adams, 2015) , and relying on the posteriors of the neural network weights to perform exploration under the ts framework (riquelme et al., 2018) .",{'posterior approximation'},0.0,,,,,
48,17927373.0,we investigate the problem of secure communications in a gaussian multiway relay channel applying the compute-and-forward scheme under usage of nested lattice codes. all nodes employ half-duplex operation and can exchange confidential messages only via an untrusted relay.,{'compute - - forward scheme'},0.0,,,,,
49,56003001.0,"in this paper we analyze different aspects related to the use of twitter in different national meteorological services (nms) worldwide. firstly, we will review the general position of nms worldwide regarding the use of twitter technology.",{'nms'},0.0,,,,,
50,56003001.0,"as a consequence many nms have developed new communication strategies and incorporated this tool for different purposes. some nms do not only provide forecast and other remarkable information routinely, but gives real-time observed data, forecast and relevant information continuously before and during severe-weather episodes, as in the basque meteorology service (euskalmet) case (gaztelumendi et al., 2013a) .",{'nms'},1.0,is-a,"nms is a tool that can not only provide forecast and other remarkable information routinely, but gives real-time observed data, forecast and relevant information continuously before and during severe-weather episodes, as in the basque meteorology service.",nms,tool,no
51,10351076.0,"this study develops an original and innovative matrix representation with respect to the information flow for networked multi-agent system. to begin with, the general concepts of the edge laplacian of digraph are proposed with its algebraic properties.",{'networked multi - agent system'},0.0,,,,,
52,10351076.0,"to begin with, the general concepts of the edge laplacian of digraph are proposed with its algebraic properties. benefit from this novel graph-theoretic tool, we can build a bridge between the consensus problem and the edge agreement problem; we also show that the edge laplacian sheds a new light on solving the leaderless consensus problem.",{'edge laplacian'},1.0,is-a,edge laplacian of digraph is a novel graph-theoretic tool that can build a bridge between the consensus problem and the edge agreement problem and sheds a new light on solving the leaderless consensus problem.,edge laplacian,novel graph-theoretic tool,no
53,10351076.0,"first, the edge laplacian of digraph is proposed as well as the edge adjacency matrix. comparing to our previous works [35] , much more details about the algebraic properties of the edge laplacian are explored.",{'edge laplacian'},0.0,,,,,
54,10351076.0,"comparing to our previous works [35] , much more details about the algebraic properties of the edge laplacian are explored. as a matter of fact, the invertibility of the incidence matrix and the spectra properties of the edge laplacian play a central role in the subsequent analysis.",{'edge laplacian'},0.0,,,,,
55,11387290.0,"random forest is an algorithm that uses an ensemble of classification trees, each of which is built using a bootstrap sample of the data, and at each split the candidate set of genes is a random subset of the genes. thus, random forest uses both bagging (bootstrap aggregation) and random variable selection for tree building.",{'random forest'},1.0,is-a,"random forest is an algorithm that uses an ensemble of classification trees, each of which is built using a bootstrap sample of the data, and at each split the candidate set of genes is a random subset of the genes. ",random forest,algorithm,no
56,11387290.0,,,,is-a,random forest is an algorithm that uses both bagging (bootstrap aggregation) and random variable selection for tree building.,random forest,algorithm,no
57,11387290.0,"thus, random forest uses both bagging (bootstrap aggregation) and random variable selection for tree building. each tree is unpruned to obtain low-bias trees; at the same time, bagging and random variable selection result in low correlation of the individual trees.",{'random forest'},1.0,is-a,bagging is a bootstrap aggregation that is used for tree building in random forests and results in low correlation of the individual trees.,bagging,bootstrap aggregation,no
58,11387290.0,,,,compare,bagging is like random variable selection in that they are used for tree building in random forests and result in low correlation of the individual trees.,bagging,random variable selection,no
59,6527365.0,"amr aims to abstract away from syntactic idiosyncrasies and attempts to capture only the core meaning of a sentence, which could potentially improve ddi extraction from sentences. two classifiers (support vector machine and random forest) taking these embedding features as input were evaluated on the ddiextraction 2013 challenge corpus.",{'ddi extraction'},1.0,is-a,random forest is a classifier that has taken embedding features as input to evaluate on the ddiextraction 2013 challenge corpus.,random forest,classifier,no
60,6527365.0,,,,compare,random forest is like support vector machine in that they are classifiers that have taken embedding features as input to evaluate on the ddiextraction 2013 challenge corpus.,random forest,support vector machine,no
61,6527365.0,"in this paper, we utilize dependency and amr embeddings as features for ddi extraction. we evaluate these embeddings on ddiextraction 2013 challenge corpus with two different classification methods: svm and random forest.",{'ddi extraction'},1.0,is-a,random forest is a classification method that is evaluated on the ddiextraction 2013 challenge corpus.,random forest,classification method,no
62,6527365.0,,,,compare,random forest is like svm in that they are both classification methods that are evaluated on the ddiextraction 2013 challenge corpus.,random forest,svm,no
63,6527365.0,"in the next section, we briefly introduce the related work of used features for ddi extraction in the literature. in section 3, we describe the proposed methods for ddi extraction.",{'ddi extraction'},0.0,,,,,
64,6527365.0,"[36, 37] organized the ddi extraction challenge tasks in 2011 and 2013 to stimulate research in developing automatic information extraction tools for ddi extraction from literature. the datasets for ddiextraction 2011 were composed of sentences describing ddis from the drugbank database and another dataset including medline abstracts was added to ddiextraction 2013.",{'ddi extraction'},1.0,is-a,ddi extraction is a challenge task for automatic information extraction from literature that used datasets composed of sentences describing ddis from the drugbank database (2011) and included medline abstracts (2013).,ddi extraction,challenge task for automatic information extraction from literature,no
65,6527365.0,"word embedding is a word representation that captures semantic and syntactic similarities between words. it has been widely utilized for a variety of tasks, such as sentence classification [42] , relation classification [41] , and sentiment analysis [38] , since the introduction of word2vec software.",{'word representation'},1.0,is-a,sentence classification is a task that word embedding has been utilized for since the introduction of word2vec software.,sentence classification,task,no
66,6527365.0,,,,compare,"sentence classification is like [relation classification, sentiment analysis] in that they are tasks that word embedding has been utilized for since the introduction of word2vec software.",sentence classification,"relation classification, sentiment analysis",yes
67,6527365.0,,,,used-for,"word representation has been used for [sentence classification, relation classification, sentiment analysis], since the introduction of word2vec software.",word representation,"sentence classification, relation classification, sentiment analysis",yes
68,6527365.0,"it has been widely utilized for a variety of tasks, such as sentence classification [42] , relation classification [41] , and sentiment analysis [38] , since the introduction of word2vec software. for ddi extraction from biomedical literature, word embeddings have also drawn researchers' attention recently.","{'sentence classification', 'relation classification'}",0.0,,,,,
69,2012740.0,"we in this paper describe the regression system for our participation in the quality estimation task of wmt12. this paper focuses on exploiting special phrases, or word sequences, to estimate translation quality.",{'wmt12'},0.0,,,,,
70,2012740.0,"early works (quirk, 2004; gamon et al., 2005) have demonstrated the consistency of the automatic score and human evaluation. several further works aimed at predicting automatic scores in order to better select mt n-best candidates (specia and farzindar, 2010) , measure post-editing effort (specia et al., 2011) or combine smt and tm systems (he et al., 2010) .",{'human evaluation'},0.0,,,,,
71,204960894.0,"this paper investigates a downlink multiple-input single-output intelligent reflecting surface (irs) non-orthogonal multiple access (noma) system, where a base station (bs) serves multiple users with the aid of irss. our goal is to maximize the sum rate of all users by jointly optimizing the active beamforming at the bs and the passive beamforming at the irs, subject to successive interference cancellation decoding rate conditions and irs reflecting elements constraints.",{'irss'},1.0,part-of,passive beamforming is a part of the intelligent reflecting surface (irs) that is subject to successive interference cancellation decoding rate conditions and irs reflecting elements constraints.,passive beamforming,intelligent reflecting surface (irs),no
72,1120611.0,gepsvm cancels the constraint that the two hyperplanes must be parallel in psvm. gepsvm makes each type of sample points be as close as possible to its hyperplane and be as far as possible away from the other sample points.,{'gepsvm'},0.0,,,,,
73,1120611.0,"thereafter, on the basis of the extensive and in-depth study of psvm and gepsvm, in 2007, the algorithm of twin support vector machines (twsvm) was proposed by jayadeva [16] et al. twsvm solves a hyperplane for each type of sample points and makes each type of sample points be as close as possible to its hyperplane and as far as possible away from another type of sample points' hyperplane.",{'twin support vector machine'},1.0,is-a,twin support vector machine (twsvm) is an algorithm that solves a hyperplane for each type of sample points and makes each type of sample points be as close as possible to its hyperplane and as far as possible away from another type of sample points' hyperplane.,twin support vector machine ,algorithm,no
74,1120611.0,twsvm solves a hyperplane for each type of sample points and makes each type of sample points be as close as possible to its hyperplane and as far as possible away from another type of sample points' hyperplane. the two hyperplanes in twsvm have no constraint of the parallel condition.,{'twsvm'},1.0,is-a,"twsvm is an algorithm that solves a hyperplane for each type of sample points and makes each type of sample points be as close as possible to its hyperplane and as far as possible away from another type of sample points' hyperplane, and the two hyperplanes have no constraint of the parallel condition.",twsvm,algorithm,no
75,1120611.0,the two hyperplanes in twsvm have no constraint of the parallel condition. the binary classification problem is converted to two smaller quadratic programming problems by twsvm.,{'twsvm'},1.0,is-a,twsvm is an algorithm that converts the binary classification problem to two smaller quadratic programming problems.,twsvm,algorithm,no
76,1120611.0,"after twsvm was proposed, it has caused the attention of many scholars. because twsvm has the solid theoretical foundation and the superiority of solving problems, many scholars contribute to the study of twsvm [17] [18] [19] .",{'twsvm'},0.0,,,,,
77,1120611.0,"because twsvm has the solid theoretical foundation and the superiority of solving problems, many scholars contribute to the study of twsvm [17] [18] [19] . although the time of the development of twsvm is not long, there have been many achievements in the efforts of the majority of research workers.",{'twsvm'},0.0,,,,,
78,1120611.0,"although the time of the development of twsvm is not long, there have been many achievements in the efforts of the majority of research workers. for example, jing chen[20] proposed the algorithm of wlstwsvm(weighted least squares twsvm), qi zhiquan [21] proposed a new type of robust twin support vector machine for pattern classification, in 2009, xinsheng zhang et al applied the twsvm to the detection of mcs [22] .",{'twsvm'},1.0,used-for,robust twin support vector machine can be used for pattern classification.,robust twin support vector machine,pattern classification,no
79,1120611.0,"for example, jing chen[20] proposed the algorithm of wlstwsvm(weighted least squares twsvm), qi zhiquan [21] proposed a new type of robust twin support vector machine for pattern classification, in 2009, xinsheng zhang et al applied the twsvm to the detection of mcs [22] . as a classifier, twsvm makes decisions about the presence of mcs or not.","{'robust twin support vector machine', 'twsvm'}",1.0,is-a,twsvm is a classifier that makes decisions about the presence of mcs or not.,twsvm,classifier,no
80,1120611.0,,,,used-for,robust twin support vector machine can be used for pattern classification.,robust twin support vector machine,pattern classification,no
81,1120611.0,"as a classifier, twsvm makes decisions about the presence of mcs or not. the experiments show that the classifier of twsvm is conducive to the real-time processing of cms.",{'twsvm'},1.0,is-a,twsvm is a classifier that is conducive to the real-time processing of cms.,twsvm,classifier,no
82,1120611.0,,,,is-a,twsvm is a classifier that makes decisions about the presence of mcs or not.,twsvm,classifier,no
83,1120611.0,"the experiments show that the classifier of twsvm is conducive to the real-time processing of cms. in 2012, the twin support vector machines based on rough sets was proposed by junzhao yu",{'twsvm'},1.0,is-a,twsvm is a classifier that is conducive to the real-time processing of cms.,twsvm,classifier,no
84,1120611.0,this paper proposes a algorithm to find the values of the optimal parameters quickly and we can use this algorithm to improve twsvm. that is the twin support vector machines based on quantum particle swarm optimization (qpso-twsvm).,{'twsvm'},0.0,,,,,
85,59540846.0,"sampling-based planners have proven to be effective in challenging settings of the single-robot case, and a number of such planners have been proposed for mrmp (dobson et al., 2017;  vestka and overmars, 1998; wagner and choset, 2015) . sampling-based planners attempt to capture the connectivity of the free space by sampling random configurations and connecting nearby configurations by simple collision-free paths.",{'sampling - base planner'},1.0,is-a,"sampling-based planners are planners that have proven to be effective in challenging settings of the single-robot case, a number of such planners have been proposed for mrmp, and they attempt to capture the connectivity of the free space by sampling random configurations and connecting nearby configurations by simple collision-free paths.",sampling - base planner,planner,no
86,204512527.0,"recently, many nlp tasks have shown great improvements thanks to pre-trained language models. models such as elmo [10] , bert [3] and gpt [11] include a large language model or contextual embedder with hundreds of millions of parameters trained on large datasets and were shown to produce state-of-the-art models for many nlp tasks, including low-resource scenarios where very little annotated data is available.",{'nlp task'},1.0,is-a,"[elmo, bert, gpt] are pre-trained language models that include a large language model or contextual embedder with hundreds of millions of parameters trained on large datasets and were shown to produce state-of-the-art models for many nlp tasks, including low-resource scenarios where very little annotated data is available.","elmo, bert, gpt",pre-trained language model,no
87,204512527.0,,,,part-of,"large language models are a part of [gpt, bert, elmo] that have hundreds of millions of parameters trained on large datasets and were shown to produce state-of-the-art models for many nlp tasks, including low-resource scenarios where very little annotated data is available.",large language model,"gpt, bert, elmo",yes
88,204512527.0,,,,compare,"elmo is like [bert, gpt] in that they are pre-trained language models that include a large language model or contextual embedder with hundreds of millions of parameters trained on large datasets and were shown to produce state-of-the-art models for many nlp tasks, including low-resource scenarios where very little annotated data is available.",elmo ,"bert, gpt",yes
89,204512527.0,,,,compare,"bert is like [elmo, gpt] in that they are pre-trained language models that include a large language model or contextual embedder with hundreds of millions of parameters trained on large datasets and were shown to produce state-of-the-art models for many nlp tasks, including low-resource scenarios where very little annotated data is available.",bert,"elmo, gpt",yes
90,204512527.0,,,,compare,"gpt is like [bert, elmo] in that they are pre-trained language models that include a large language model or contextual embedder with hundreds of millions of parameters trained on large datasets and were shown to produce state-of-the-art models for many nlp tasks, including low-resource scenarios where very little annotated data is available.",gpt,"bert, elmo",yes
91,204512527.0,"models such as elmo [10] , bert [3] and gpt [11] include a large language model or contextual embedder with hundreds of millions of parameters trained on large datasets and were shown to produce state-of-the-art models for many nlp tasks, including low-resource scenarios where very little annotated data is available. in particular, transformer-base [16] models such as bert were shown to be highly effective in transfer-learning by fine-tuning all model parameters when training on a target task.","{'gpt', 'large language model', 'bert', 'nlp task', 'elmo'}",1.0,type-of,bert is a type of transformer-base model that was shown to be highly effective in transfer-learning by fine-tuning all model parameters when training on a target task.,bert,transformer-base model,no
92,204512527.0,,,,is-a,"[elmo, bert, gpt] are models that include a large language model or contextual embedder with hundreds of millions of parameters trained on large datasets and were shown to produce state-of-the-art models for many nlp tasks, including low-resource scenarios where very little annotated data is available.","elmo, bert, gpt",model,no
93,204512527.0,,,,part-of,"large language models are a part of [gpt, bert, elmo] that have hundreds of millions of parameters trained on large datasets and were shown to produce state-of-the-art models for many nlp tasks, including low-resource scenarios where very little annotated data is available.",large language model,"gpt, bert, elmo",yes
94,204512527.0,,,,compare,"elmo is like [bert, gpt] in that they are pre-trained language models that include a large language model or contextual embedder with hundreds of millions of parameters trained on large datasets and were shown to produce state-of-the-art models for many nlp tasks, including low-resource scenarios where very little annotated data is available.",elmo ,"bert, gpt",yes
95,204512527.0,,,,compare,"bert is like [elmo, gpt] in that they are pre-trained language models that include a large language model or contextual embedder with hundreds of millions of parameters trained on large datasets and were shown to produce state-of-the-art models for many nlp tasks, including low-resource scenarios where very little annotated data is available.",bert,"elmo, gpt",yes
96,204512527.0,,,,compare,"gpt is like [bert, elmo] in that they are pre-trained language models that include a large language model or contextual embedder with hundreds of millions of parameters trained on large datasets and were shown to produce state-of-the-art models for many nlp tasks, including low-resource scenarios where very little annotated data is available.",gpt,"bert, elmo",yes
97,204512527.0,"our approach can be used to train compact models for other nlp tasks. for example, by replacing the compact model with other compact models relevant to the downstream task or by replacing or creating an ensemble of teacher models.",{'nlp task'},0.0,,,,,
98,17668071.0,"intuitively, pixel-level labels provide a large amount of supervision compared to image-level labels, given proper accounting of correlations. without using any extra data, our model outperforms previous unsupervised/self-supervised approaches for semantic segmentation on pascal voc-2012 [26] , and is competitive to fine-tuning from pre-trained models for surface normal estimation.",{'image - level label'},1.0,compare,image-level labels are an alternative to pixel-level labels that provide a smaller amount of supervision.,image - level label,pixel - level label,no
99,17668071.0,"the family of fully-convolutional and skip networks [65, 77] are illustrative examples that have been successfully applied to, e.g., edge detection [94] and semantic segmentation [12, 16, 27, 30, 62, 60, 67, 71, 75] . because such architectures still produce separate predictions for each pixel, numerous approaches have explored post-processing steps that enforce spatial consistency across labels via e.g., bilateral smoothing with fully-connected gaussian crfs [16, 52, 101] or bilateral solvers [8] , dilated spatial convolutions [97] , lstms [12] , and convolutional pseudo priors [93] .",{'semantic segmentation'},1.0,is-a,bilateral solvers are an approach that have explored post-processing steps that enforce spatial consistency across labels for the family of fully-convolutional and skip networks that still produce separate predictions for each pixel.,bilateral solver,approach,no
100,17668071.0,,,,compare,"bilateral solvers are like [bilateral smoothing with fully-connected gaussian crfs, dilated spatial convolutions, lstms, convolutional pseudo priors] in that they are approaches that have explored post-processing steps that enforce spatial consistency across labels for the family of fully-convolutional and skip networks that still produce separate predictions for each pixel.",bilateral solver,"bilateral smoothing with fully-connected gaussian crfs, dilated spatial convolutions, lstms, convolutional pseudo priors",no
101,17668071.0,"deeplab [16] incorporates filter dilation and applies similar deconvolution and linear-weighted fusion, in addition to reducing the dimensionality of the fully-connected layers to reduce memory footprint. parsenet [60] added spatial context for a layer's responses by average pooling the feature responses, followed by normalization and concatenation.",{'fully - connect layer'},1.0,compare,"parsenet is like deeplab, except parsenet added spatial context for a layer's responses by average pooling the feature responses, followed by normalization and concatenation.",parsenet,deeplab,no
102,213175531.0,we improve upon previous state-of-the-art on reasonable/heavy subsets of citypersons dataset by 1.3%/1.7% and on caltech by 1.8%/14.9% in terms of log average miss rate (m r 2 ) points without any fine-tuning on the test set. detector trained through proposed pipeline achieves top rank at the leaderborads of citypersons [42] and ecp [4] .,"{'fine - tuning', 'cityperson'}",0.0,,,,,
103,213175531.0,"right: we show comparison between traditional single-dataset train and test evaluation on caltech [12] vs. cross-dataset evaluation for 3 pedestrian detectors and one general object detector (cascade r-cnn). methods enclosed in bounding-box are trained on citypersons [42] and evaluated on caltech [12] , while others are trained on caltech.",{'cascade r - cnn'},1.0,is-a,cascade r-cnn is a general object detector.,cascade r - cnn,general object detector,no
104,213175531.0,"pedestrian detection. before the emergence of cnns, a common way to address this problem was to exhaustively operate in a sliding window manner over all possible locations and scales, inspired from viola and jones [35] .",{'pedestrian detection'},0.0,,,,,
105,213175531.0,"before the emergence of cnns, a common way to address this problem was to exhaustively operate in a sliding window manner over all possible locations and scales, inspired from viola and jones [35] . dalal and triggs in their landmark pedestrian detection work [10] proposed histogram of oriented gradients (hog) feature descriptor for representing pedestrians.","{'viola', 'cnn'}",0.0,,,,,
106,213175531.0,"in recent years, convolutional neural networks (cnns) have become the dominant paradigm in generic object detection [30, 16, 33, 21] . the same trend is also true for the pedestrian detection [2, 17, 7] .",{'convolutional neural network'},1.0,is-a,convolutional neural networks are a dominant paradigm that are used in generic object detection and pedestrian detection.,convolutional neural network,dominant paradigm,no
107,213175531.0,"rpn+bf [40] was the first work to use region proposal network (rpn); it used boosted forest for improving pedestrian detection performance. this work also pointed out some problems in the underlying classification branch of faster rcnn [30] , namely that the resolution of the feature maps and class-imbalance.","{'region proposal network', 'rpn'}",0.0,,,,,
108,213175531.0,"after the initial works, faster rcnn [30] became most popular framework with wide range of literature deploying it for pedestrian detection [44, 42, 6, 5, 25] .",{'fast rcnn'},1.0,used-for,faster rcnn is used for pedestrian detection.,fast rcnn,pedestrian detection,yes
109,213175531.0,,,,is-a,faster rcnn is a popular framework that has a wide range of literature deploying it for pedestrian detection.,fast rcnn,popular framework,no
110,213175531.0,"therefor, in this paper we argue that despite some recent large scale datasets, the ability of pedestrian detectors to generalize has been constraint by lack of diversity and density. moreover, benchmarks such as wider pedestrian [1] and crowdhuman [31] , which contain web crawled images provide a much larger diversity and density.",{'pedestrian detector'},1.0,is-a,crowdhuman is a benchmark that contains web crawled images that provide a much larger diversity and density to improve the ability of pedestrian detectors to generalize.,crowdhuman ,benchmark,no
111,213175531.0,,,,compare,crowdhuman is like wider pedestrian in that they are benchmarks that contains web crawled images that provide a much larger diversity and density to improve the ability of pedestrian detectors to generalize.,crowdhuman ,wider pedestrian,no
112,6166472.0,"for stms, we used gcc's stm due to its low overhead. results with our designed dyadhytm show that it provides better performance than conventional synchronization methods such as locks, stms and even htms for a standard graph application of large size as we scale the core/thread count, memory size and problem size.",{'stms'},0.0,,,,,
113,208513380.0,"ford [16] presents packrat parsing, a parsing technique for parsing expression grammars (pegs). packrat parsers are nonambiguous and guaranteed to run in linear time through heavy use of memoisation but tend to be slower than many other linear-time parsing techniques.",{'expression grammar'},1.0,is-a,packrat parsing is a parsing technique for parsing expression grammars (pegs) that is nonambiguous and guaranteed to run in linear time through heavy use of memoisation but tends to be slower than many other linear-time parsing techniques.,packrat parser,parsing technique for parsing expression grammars (pegs),no
114,32084468.0,"the simulation results show that the gail algorithm can achieve optimal performance with considerably lower and more stable computational complexity with the appropriate parameter settings compared to other conventional detectors such as sphere decoding (sd) and the k-best algorithm. moreover, the gail algorithm achieves significantly improved performance while exhibiting lower complexity than the sic detector, particularly for large mimo systems.",{'k - good algorithm'},1.0,is-a,the k-best algorithm is a conventional detector.,k - good algorithm,conventional detector,no
115,32084468.0,,,,compare,the k-best algorithm is like sphere decoding (sd) in they they are conventional detectors.,k - good algorithm,sphere decoding (sd),no
116,208104997.0,[32] construct a graph kernel considering the subtree patterns which are rooted subgraphs at vertices. every subtree pattern has a tree-structured signature.,{'subtree pattern'},1.0,is-a,subtree patterns are rooted subgraphs at vertices that each have a tree-structured signature.,subtree pattern,rooted subgraphs at vertices,no
117,208104997.0,the optimal assignment kernels can provide a more valid notion of graph similarity. the authors finally integrate the optimal assignment kernels into the weisfeiler-lehman subtree kernel.,{'optimal assignment kernel'},0.0,,,,,
118,208104997.0,"the authors finally integrate the optimal assignment kernels into the weisfeiler-lehman subtree kernel. in addition to the above-described literature, there are also some literature [17, 20, 26, 27, 41, 42] for graph classification that are related to our work.",{'optimal assignment kernel'},0.0,,,,,
119,208104997.0,then hgk compares these discrete labeled graphs by an arbitrary graph kernel such as the weisfeiler-lehman subtree kernel or the shortest-path kernel. gik [28] proposes graph invariant kernels that exploit a vertex invariant kernel (spectral coloring kernel) to combine both the similarities of vertex labels and vertex structural roles.,{'short - path kernel'},1.0,is-a,shortest-path kernel is an arbitrary graph kernel.,short - path kernel,arbitrary graph kernel,no
120,208104997.0,,,,compare,shortest-path kernel is like the weisfeiler-lehman subtree kernel in that they are arbitrary graph kernels.,short - path kernel,weisfeiler-lehman subtree kernel,no
121,208104997.0,,,,is-a,graph invariant kernels are kernels that can exploit a vertex invariant kernel (spectral coloring kernel) to combine both the similarities of vertex labels and vertex structural roles.,graph invariant kernel,kernel,no
122,11135343.0,"color -presence of more than one color in melanoma lesions in recent years, there have been a number of computerized diagnosis techniques developed which use digital image processing in an attempt to classify benign and malignant skin lesions from dermoscopy images [4] . to accelerate the innovation in this area the international skin imaging collaboration (isic) 1 has initiated the isic challenge.",{'dermoscopy image'},1.0,is-a,isic is the international skin imaging collaboration that initiated the isic challenge to accelerate the innovation in the area of computerized diagnosis techniques developed which use digital image processing in an attempt to classify benign and malignant skin lesions from dermoscopy images.,isic,international skin imaging collaboration,yes
123,11135343.0,,,,used-for,dermoscopy images are used to classify benign and malignant skin lesions.,dermoscopy image,classify benign and malignant skin lesions,no
124,8908134.0,probabilistic model checking is an advanced formal verification technique for modeling and analyzing systems that exhibit probabilistic behavior. the key benefit of using probabilistic model checking in our approach is that it caters for incorporating the real-world disturbances and noise in the models and thus can be utilized for the quantitative analysis of cell injection systems.,{'probabilistic model checking'},1.0,is-a,"probabilistic model checking is an advanced formal verification technique that is used for modeling and analyzing systems that exhibit probabilistic behavior, and it caters for incorporating the real-world disturbances and noise in the models and thus can be utilized for the quantitative analysis of cell injection systems.",probabilistic model checking,advanced formal verification technique,no
125,212634227.0,"the methods using binary code representation can be categorized as binary hashing (bh) and product quantization (pq) [13] . bh-based methods [34, 7, 26 ] employ a hash function that maps a high-dimensional vector space to a hamming space, where the distance between two codes can be measured extremely fast via bitwise xor operation.","{'product quantization', 'binary hashing'}",1.0,is-a,"binary hashing is a method that uses binary code representation and employs a hash function that maps a high-dimensional vector space to a hamming space, where the distance between two codes can be measured extremely fast via bitwise xor operation.",binary hashing,method,no
126,212634227.0,,,,compare,binary hashing is like product quantization in that they are methods that use binary code representation.,binary hashing,product quantization,yes
127,212634227.0,,,,is-a,product quantization is a method that uses binary code representation.,product quantization,method,no
128,212634227.0,"along with millions of elaborately labeled data, deep hashing for both bh [35, 18, 11, 12, 14] and pq [2, 19, 38, 16] has been introduced to take advantage of deep representations for image retrieval. by employing supervised deep neural networks, deep hashing outperforms conventional ones on many benchmark datasets.",{'deep hashing'},1.0,is-a,deep hashing is a method that takes advantage of deep representations for image retrieval and employs supervised deep neural networks to outperform conventional ones on many benchmark datasets.,deep hashing,method,no
129,212634227.0,"existing hashing methods referring to the survey [31] , early works in binary hashing (bh) [34, 7, 26, 30] and product quantization (pq)",{'binary hashing'},0.0,,,,,
130,52197431.0,"in order to address these issues, we propose a novel verifiable fuzzy keyword search scheme over encrypted cloud data. for the purpose of introducing this scheme, we first propose a verifiable exact keyword search scheme and then extend this scheme to the fuzzy keyword search scheme.",{'encrypt cloud datum'},0.0,,,,,
131,52197431.0,"for the purpose of introducing this scheme, we first propose a verifiable exact keyword search scheme and then extend this scheme to the fuzzy keyword search scheme. in the fuzzy keyword search scheme, we employ the linked list as our secure index to achieve the efficient storage.",{'fuzzy keyword search scheme'},0.0,,,,,
132,52197431.0,"in the fuzzy keyword search scheme, we employ the linked list as our secure index to achieve the efficient storage. we construct a linked list with three nodes for each exact keyword and generate a fuzzy keyword set for it.","{'secure index', 'fuzzy keyword search scheme'}",0.0,,,,,
133,52197431.0,"we construct a linked list with three nodes for each exact keyword and generate a fuzzy keyword set for it. to reduce the computation cost and the storage space, we generate one index vector for each fuzzy keyword set, rather than each fuzzy keyword.",{'fuzzy keyword'},0.0,,,,,
134,52197431.0,"to reduce the computation cost and the storage space, we generate one index vector for each fuzzy keyword set, rather than each fuzzy keyword. to resist malicious behaviors of the cloud server, we generate an authentication label for each fuzzy keyword to verify the authenticity of the returned ciphertexts.",{'fuzzy keyword'},0.0,,,,,
135,17650320.0,"polyhedral visual hull. several approaches (matusik et al., 2000) , (casas and salvador, 2006) , reconstruct the visual hull based in 3d constructive solid geometry intersections.",{'polyhedral visual hull'},0.0,,,,,
136,17650320.0,"several approaches (matusik et al., 2000) , (casas and salvador, 2006) , reconstruct the visual hull based in 3d constructive solid geometry intersections. silhouettes are backprojected creating a set of extruded cones, which are then intersected to form a polyhedral visual hull.",{'visual hull'},0.0,,,,,
137,9037945.0,"first reported in [6] , opinion spam refers to deliberate attempts (e.g., writing fake reviews, giving unfair ratings) to promote/demote target products/services. several high-profile cases of fake reviews have been reported in the news.","{'opinion spam', 'fake review', 'unfair rating'}",1.0,is-a,opinion spam is the deliberate attempt to promote/demote target products/services such as writing fake reviews and giving unfair ratings.,opinion spam,deliberate attempt to promote/demote target products/services such as writing fake reviews and giving unfair ratings,no
138,9037945.0,,,,type-of,fake reviews are a type of opinion spam that attempt to promote/demote target products/services and have been reported in the news for several high-profile cases.,fake review,opinion spam,yes
139,9037945.0,,,,type-of,unfair ratings are a type of opinion spam that attempt to promote/demote target products/services.,unfair rating,opinion spam,yes
140,9037945.0,,,,compare,unfair ratings are like fake reviews in that they are types of opinion spam that attempt to promote/demote target products/services.,unfair rating,fake review,yes
141,9037945.0,"several high-profile cases of fake reviews have been reported in the news. while credit-card fraud is as low as 0.2%, opinion spam is prevalent",{'fake review'},0.0,,,,,
142,202776994.0,"in this paper, a new health degradation monitoring method of reb is proposed based on growing self-organizing mapping (gsom) and clustered support vector machine (csvm). gsom adjusts network structure and parameters adaptively and fuses the feature data for his of the reb automatically.",{'gsom'},1.0,is-a,gsom is growing self-organizing mapping that adjusts network structure and parameters adaptively and fuses the feature data for his of the reb automatically.,gsom,growing self-organizing mapping,no
143,121288690.0,"sparse coding problems assume the data y can be represented as a sparse linear combination of columns (features) of a matrix h, termed a dictionary. given the dictionary h, methods such as orthogonal matching pursuit [1] and basis pursuit [2] find the sparse representation.",{'sparse linear combination'},1.0,is-a,"orthogonal matching pursuit is a method that finds the sparse representation for a dictionary h, which is a sparse linear combination of columns (features) of a matrix h.",orthogonal matching pursuit,method,no
144,121288690.0,,,,compare,"orthogonal matching pursuit is like basis pursuit in that they are methods that find the sparse representation for a dictionary h, which is a sparse linear combination of columns (features) of a matrix h.",orthogonal matching pursuit,basis pursuit,yes
145,121288690.0,,,,is-a,"basis pursuit is a method that finds the sparse representation for a dictionary h, which is a sparse linear combination of columns (features) of a matrix h.",basis pursuit,method,no
146,121288690.0,,,,part-of,"a sparse linear combination is a part of sparse coding problems that represents the data y in the columns (features) of a matrix h, termed a dictionary.",sparse linear combination,sparse coding problem,no
147,202660778.0,"(2015b) proposed the generalized advantage estimation (gae) to explore the trade-off between bias and variance of policy gradient. recently, action-dependent baselines are also used in tucker et al.","{'policy gradient', 'gae', 'generalized advantage estimation'}",1.0,is-a,gae is the generalized advantage estimation that was proposed to explore the trade-off between bias and variance of policy gradient.,gae,generalized advantage estimation,yes
148,10284077.0,"alternatively, physical-layer security emerges as a promising paradigm to achieve the perfect secrecy by taking full advantage of physical characteristics of wireless channels [14] , [15] . wyner [16] first proved that if the wiretap channel spanning from a source to an eavesdropper is a degraded version of the main channel spanning from the source to its desired receiver, a perfect secrecy can be achieved without any confidential information leakage to the eavesdropper.",{'perfect secrecy'},0.0,,,,,
149,10284077.0,"wyner [16] first proved that if the wiretap channel spanning from a source to an eavesdropper is a degraded version of the main channel spanning from the source to its desired receiver, a perfect secrecy can be achieved without any confidential information leakage to the eavesdropper. later on, leung-yan-cheong and hellman [17] introduced a notion of secrecy capacity shown as the difference between the capacity of main channel and that of wiretap channel, which is severely degraded in wireless fading environments.","{'wiretap channel', 'perfect secrecy'}",1.0,is-a,"secrecy capacity is a notion that has been shown as the difference between the capacity of main channel and that of wiretap channel, which is severely degraded in wireless fading environments.",secrecy capacity,notion,no
150,9796844.0,"because the signal detected at 3.02 ppm using these experimental parameters is also expected to contain contributions from both macromolecules (mm) and homocarnosine, in this study the signal is labeled gaba+ rather than gaba. significant negative correlations were observed between age and gaba+ in both regions studied (gaba +/cr: frontal region, r =  0.68, p b 0.001, parietal region, r =  0.54, p b 0.001; gaba +/naa: frontal region, r =  0.58, p b 0.001, parietal region, r =  0.49, p b 0.001).",{'gaba+'},0.0,,,,,
151,30474563.0,"xcs uses the accuracy of rules as their fitness and genetic algorithms (ga) (holland, 1975) to evolve generalizations over the space of possible state-action pairs of a reinforcement learning task with the aim of easing the use of such approaches in large problems, (i.e., those with state-action combinations that are too numerous for an explicit entry for each). xcs can also avoid problematic over general rules that receive a high optimal payoff for some inputs, but are sub-optimal to other lower payoff inputs.",{'xcs'},1.0,is-a,"xcs is a tool that uses the accuracy of rules as their fitness and genetic algorithms (ga) to evolve generalizations over the space of possible state-action pairs of a reinforcement learning task with the aim of easing the use of such approaches in large problems, (i.e., those with state-action combinations that are too numerous for an explicit entry for each) and can also avoid problematic over general rules that receive a high optimal payoff for some inputs, but are sub-optimal to other lower payoff inputs.",xcs,tool,no
152,30474563.0,"in particular, wilson (2001a wilson ( ) (2001b applied xcs to a medical dataset, namely the wisconsin breast cancer dataset (wbc), and showed that xcs can tackle real complex learning problems, in addition to its capability to deal with different representations. also, xcs was tested on the wisconsin diagnostic breast cancer dataset (wdbc) dataset in (bacardit and butz, 2004 ) and shown to have competitive performance in both training and testing phases.",{'xcs'},1.0,used-for,xcs is used for medical datasets to tackle real complex learning problems and deal with different representations and has shown to have competitive performance in both training and testing phases.,xcs,medical datasets to tackle real complex learning problems and deal with different representations and has shown to have competitive performance in both training and testing phases,no
153,53780660.0,"this strict constraint, however, leads to the fact that nmf cannot be applied to many real problems due to noise or outlier. to solve this problem, the concept factorization (cf)",{'nmf'},0.0,,,,,
154,7561107.0,"the conditions under which a game belongs to these classes have been examined by several researchers (hofbauer, 1985; monderer and shapley, 1996; ui, 2000; hofbauer and sandholm, 2009; sandholm, 2010a) . for example monderer and shapley (1996) and hofbauer and sigmund (1998) provide four-cycle criteria for potential games and zero-sum games (see theorem 11.2.2 and exercise 11.2.9 in hofbauer and sigmund, 1998) .",{'shapley'},0.0,,,,,
155,41191245.0,"at stage-i, we use a person's image as input and disentangle the information into three main factors, namely foreground, background and pose. each disentangled factor is modeled by embedding features through a reconstruction network.",{'person image'},1.0,part-of,"disentangled factors are a part of a person's image that includes the foreground, background and pose, each modeled by embedding features through a reconstruction network.",disentangle factor,person image,no
156,41191245.0,"image generation from noise. the ability of generative models, such as gans [7] , adversarial autoencoders (aae)",{'image generation'},1.0,is-a,gans is a generative model.,gans,generative model,no
157,41191245.0,,,,is-a,adversarial autoencoders (aae) are a generative model.,adversarial autoencoders,generative model,no
158,41191245.0,,,,compare,gans is like adversarial autoencoders (aae) in that they are generative models.,gans,adversarial autoencoders (aae),yes
159,41191245.0,"traditional image generation works use gans [7] or vaes [12] to map a distribution generated by noise z to the distribution of real data. convolutional vaes and aaes [21] have shown how to transform an autoencoder into a generator, but in this case, it is rather difficult to train the mapping function for complex data distributions, such as person images (as also mentioned in arae-gan [11] ).",{'gan'},1.0,used-for,gans are used for traditional image generation works to map a distribution generated by noise z to the distribution of real data. ,gans,traditional image generation works to map a distribution generated by noise z to the distribution of real data,no
160,41191245.0,,,,type-of,person images are a type of complex data distribution.,person image,complex data distribution,no
161,41191245.0,disentangled image generation. few papers have already tried to work towards this direction by learning a disentangled representation of the input image.,{'image generation'},0.0,,,,,
162,166228643.0,"under this setting, without access to expert actions, approaches like dagger, aggrevate, gail, and behaviour cloning by definition cannot work. although recently several model-based approaches, which learn an inverse model that predicts the actions taken by an expert (torabi et al., 2018; edwards et al., 2018) based on successive observations, have been proposed, these approaches can suffer from covariate shift (ross et al., 2011) .",{'dagger'},0.0,,,,,
163,53286630.0,"in our framework, the upscaling of a low-resolution depth image is guided by a corresponding intensity images; we formulate it as a cost aggregation problem with the guided filter. however, the guided filter does not make full use of the information of the depth image.",{'guide filter'},0.0,,,,,
164,53286630.0,"however, the guided filter does not make full use of the information of the depth image. since depth images have quite sparse gradients, it inspires us to regularize the gradients for improving depth upscaling results.",{'guide filter'},0.0,,,,,
165,53286630.0,"depth image upsampling is a quite challenging task. specifically, due to the limited spatial resolution, the lr image loses or distorts fine structures of the hr image.",{'depth image upsampling'},1.0,is-a,depth image upsampling is a task that is challenging because the lr image loses or distorts fine structures of the hr image due to the limited spatial resolution.,depth image upsampling,task,no
166,53286630.0,"in this work, we present a novel method that combines the advantages of guided filter and the energy minimization model to compute an accurate high-resolution output from a lr depth map with the corresponding hr intensity image. in recent years, the guided filter as a new edgepreserving technology has also been employed in a wide range of applications, such as image deconvolution [12] , image super-resolution [13] and image fusion [14] .",{'guide filter'},1.0,is-a,"the guided filter is a new edgepreserving technology that has been employed in a wide range of applications, such as image deconvolution, image super-resolution and image fusion.",guide filter,new edgepreserving technology,no
167,53286630.0,"in recent years, the guided filter as a new edgepreserving technology has also been employed in a wide range of applications, such as image deconvolution [12] , image super-resolution [13] and image fusion [14] . since the depth image is smooth, it is appropriate to be processed by guided filter which has shown to be effective for textureless image.",{'guide filter'},1.0,is-a,"the guided filter is a new edgepreserving technology that has been employed in a wide range of applications, such as image deconvolution, image super-resolution and image fusion and has shown to be effective for textureless image.",guide filter,new edgepreserving technology,no
168,53286630.0,"since the depth image is smooth, it is appropriate to be processed by guided filter which has shown to be effective for textureless image. and the guided filter can effectively fuse images from different sensors.",{'guide filter'},1.0,used-for,the guided filter is used for textureless image and to fuse images from different sensors.,guide filter,textureless image and to fuse images from different sensors,no
169,53286630.0,"and the guided filter can effectively fuse images from different sensors. inspired by these, we attempt to use guided filter for depth image upsampling.",{'guide filter'},1.0,used-for,the guided filter is used to fuse images from different sensors.,guide filter,fuse images from different sensors,no
170,53286630.0,"inspired by these, we attempt to use guided filter for depth image upsampling. however, the properties of depth images are not fully exploited by the guided filter.","{'guide filter', 'depth image upsampling'}",0.0,,,,,
171,53286630.0,the rest of the paper is organized as follows: section 2 briefly introduces related work in depth image upsampling. section 3 describes the proposed approach which considers the guided filter and the low gradient regularization.,{'depth image upsampling'},0.0,,,,,
172,10219018.0,this property opposes to the universal verifiability of classical digital signatures and allows the signer to have a control on the spread of his signatures. further applications of undeniable signatures such as licensing software or auctions were proposed in the literature.,{'universal verifiability'},0.0,,,,,
173,10219018.0,"in the next section, we recall the definition of an undeniable signature. section 3 is devoted to the security model of an undeniable signature.",{'undeniable signature'},0.0,,,,,
174,62155510.0,later they extracted helper data from the biometric and used it in decoding of fuzzy vault. they also proved that the fuzzy vault can be used in biometric template protection.,{'fuzzy vault'},1.0,used-for,the fuzzy vault can be used for biometric template protection.,fuzzy vault,biometric template protection,no
175,62155510.0,they also proved that the fuzzy vault can be used in biometric template protection. they also have suggested that multiple fingerprints from same finger and multiple biometrics could be used for the greater security of fuzzy vault.,{'fuzzy vault'},1.0,used-for,the fuzzy vault can be used for biometric template protection.,fuzzy vault,biometric template protection,no
176,7532885.0,"wyner [5] and ozarow and wyner [6] exploit the channel for secret communications but in a com- pletely different setting. their results are existence proofs; in particular, it was shown that for given noisy channels (one for the communicators and one for an eavesdropper) there exists a rate below which perfect secrecy is possible.",{'wyner'},0.0,,,,,
177,126494268.0,"afterwards, the original largescale multiobjective optimization problem is reformulated into a low-dimensional single-objective optimization problem. in the reformulated problem, the decision space is reconstructed by the weight variables and the objective space is reduced by an indicator function.",{'multiobjective optimization problem'},1.0,part-of,"the objective space is a part of the largescale multiobjective optimization problem reformulated into a low-dimensional single-objective optimization problem, that is reduced by an indicator function.",objective space,largescale multiobjective optimization problem reformulated into a low-dimensional single-objective optimization problem,no
178,126494268.0,"it can be observed that nsga-ii performs much better in the early stage of the evolution. meanwhile, nsga-ii performs overall better than moea/dva and similarly to lmea, which implies that the decision variable analysis adopted by moea/dva and lmea do not work effectively.",{'nsga'},0.0,,,,,
179,131780081.0,this scenario is known as the relay channel and it has been widely studied in the literature. cover and el gamal [4] determined bounds on the capacity of the degraded relay channel considering different relaying strategies.,{'relay channel'},0.0,,,,,
180,131780081.0,cover and el gamal [4] determined bounds on the capacity of the degraded relay channel considering different relaying strategies. this seminal paper was the starting point for extensive research on the design of suitable transmission schemes for the relay channel.,"{'el gamal', 'degraded relay channel'}",0.0,,,,,
181,131780081.0,"this seminal paper was the starting point for extensive research on the design of suitable transmission schemes for the relay channel. as a result, several relaying strategies have been proposed for the relay channel such as amplify-and-forward (af) [5] , [6] , compression-and-forward (cf)",{'relay channel'},0.0,,,,,
182,11943976.0,"a counterintuitive property of the mcn is that every layer of the mcn has an extremely strong controllability, which significantly differs from ordinary scale-free networks requiring a large fraction of driver nodes. to steer the network in a layer, the minimum number of driver nodes is nothing but the reminder r that is negligible as compared to the network size.",{'driver node'},0.0,,,,,
183,11943976.0,"a counterintuitive property of the mcn is that every layer of the mcn has an extremely strong controllability, which significantly differs from ordinary scale-free networks requiring a large fraction of driver nodes. to steer the network in a layer, the minimum number of driver nodes is nothing but the number of reminder r that is negligible as compared to the network size.",{'driver node'},0.0,,,,,
184,55790256.0,"later, oinas-kukkonen and harjumaa (2009) define persuasive systems as designed to ""reinforce, change or shape attitudes or behaviors or both without using coercion or deception"" (p. 486). using such systems is based on voluntariness (oinas-kukkonen, 2013; karppinen & oinas-kukkonen, 2013 ); if the system were to be effective, it would have to have enough persuasive power.",{'persuasive system'},1.0,is-a,"persuasive systems are systems that are designed to ""reinforce, change or shape attitudes or behaviors or both without using coercion or deception"".",persuasive system,system,no
185,55790256.0,,,,based-on,"persuasive systems are based on voluntariness in that if the system were to be effective, it would have to have enough persuasive power.",persuasive system,voluntariness,yes
186,204976915.0,"ignoring such relationship polarities between users and treating signed social networks as unsigned ones would result in over-estimation of positive influence spread, thereby leading to lower-quality solutions. social influence can be further complicated when competing campaigns are simultaneously spread over a signed social network.",{'sign social network'},0.0,,,,,
187,204976915.0,"social influence can be further complicated when competing campaigns are simultaneously spread over a signed social network. therefore, influence and opinion dynamics in a signed social network is a critical problem that, unfortunately, remains pretty much open.",{'sign social network'},1.0,part-of,opinion dynamics are a part of a signed social network that remain a critical problem because social influence can be complicated when competing campaigns are simultaneously spread over a signed social network.,opinion dynamic,sign social network,yes
188,204976915.0,,,,compare,opinion dynamics are like influence in that they are a part of a signed social network and remain a critical problem because social influence can be complicated when competing campaigns are simultaneously spread over a signed social network.,opinion dynamic,influence,no
189,204976915.0,"for example, people's opinions change over time; thus, activation based models, such as independent cascade (ic) and linear threshold (lt) models [15] are less appropriate in political contexts. second, in reality a signed social network might not be perfectly balanced [18] , that is, there may not exist a partition v 1 , v 2 of the node set v , such that all edges with v 1 and v 2 are positive and all edges across v 1 and v 2 are negative.","{'linear threshold', 'independent cascade'}",1.0,type-of,independent cascade is a type of activation based model that is less appropriate in political contexts because people's opinions change over time.,independent cascade,activation based model,no
190,204976915.0,,,,type-of,linear threshold is a type of activation based model that is less appropriate in political contexts because people's opinions change over time.,linear threshold,activation based model,no
191,204976915.0,,,,compare,independent cascade is like linear threshold in that they are types of activation based models that are less appropriate in political contexts because people's opinions change over time.,independent cascade,linear threshold,yes
192,204976915.0,,,,is-a,"a signed social network is a network that might not be perfectly balanced in reality, that is, there may not exist a partition v 1 , v 2 of the node set v , such that all edges with v 1 and v 2 are positive and all edges across v 1 and v 2 are negative.",sign social network,network,no
193,35927349.0,"however, fundamental forms of reasoning such as containment and equivalence of relation paths have hitherto been ignored. intuitively, two relation paths are equivalent if they share the same extension, i.e., set of source and target entity pairs.",{'relation path'},0.0,,,,,
194,1838296.0,"the first one is conformance of a process to an artifact system, which consists in checking whether a given process generates the correct lifecycle for the various artifacts and, more generally, whether it satisfies all intra-artifact and inter-artifact constraints. the second reasoning task is process verification, that is checking whether a process (over an artifact system) verifies general dynamic properties of interest.",{'artifact system'},0.0,,,,,
195,202888695.0,"in this work, we focus on explicit cf as well as ctr prediction. in explicit cf user ratings for particular items are directly observed and therefore it can be formally framed as a matrix completion problem [9, 10, 11, 22] .",{'ctr prediction'},0.0,,,,,
196,202888695.0,"in this work, we focus on explicit cf as well as ctr prediction. in explicit cf user ratings for particular items are directly observed and therefore it can be formally framed as a matrix completion problem [9, 10, 11, 22] .",{'ctr prediction'},0.0,,,,,
197,5323444.0,"most other node structural similarity measures [1, 12, 22, 43, 44, 45] are variants of simrank. though simrank seems to capture the intuition of the above recursive structural similarity, its random walk matching does not satisfy the basic graph automorphism condition.",{'simrank'},0.0,,,,,
198,5323444.0,"though simrank seems to capture the intuition of the above recursive structural similarity, its random walk matching does not satisfy the basic graph automorphism condition. for example, in figure 1 , though s1 and j1 are automorphically equivalent, simrank assigns them a value of 0.226.",{'simrank'},0.0,,,,,
199,32372358.0,jabref provides an opportunity for us to study code churn and code ownership in the light of architectural violations in a project that use sacc. our overall aim is to determine whether there is a difference in code churn and ownership between files that do and do not contain architectural violations as well as how architectural refactoring impacts files with violations.,{'code churn'},0.0,,,,,
200,32372358.0,our overall aim is to determine whether there is a difference in code churn and ownership between files that do and do not contain architectural violations as well as how architectural refactoring impacts files with violations. we are curious if there is a link between architectural violations and code churn or code ownership and seek to answer the following research questions:,{'code churn'},0.0,,,,,
201,32372358.0,"hall and munson introduce the concept of code churn and code delta to understand the evolution of software metrics [11] . they define code churn as the amount of change of a metric (for example the amount of source code lines added, modified, or deleted) and code delta as the difference of a metric between two revisions of a system, respectively.",{'code churn'},1.0,is-a,"code churn is a concept that is defined as the amount of change of a metric (for example the amount of source code lines added, modified, or deleted).",code churn,concept,no
202,32372358.0,,,,compare,"code churn is like code delta, except code churn is the amount of change of a metric (for example the amount of source code lines added, modified, or deleted) and code delta is the difference of a metric between two revisions of a system, respectively.",code churn,code delta,no
203,202764268.0,"instead of treating data augmentation as a policy in reinforcement learning [5] , we formulate manipulation as a reward function and use efficient stochastic gradient descent to learn the manipulation parameters. text data augmentation has also achieved impressive success, such as contextual augmentation [25, 49] , back-translation [42] , and manual approaches [48, 2] .","{'reinforcement learning', 'datum augmentation', 'reward function'}",1.0,type-of,contextual augmentation is a type of text data augmentation that has achieved impressive success.,contextual augmentation,text data augmentation,no
204,202764268.0,,,,compare,"contextual augmentation is like [back-translation, manual approaches] in that they are types of text data augmentation that have achieved impressive success.",contextual augmentation,"back-translation, manual approaches",no
205,36102915.0,"at hardware level, random placement was proposed in [31] to enable the use of set-associative caches for mbpta. [45] and [16] discuss the reliability of 980 pwcet estimates obtained with mbpta on top of random placement caches.",{'mbpta'},0.0,,,,,
206,14370263.0,"we hence investigate island multicast that integrates ip multicast with overlay distribution. in island multicast, hosts within the same island use ip multicast for data distribution.",{'island multicast'},0.0,,,,,
207,11169209.0,"more vision tasks, such as object detection or semantic segmentation, can be accelerated greatly using the pruned model. in this paper, we propose a unified framework, namely thinet (stands for ""thin net""), to prune the unimportant filters to simultaneously accelerate and compress cnn models in both training and test stages with minor performance degradation.","{'object detection', 'prune model', 'semantic segmentation'}",1.0,type-of,object detection is a type of vision task that can be accelerated greatly using the pruned model.,object detection,vision task,no
208,11169209.0,,,,type-of,semantic segmentation is a type of vision task that can be accelerated greatly using the pruned model.,semantic segmentation,vision task,no
209,11169209.0,,,,compare,object detection is like semantic segmentation in that they are types of vision tasks that can be accelerated greatly using the pruned model.,object detection,semantic segmentatio,yes
210,11169209.0,,,,is-a,thinet is a unified framework that is proposed to prune the unimportant filters to simultaneously accelerate and compress cnn models in both training and test stages with minor performance degradation.,thinet,unified framework,no
211,11169209.0,"in this paper, we propose a unified framework, namely thinet (stands for ""thin net""), to prune the unimportant filters to simultaneously accelerate and compress cnn models in both training and test stages with minor performance degradation. with our pruned network, some important transfer tasks such as object detection or fine-grained recognition can run much faster (both training and inference), especially in small devices.",{'thinet'},1.0,is-a,thinet is a unified framework that is proposed to prune the unimportant filters to simultaneously accelerate and compress cnn models in both training and test stages with minor performance degradation.,thinet,unified framework,no
212,11169209.0,,,,type-of,"object detection is a type of transfer task that can run much faster (both training and inference) with the thinet pruned network, especially in small devices.",object detection,transfer task,no
213,11169209.0,,,,compare,"object detection is like fine-grained recognition in that they are types of transfer tasks that can run much faster (both training and inference) with the thinet pruned network, especially in small devices.",object detection,fine-grained recognition,no
214,11169209.0,"we evaluate thinet on the large-scale imagenet classification task. thinet achieves 3.31 flops reduction and 16.63 compression on vgg-16 model [28] , with only 0.52% top-5 accuracy drop.",{'thinet'},0.0,,,,,
215,11169209.0,"thinet can still reduce 2.26 flops and 2.06 parameters with roughly 1% top-5 accuracy drop. to explore the limits of thinet, we show that the original vgg-16 model can even be pruned into 5.05mb, but still preserving alexnet level accuracy.",{'thinet'},0.0,,,,,
216,11169209.0,"in addition, we also explore the performance of thinet in a more practical task, i.e., transfer learning on small-scale datasets. experimental results demonstrate the excellent effectiveness of thinet, which achieves the best trade-off between model size and accuracy.",{'thinet'},0.0,,,,,
217,11169209.0,"we propose a simple yet effective framework, namely thinet, to simultaneously accelerate and compress cnn models. thinet shows significant improvements over existing methods on numerous tasks.",{'thinet'},1.0,is-a,thinet is a simple yet effective framework that simultaneously accelerates and compresses cnn models and shows significant improvements over existing methods on numerous tasks.,thinet,simple yet effective framework,no
218,67855449.0,"supervised learning of single-view geometry supervised learning based methods for depth prediction rely upon availability of sensory depth data, such as that acquired by the kinect sensor and lidar sensor (for indoor and outdoor scenes respectively). one of the early learning based methods to achieve reasonable success in single image depth estimation is make3d",{'depth prediction'},0.0,,,,,
219,67855449.0,"[29] adapted the densenet architecture for several regression tasks including depth prediction, and showed that jointly predicting pixelwise depths and confidences, where the output is modeled as a multivariate gaussian distribution, improves depth estimation results. [34] combined shallow convolutional networks with regression forests to reduce the need for large training sets.","{'densenet architecture', 'depth prediction'}",1.0,type-of,"depth prediction is a type of regression task that the densenet architecture is adapted for by jointly predicting pixelwise depths and confidences, where the output is modeled as a multivariate gaussian distribution, to improve depth estimation results.",depth prediction,regression task,
220,67855449.0,"methods like [7] [8] proposed to combine the advantages of using both spatial and temporal information available in kitti sequences for improving depth predictions while solving the scaling ambiguity issue. a large body of work since have been targeted to use better loss functions, in particular the image alignment loss [5] , [9] propose to use ssim and gans respectively for image matching.",{'depth prediction'},1.0,is-a,gans is a loss function that can be used for image matching.,gans,loss function,no
221,67855449.0,,,,is-a,ssim is a loss function that can be used for image matching.,ssim,loss function,no
222,67855449.0,,,,compare,gans is like ssim in that they are loss functions that can be used for image matching.,gans,ssim,yes
223,67855449.0,"a large body of work since have been targeted to use better loss functions, in particular the image alignment loss [5] , [9] propose to use ssim and gans respectively for image matching. enforcing temporal consistency in the predicted depths by aligning the backprojected depth maps via differentiable approximation of icp has been studied in [37] .","{'gan', 'ssim'}",1.0,is-a,gans is a loss function that can be used for image matching.,gans,loss function,no
224,67855449.0,,,,is-a,ssim is a loss function that can be used for image matching.,ssim,loss function,no
225,67855449.0,,,,compare,gans is like ssim in that they are loss functions that can be used for image matching.,gans,ssim,yes
226,67855449.0,"similar to [6] , [11] [12] learn depth from monocular sequences using a self-supervised photometric loss but additionally they compute surface normals from the predicted depths using a weighted mean cross product [38] . they propose to regularize the inverse depths and the normals computed from the depth predictions simultaneously.",{'predict depth'},0.0,,,,,
227,67855449.0,they propose to regularize the inverse depths and the normals computed from the depth predictions simultaneously. we believe that this is redundant and a separate normal prediction is beneficial then relying on the normals to be computed from predicted depth.,"{'inverse depth', 'depth prediction'}",0.0,,,,,
228,9804248.0,"transactional memory (tm) allows programmers to group memory operations into transactions that appear to execute atomically: no transaction sees the intermediate states of other transactions executing in other threads, and all work of a transaction either happens (the transaction commits) or not (the transaction aborts). transactional memory is more abstract than locking, and avoids many of the problems encountered with locks, such as deadlock, priority inversion, convoying, pre-emption, and reduced concurrency.",{'transactional memory'},1.0,compare,"transactional memore is an alternative to locking that is more abstract and avoids many of the problems encountered with locks, such as deadlock, priority inversion, convoying, pre-emption, and reduced concurrency.",transactional memory,locking,no
229,9804248.0,,,,is-a,"transactional memory (tm) is a model that allows programmers to group memory operations into transactions that appear to execute atomically: no transaction sees the intermediate states of other transactions executing in other threads, and all work of a transaction either happens (the transaction commits) or not (the transaction aborts).`",transactional memory,model,no
230,10721564.0,the category boxes used by fuzzy artmap with complement coding are comparable to hyperrectangles. hyperrectangles in fuzzy artmap with complement coding grow monotonically during learning; their maximum size is bounded by a vigilance parameter.,{'fuzzy artmap'},1.0,part-of,a vigilance parameter is a part of the fuzzy artmap in that it bounds the maximum size of the hyperrectangles with complement coding that grow monotonically during learning.,vigilance parameter,fuzzy artmap,yes
231,7309650.0,"a multifaceted evaluation strategy including automatic metrics, human evaluation and linguistic analysis, was implemented to perform evaluation experiments. the results of the evaluation have shown a slight improvement in the output quality of machine translation with spatial knowledge.",{'human evaluation'},0.0,,,,,
232,15569516.0,"testing figure 1 : while training, given a dataset consisting of pairs of images and corresponding texts (here captions), we learn models for the two tasks (im2text and text2im) using a joint image-text representation. while testing for im2text, given a query image, we perform retrieval on a collection of only textual samples using the learned model.",{'im2text'},0.0,,,,,
233,4710028.0,"in contrast, we propose to use soft attention, which uses multiple contexts for prediction, with different weights for each. in previous works which used non-neural techniques, soft attention is not even expressible.",{'soft attention'},1.0,is-a,"soft attention is a technique that uses multiple contexts for prediction, with different weights for each, and is not even expressible in previous works which used non-neural techniques.",soft attention,technique,no
234,52896778.0,"in this paper, we propose a machine learning approach that uses deep networks to estimate af recurrence by predicting shape descriptors directly from mri images, with no image pre-processing involved. we also propose a novel data augmentation scheme to effectively train a deep network in a limited training data setting.",{'deep network'},0.0,,,,,
235,52896778.0,"in this paper, we propose an automated approach that rely on deep networks to generate a patient-specific landmark-based anatomy representation directly from 3d cardiac mri, hence, negating any need for manual pre-processing and segmentation. however, a deep network cannot be viably trained with limited training samples -a typical situation in this application and in many similar medical imaging applications.",{'deep network'},1.0,is-a,a deep network is a model that cannot be viably trained with limited training samples -a typical situation in many medical imaging applications.,deep network,model,no
236,52896778.0,"however, a deep network cannot be viably trained with limited training samples -a typical situation in this application and in many similar medical imaging applications. to mitigate this problem, we propose a novel data augmentation scheme that generates more statistically feasible data, and hence enable training the deep network while reducing the associated risk of overfitting.",{'deep network'},1.0,is-a,a deep network is a model that cannot be viably trained with limited training samples -a typical situation in many medical imaging applications.,deep network,model,no
237,46488544.0,"we design, implement, and evaluate covertcast, a censorship circumvention system that broadcasts the content of popular websites in real-time, encrypted video streams on common live-streaming services such as youtube. covertcast does not require any modifications to the streaming service and employs the same protocols, servers, and streaming software as any other user of the service.",{'covertcast'},1.0,is-a,"covertcast is a censorship circumvention system that broadcasts the content of popular websites in real-time, encrypted video streams on common live-streaming services such as youtube, does not require any modifications to the streaming service and employs the same protocols, servers, and streaming software as any other user of the service.",covertcast,censorship circumvention system,no
238,46488544.0,"we design, implement, and evaluate covertcast, a new system that distributes digital content (in particular, news websites) by encoding it as a sequence of images and transmitting these images to users via a livestreaming service such as youtube. the design and implementation of covertcast are service-agnostic and can be deployed with any live-streaming service.",{'covertcast'},1.0,is-a,"covertcast is a new system that distributes digital content (in particular, news websites) by encoding it as a sequence of images and transmitting these images to users via a livestreaming service such as youtube.",covertcast,new system,no
239,46488544.0,,,,is-a,covertcast is a new system that has a service-agnostic design and implementation and can be deployed with any live-streaming service.,covertcast,new system,no
240,46488544.0,"we evaluate covertcast by loading various news sites, which is reportedly the most frequent use of censorship circumvention software [4] . although covertcast takes a relatively long time to load a page (one to two minutes for most news sites we examined), this latency is due to ensuring that the streaming service broadcasts images without visual artifacts and is not an inherent limitation of covertcast.",{'covertcast'},1.0,type-of,"covertcast is a type of censorship circumvention software that takes a relatively long time to load a page, due to ensuring that the streaming service broadcasts images without visual artifacts and is not an inherent limitation of covertcast.",covertcast,censorship circumvention software,no
241,46488544.0,"although covertcast takes a relatively long time to load a page (one to two minutes for most news sites we examined), this latency is due to ensuring that the streaming service broadcasts images without visual artifacts and is not an inherent limitation of covertcast. we also evaluate covertcast under various network conditions, including low bandwidth and high packet-drop rates.",{'covertcast'},0.0,,,,,
242,50782258.0,"[30] propose a summarization model based on a bidirectional long short term memory (bilstm) framework, which is trained on videos with annotated importance scores for keyframe selection. they additionally apply determinantal point process (dpp) to enhance the diversity of the chosen keyframes.",{'summarization model'},0.0,,,,,
243,211296666.0,"this suggests that the abstractions learned by these models can transfer across languages, even when trained on monolingual data. in this paper, we investigate whether such generalization potential applies to other modalities, such as vision: does bert contain abstractions that generalize beyond text?",{'monolingual datum'},0.0,,,,,
244,211296666.0,"in this paper, we investigate whether such generalization potential applies to other modalities, such as vision: does bert contain abstractions that generalize beyond text? we introduce bert-gen, an architecture for text generation based on bert, able to leverage on either mono-or multi-modal representations.",{'bert'},0.0,,,,,
245,211296666.0,"unsupervised pre-trained language models learning unsupervised textual representations that can be applied to downstream tasks is a widely investigated topic in the literature. text representations have been learned at different granularities: words with word2vec (mikolov et al., 2013) , sentences with skipthought , paragraphs with paragraphvector (le & mikolov, 2014) and contextualized word vectors with elmo (peters et al., 2018) .",{'downstream task'},1.0,is-a,contextualized word vectors are text representations that have been learned with elmo.,contextualize word vector,text representation,no
246,211296666.0,,,,type-of,elmo is a type of unsupervised pre-trained language model that can learn contextualized word vectors that can be applied to downstream tasks.,elmo,unsupervised pre-trained language model,no
247,211296666.0,"text representations have been learned at different granularities: words with word2vec (mikolov et al., 2013) , sentences with skipthought , paragraphs with paragraphvector (le & mikolov, 2014) and contextualized word vectors with elmo (peters et al., 2018) . other methods leverage a transfer-learning approach by fine-tuning all parameters of a pre-trained model on a target task, a paradigm which has become mainstream since the introduction of bert (devlin et al., 2019) .","{'contextualize word vector', 'elmo'}",1.0,is-a,contextualized word vectors are text representations that have been learned with elmo.,contextualize word vector,text representation,no
248,211296666.0,,,,is-a,elmo is a method that learns contextualized word vectors.,elmo,method,no
249,211296666.0,,,,compare,bert is an alternative to elmo that leverages a transfer-learning approach by fine-tuning all parameters of a pre-trained model on a target task.,bert,elmo,yes
250,211296666.0,"other methods leverage a transfer-learning approach by fine-tuning all parameters of a pre-trained model on a target task, a paradigm which has become mainstream since the introduction of bert (devlin et al., 2019) . bert alleviates the problem of the uni-directionality of most language models (i.e. where the training objective aims at predicting the next word) by proposing a new objective called masked language model (mlm).","{'fine - tuning', 'bert'}",1.0,is-a,"bert is a language model that leverages a transfer-learning approach by fine-tuning all parameters of a pre-trained model on a target task, and alleviates the problem of the uni-directionality of most language models (i.e. where the training objective aims at predicting the next word) by proposing a new objective called masked language model (mlm).",bert,language model,yes
251,211296666.0,,,,is-a,masked language model is an objective of bert.,masked language model,objective of bert,no
252,211296666.0,"bert alleviates the problem of the uni-directionality of most language models (i.e. where the training objective aims at predicting the next word) by proposing a new objective called masked language model (mlm). under mlm, some words, that are randomly selected, are masked; the training objective aims at predicting them.","{'language model', 'bert', 'masked language model'}",1.0,is-a,"bert is a language model that alleviates the problem of the uni-directionality of most language models (i.e. where the training objective aims at predicting the next word) by proposing a new objective called masked language model (mlm), where some words, that are randomly selected, are masked; the training objective aims at predicting them.",bert,language model,yes
253,211296666.0,,,,is-a,mlm is the masked language model that is an objective of bert to alleviate the problem of the uni-directionality of most language models by masking some randomly selecting words and aiming to predict them.,mlm,masked language model,yes
254,211296666.0,,,,is-a,masked language model is an objective of bert that masks some randomly selecting words and aims to predict them to alleviate the problem of the uni-directionality of most language models.,masked language model,objective of bert,no
255,211296666.0,"multi-modal language models following the successful application of bert (devlin et al., 2019) , and its derivatives, across a great majority of nlp tasks, several research efforts have focused on the design of multi-modal versions of bert. videobert (sun et al., 2019a) , a joint video and text model, is pre-trained on a huge corpus of youtube videos, and applied to action classification and video captioning tasks on the youcook ii dataset (zhou et al., 2018b) .","{'bert', 'nlp task'}",1.0,is-a,"videobert is a joint video and text model that is pre-trained on a huge corpus of youtube videos, and applied to action classification and video captioning tasks on the youcook ii dataset.",videobert,joint video and text model,no
256,211296666.0,,,,compare,videobert is used for action classification.,videobert,action classification,yes
257,211296666.0,"however, its visual counterpart, visual question generation (vqg), has been comparatively less explored than standard well-known multi-modal tasks such as visual question answering (vqa) (gao et al., 2015; xu & saenko, 2016; ren et al., 2015; ma et al., 2016) , visual dialog (das et al., 2017; , or image captioning (vinyals et al., 2015; yan et al., 2016; karpathy & li, 2015) .","{'visual question', 'visual question generation'}",1.0,compare,"visual question generation is an alternative to [visual question answering, visual dialog, image captioning] that has been comparatively less explored.",visual question generation,"visual question answering, visual dialog, image captioning",yes
258,211296666.0,,,,is-a,visual dialog is a standard well-known multi-modal task.,visual dialog,standard well-known multi-modal task,no
259,211296666.0,,,,compare,"visual dialog is like [visual question answering, image captioning] in that they are standard well-known multi-modal tasks.",visual dialog,"visual question answering, image captioning",no
260,211296666.0,"suitable data for the vqg task can come from standard image datasets on which questions have been manually annotated, such as v qg coco , v qg f lickr , v qg bing (mostafazadeh et al., 2016) , each consisting of 5000 images with 5 questions per image. alternatively, vqg samples can be derived from visual question answering datasets, such as v qa1.0 (antol et al., 2015) , by ""reversing"" them (taking images as inputs and questions as outputs).",{'coco'},1.0,is-a,"v qg coco is a standard image dataset that questions have been manually annotated on, consisting of 5000 images with 5 questions per image.",coco,standard image dataset,no
261,211296666.0,,,,compare,"v qg coco is a like [v qg f lickr, v qg bing] in that they are standard image datasets that questions have been manually annotated on, each consisting of 5000 images with 5 questions per image.",coco,"v qg f lickr, v qg bing",no
262,13991804.0,"they demonstrated that the user cooperation diversity provides a significant improvement in the achievable rates, over the traditional mac with non-cooperating transmitters. at this point, we would like to mention that, there has been a tremendous amount of work on several aspects of user cooperation diversity within the last decade, and the surge still continues.",{'user cooperation diversity'},0.0,,,,,
263,10119997.0,"ner is a sub-branch of information extraction, whose inception goes back to the sixth message understanding conference (muc-6) (grishman and sundheim, 1996) . ner aims at recognising and labelling (multi)words, as names of people, things, places, etc.",{'ner'},1.0,is-a,"ner is a sub-branch of information extraction that goes back to the sixth message understanding conference (muc-6) and aims at recognising and labelling (multi)words, as names of people, things, places, etc.",ner,sub-branch of information extraction,no
264,10119997.0,"ner aims at recognising and labelling (multi)words, as names of people, things, places, etc. since muc-6, ner has largely expanded, with several applications also on ancient languages (see, for example, depauw and van beek, 2009) .",{'ner'},1.0,is-a,"ner is a method that aims at recognising and labelling (multi)words, as names of people, things, places, etc, and since muc-6, has largely expanded, with several applications also on ancient languages.",ner,method,no
265,9086181.0,"we believe that paraphrasing provides us with an option to expand training corpora and to enrich opinion sentences for polarity classif ication, which would alleviate the problem of data sparseness and lack of annotated corpora for training. at this point, our current study is also relevant to paraphrasing tasks, including paraphrase recognition, paraphrase extraction and paraphrase generation.",{'opinion sentence'},0.0,,,,,
266,2069424.0,"in this paper, we design aggregated path authentication schemes by combining two efficient cryptographic techniquessignature amortization and aggregate signatures. we propose six constructions for aggregated path authentication that substantially improve efficiency of s-bgp's path authentication on both speed and space criteria.",{'aggregate signature'},1.0,is-a,aggregate signature is an efficient cryptographic technique.,aggregate signature,efficient cryptographic technique,no
267,2069424.0,we propose six constructions for aggregated path authentication that substantially improve efficiency of s-bgp's path authentication on both speed and space criteria. our performance evaluation shows that the new schemes achieve such an efficiency that they may overcome the space obstacles and provide a real-world practical solution for bgp security.,{'aggregated path authentication'},1.0,used-for,aggregated path authentication is used to improve efficiency of s-bgp's path authentication on both speed and space criteria and may provide a real-world practical solution for bgp security.,aggregated path authentication,improve efficiency of s-bgp's path authentication on both speed and space criteria and may provide a real-world practical solution for bgp security,no
268,8816526.0,"this paper illustrates cgpms by integrating them into bayesdb (mansinghka et al., 2015a) , a probabilistic programming platform for data analysis. bayesdb demonstrated that the bayesian query language (bql) can express several tasks from multivariate statistics and probabilistic machine learning in a model-independent way.",{'bayesdb'},1.0,is-a,bayesdb is a probabilistic programming platform for data analysis that demonstrated that the bayesian query language (bql) can express several tasks from multivariate statistics and probabilistic machine learning in a model-independent way.,bayesdb,probabilistic programming platform for data analysis,no
269,8816526.0,"bayesdb demonstrated that the bayesian query language (bql) can express several tasks from multivariate statistics and probabilistic machine learning in a model-independent way. however this idea was illustrated by emphasizing that a domain-general baseline model builder based on crosscat (mansinghka et al., 2015b) , with limited support for plug-in models called ""foreign predictors"", provides good enough performance for common statistical tasks.",{'bayesdb'},0.0,,,,,
270,8816526.0,"however this idea was illustrated by emphasizing that a domain-general baseline model builder based on crosscat (mansinghka et al., 2015b) , with limited support for plug-in models called ""foreign predictors"", provides good enough performance for common statistical tasks. due to limitations in the underlying formalism of generative population models (gpms), which do not accept inputs and only learn joint distributions over observable variables, the paper did not provide an expressive modeling language for constructing a wide class of models applicable to different data analysis tasks, or for integrating domain-specific models built by experts into bayesdb.",{'crosscat'},0.0,,,,,
271,8816526.0,"it is helpful to contrast cgpms in bayesdb with other probabilistic programming formalisms such as stan (carpenter et al., 2015) . stan is a probabilistic programming language for specifying hierarchical bayesian models, with built-in algorithms for automated, highly efficient posterior inference.","{'bayesdb', 'stan'}",1.0,is-a,"stan is a probabilistic programming language that is used for specifying hierarchical bayesian models, with built-in algorithms for automated, highly efficient posterior inference.",stan,probabilistic programming language,no
272,24698940.0,"such network of fake osn accounts are also known as social bots, which are ""software-controlled osn accounts that mimic human users with malicious intentions"" [23] (p.46). social bots on twitter for either spam distribution or digital influence manipulation -including smf-have been known to be very efficient [23] .",{'social bot'},1.0,is-a,"social bots are software-controlled osn accounts that mimic human users with malicious intentions, and on twitter for either spam distribution or digital influence manipulation -including smf-have been known to be very efficient.",social bot,software-controlled osn account,no
273,7334090.0,"in this paper, we introduce a path-signature feature to an end-to-end text-independent writer-identification system with a deep convolutional neural network (dcnn). because deep models require a considerable amount of data to achieve good performance, we propose a data-augmentation method named dropstroke to enrich personal handwriting.",{'deep convolutional neural network'},0.0,,,,,
274,58094114.0,"the cnn has a wide range of applications in image processing [11] - [13] , and is good at creating spatial relations for pixel points in a local field of vision. the cnn has been adapted to analyze actions based on skeletal data by considering a matrix of sequences of a skeleton as an image [14] - [16] , and models spatial relationships.",{'cnn'},1.0,used-for,"cnn is used for a wide range of applications in image processing, and is good at creating spatial relations for pixel points in a local field of vision.",cnn,"wide range of applications in image processing, and is good at creating spatial relations for pixel points in a local field of vision",no
275,58094114.0,,,,used-for,"the cnn is used to analyze actions based on skeletal data by considering a matrix of sequences of a skeleton as an image, and models spatial relationships.",cnn,"analyze actions based on skeletal data by considering a matrix of sequences of a skeleton as an image, and models spatial relationships",no
276,8197919.0,"hasanuzzaman et al. proposed a banknote-recognition method based on speeded-up robust features (surf) features [11] . because it uses surf features, their method is robust to illumination and scaling changes, as well as image rotation.","{'surf', 'speed - robust feature'}",0.0,,,,,
277,210838998.0,"we are interested in community detection as this task can also be used to address the other two tasks. for node classification, a node can be assigned a label carried by its community members; and for link prediction, nodes of the same community are more likely to connect with each other as compared to nodes from different communities.",{'community detection'},1.0,is-a,"community detection is a task that can be used to address node classification, where a node can be assigned a label carried by its community members; and link prediction, where nodes of the same community are more likely to connect with each other as compared to nodes from different communities.",community detection,task,no
278,210838998.0,,,,is-a,node classification is a task that assigns a label carried by its community members to a node.,node classification,task,no
279,210838998.0,,,,compare,node classification is like link prediction in that community detection can be used to address them.,node classification,link prediction,no
280,8413138.0,"recent applications of ekeko include detecting suspicious aspect-oriented code [2] and detecting fine-grained evolutions of versioned code [3] . in this section, we demonstrate how ekeko also lends itself to providing the foundation for a program transformation tool.",{'ekeko'},1.0,part-of,ekeko is a part of the foundation for a program transformation tool that is used for applications such as detecting suspicious aspect-oriented code and detecting fine-grained evolutions of versioned code.,ekeko,foundation for a program transformation tool,no
281,18518199.0,"[2, 16] is a probabilistic variant of the relational hoare logic [4] for formal verification of the differential privacy of databases written in the programming language pwhile. in the logic aprhl, a parametric relational lifting, which relate probability distributions, play a central role to describe differential privacy in the framework of verification.",{'differential privacy'},0.0,,,,,
282,11033758.0,"this paper proposes distant supervision to help our models learn from unlabeled data. distant supervision is a weakly supervised learning paradigm, where a knowledge resource is exploited to gather (possible noisy) training instances (mintz et al., 2009) .",{'distant supervision'},1.0,is-a,distant supervision is a weakly supervised learning paradigm that exploits a knowledge resource to gather (possible noisy) training instances.,distant supervision,weakly supervised learning paradigm,no
283,11033758.0,"distant supervision is a weakly supervised learning paradigm, where a knowledge resource is exploited to gather (possible noisy) training instances (mintz et al., 2009) . our basic idea is to can use linguistic analysis of linked websites as a novel kind of distant supervision for learning how to analyze tweets.",{'distant supervision'},1.0,is-a,distant supervision is a weakly supervised learning paradigm that exploits a knowledge resource to gather (possible noisy) training instances.,distant supervision,weakly supervised learning paradigm,no
284,11033758.0,"our basic idea is to can use linguistic analysis of linked websites as a novel kind of distant supervision for learning how to analyze tweets. we explore standard sources of distant supervision, such as wiktionary for pos tagging, but we also propose to use the linked websites of tweets with urls as supervision.",{'distant supervision'},0.0,,,,,
285,16493979.0,"the purpose of these algorithms is to find the global solution, i.e. the solution that minimizes errors according to the diffusion model. nevertheless, noise in mri [11] , partial volume effect [1] and possible ambiguity induced by the diffusion model can lead to uncertainty in the tracking process.",{'diffusion model'},0.0,,,,,
286,67856119.0,"in the past few years, dnns have been widely applied to various computer vision tasks, e.g., image classification, object detection, action recognition. however, it is very difficult to deploy these deep models on resource-constrained mobile devices due to their high storage and computational cost.",{'object detection'},1.0,is-a,"object detection is a computer vision task that dnns have been widely applied to, which is very difficult to deploy on resource-constrained mobile devices due to their high storage and computational costs.",object detection,computer vision task,no
287,67856119.0,,,,compare,"object detection is like [image classification, action recognition] in that they are computer vision tasks that dnns have been widely applied to, which is very difficult to deploy on resource-constrained mobile devices due to their high storage and computational costs.",object detection,"image classification, action recognition",no
288,67856119.0,"[13] and binaryconnect [10] in which authors explicitly constrained the weights to either +1 or 1 during propagations. these two methods achieve decent performance on small datasets including mnist and cifar-10, yet they suffer from significant accuracy drop on challenging datasets such as ilsvrc-12",{'binaryconnect'},1.0,is-a,"binaryconnect is a method that has achieved decent performance on small datasets including mnist and cifar-10, yet suffers from significant accuracy drop on challenging datasets such as ilsvrc-12.",binaryconnect,method,no
289,67856119.0,,,,is-a,mnist is a small dataset that has been used for binaryconnect.,mnist,small dataset,no
290,67856119.0,the ternary weight network (twn) [12] introduced zero as a third quantized value and was the first method that achieved decent results on the ilsvrc-12 dataset. trained ternary quantization (ttq),{'ternary weight network'},1.0,is-a,the ternary weight network (twn) is a method that introduced zero as a third quantized value and was the first method that achieved decent results on the ilsvrc-12 dataset.,ternary weight network,method,no
291,15062731.0,abstract: proxy signature allows an original signer to delegate his/her signing capability to a proxy signer such that the proxy signer can sign messages on behalf of the original signer. blind signature allows a user to have a given message signed by the signer without revealing any information about the message.,{'proxy signer'},1.0,used-for,a proxy signer is used to sign messages on behalf of the original signer.,proxy signer,sign messages on behalf of the original signer,no
292,15062731.0,,,,used-for,blind signature is used to allow a user to have a given message signed by the signer without revealing any information about the message.,blind signature,allow a user to have a given message signed by the signer without revealing any information about the message,no
293,15062731.0,"proxy signatures and blind signatures are regarded as two important types of digital signatures. precisely, proxy signatures enable one party (original signer) to delegate his/her signing capability to another party (proxy signer) such that the proxy signer can sign messages on behalf of the original signer.",{'blind signature'},1.0,compare,blind signatures are like proxy signatures in that they are regarded as two important types of digital signatures.,blind signature,proxy signature,no
294,15062731.0,,,,type-of,proxy signers are a part of proxy signatures that enable one party (original signer) to delegate his/her signing capability to another party (proxy signer) such that the proxy signer can sign messages on behalf of the original signer.,proxy signer,proxy signature,no
295,15062731.0,,,,type-of,bling signatures are a type of digital signature.,blind signature,digital signature,no
296,15062731.0,"precisely, proxy signatures enable one party (original signer) to delegate his/her signing capability to another party (proxy signer) such that the proxy signer can sign messages on behalf of the original signer. blind signatures enable one party (user) to have a message signed by another party (signer) in such a way that the signer can not learn any information of the signed message.",{'proxy signer'},1.0,type-of,proxy signers are a part of proxy signatures that enable one party (original signer) to delegate his/her signing capability to another party (proxy signer) such that the proxy signer can sign messages on behalf of the original signer.,proxy signer,proxy signature,no
297,15062731.0,,,,type-of,blind signatures are a type of signature that enable one party (user) to have a message signed by another party (signer) in such a way that the signer can not learn any information of the signed message.,blind signature,signature,no
298,15062731.0,"blind signatures enable one party (user) to have a message signed by another party (signer) in such a way that the signer can not learn any information of the signed message. the concepts of proxy signature and blind signature were firstly introduced by mambo [1] and chaum [2] , in 1996 and 1983 respectively.",{'blind signature'},1.0,type-of,blind signatures are a type of signature that enable one party (user) to have a message signed by another party (signer) in such a way that the signer can not learn any information of the signed message.,blind signature,signature,no
299,49269122.0,"the coprime array makes it possible to sample the spatial signals in a sparse way, and consequently various useful properties can be obtained. recently, doa estimation for multiple sources with a coprime array has been extensively studied [5] - [11] .",{'coprime array'},0.0,,,,,
300,208821488.0,"[33] who proposed an effective lazy learning algorithm based on a data gravitation model for multi-label learning. in this algorithm, each data instance is regarded as an atom within a data gravitation model, which led to sound results in multi-label learning.",{'multi - label learning'},0.0,,,,,
301,208821488.0,"section 3 briefly reviews multi-label learning, the neighborhood information entropy, and the neighborhood conditional mutual information. section 4 introduces the sliding window scheme, the feature repulsion loss, and hence the details of our proposed streaming feature selection algorithm with dynamic sliding windows and feature repulsion loss (sf-dsw-frl) method for multi-label feature selection.",{'multi - label learning'},0.0,,,,,
302,169034493.0,"results: here we present count corrector (coco), a read assignment pipeline that takes into account the multitude of overlapping and repetitive genes in the transcriptome of higher eukaryotes. coco uses a modified annotation file that highlights nested genes and proportionally distributes multimapped reads between repeated sequences.",{'coco'},1.0,is-a,count corrector (coco) is a read assignment pipeline that takes into account the multitude of overlapping and repetitive genes in the transcriptome of higher eukaryotes and uses a modified annotation file that highlights nested genes and proportionally distributes multimapped reads between repeated sequences.,coco,read assignment pipeline,no
303,6674405.0,"model-based language specification has applications in the implementation of language processors, the design of domain-specific languages, model-driven software development, data integration, text mining, natural language processing, and corpus-based induction of models. model-based language specification decouples language design from language processing and, unlike traditional grammar-driven approaches, which constrain language designers to specific kinds of grammars, it needs general parser generators able to deal with ambiguities.",{'model - base language specification'},1.0,used-for,"model-based language specification is used for language processors, the design of domain-specific languages, model-driven software development, data integration, text mining, natural language processing, and corpus-based induction of models. ",model - base language specification,"language processors, the design of domain-specific languages, model-driven software development, data integration, text mining, natural language processing, and corpus-based induction of models",no
304,6674405.0,,,,is-a,"model-based language specification is an approach that decouples language design from language processing and, unlike traditional grammar-driven approaches, which constrain language designers to specific kinds of grammars, it needs general parser generators able to deal with ambiguities.",model - base language specification,approach,no
305,6674405.0,,,,compare,model-based language specification is an alternative to traditional grammar-driven approaches that needs general parser generators able to deal with ambiguities.,model - base language specification,traditional grammar-driven approaches,no
306,6674405.0,"model-based language specification decouples language design from language processing and, unlike traditional grammar-driven approaches, which constrain language designers to specific kinds of grammars, it needs general parser generators able to deal with ambiguities. in this paper, we propose fence, an efficient bottom-up parsing algorithm with lexical and syntactic ambiguity support that enables the use of model-based language specification in practice.",{'model - base language specification'},1.0,is-a,"model-based language specification is an approach that decouples language design from language processing and, unlike traditional grammar-driven approaches, which constrain language designers to specific kinds of grammars, it needs general parser generators able to deal with ambiguities.",model - base language specification,approach,no
307,6674405.0,,,,compare,model-based language specification is an alternative to traditional grammar-driven approaches that needs general parser generators able to deal with ambiguities.,model - base language specification,traditional grammar-driven approaches,no
308,18891857.0,"systems such as biopipe (hoon et al., 2003) , taverna (oinn et al., 2004) , galaxy (goecks et al., 2010) , geneprof (halbritter et al., 2011) or pegasys (shah et al., 2004) are easy to learn and use through their graphical user interface. others such as ruffus (goodstadt, 2010) , pwrake (tanaka and tatebe, 2010) , gxp make (taura et al., 2010) and bpipe (sadedin et al., 2012) use text-based definition of workflows, which can be advantageous: workflows can be edited without a graphical environment (e.g. directly on a remote server); and developers can collaborate on them through source code management tools.",{'taverna'},1.0,is-a,taverna is a system that is easy to learn and use through its graphical user interface.,taverna,system,no
309,18891857.0,,,,compare,"taverna is like [biopipe, galaxy, geneprof, pegasys] in that they are systems that are easy to learn and use through their graphical user interface.",taverna,"biopipe, galaxy, geneprof, pegasys",no
310,18891857.0,,,,is-a,"[ruffus, bpipe, pwrake] is a system that uses text-based definition of workflows, which can be advantageous: workflows can be edited without a graphical environment (e.g. directly on a remote server); and developers can collaborate on them through source code management tools.","ruffus, bpipe, pwrake",system,no
311,18891857.0,,,,compare,"ruffus is like [bpipe, pwrake] in that they are systems that use text-based definition of workflows, which can be advantageous: workflows can be edited without a graphical environment (e.g. directly on a remote server); and developers can collaborate on them through source code management tools.",ruffus,"bpipe, pwrake",yes
312,18891857.0,,,,compare,"[ruffus, bpipe, pwrake] is an alternative to taverna that is a system that uses text-based definition of workflows, which can be advantageous: workflows can be edited without a graphical environment (e.g. directly on a remote server); and developers can collaborate on them through source code management tools.","ruffus, bpipe, pwrake",taverna,yes
313,18891857.0,"others such as ruffus (goodstadt, 2010) , pwrake (tanaka and tatebe, 2010) , gxp make (taura et al., 2010) and bpipe (sadedin et al., 2012) use text-based definition of workflows, which can be advantageous: workflows can be edited without a graphical environment (e.g. directly on a remote server); and developers can collaborate on them through source code management tools. similar to pwrake and gxp make, snakemake is inspired by the build system gnu make (stallman and mcgrath, 1991) .","{'bpipe', 'ruffus', 'pwrake'}",1.0,is-a,"[ruffus, bpipe, pwrake] is a system that uses text-based definition of workflows, which can be advantageous: workflows can be edited without a graphical environment (e.g. directly on a remote server); and developers can collaborate on them through source code management tools.","ruffus, bpipe, pwrake",system,no
314,,,,,compare,"ruffus is like [bpipe, pwrake] in that they are systems that use text-based definition of workflows, which can be advantageous: workflows can be edited without a graphical environment (e.g. directly on a remote server); and developers can collaborate on them through source code management tools.",ruffus,"bpipe, pwrake",yes
315,,,,,compare,"snakemake is like [pwrake, gxp make] in that it is inspired by the build system gnu make.",snakemake,"pwrake, gxp make",yes
316,18891857.0,"in contrast to pwrake and gxp make, snakemake does not rely on any password-less ssh setup or custom server processes running on the cluster nodes. finally, snakemake is the first system to support file name inference with multiple named wildcards in rules.","{'snakemake', 'pwrake'}",1.0,compare,"snakemake is an alternative to [pwrake, gxp make] that does not rely on any password-less ssh setup or custom server processes running on the cluster nodes.",snakemake,"pwrake, gxp make",yes
317,18891857.0,,,,is-a,snakemake is a system that is the first to support file name inference with multiple named wildcards in rules.,snakemake,system,yes
318,15515374.0,"healthfinland 2 is a semantic health information publishing system that addresses these problems both from the publishers' and citizens' viewpoints. the concept and ideas behind healthfinland have been presented in [17, 18] .",{'healthfinland'},1.0,is-a,healthfinland 2 is a semantic health information publishing system that addresses problems both from the publishers' and citizens' viewpoints.,healthfinland,semantic health information publishing system,no
319,11684494.0,"it has been applied to various networks such as wireless local area networks (wlans), wireless sensor networks (wsns), cognitive radio networks (crns), and cognitive radio sensor networks (crsns). the implementation of cb in crsns needs special attention as primary radio (pr) nodes traffic must be protected from any harmful interference by cognitive radio (cr) nodes.",{'cognitive radio sensor network'},0.0,,,,,
320,11684494.0,"crsns also help to minimize the ism band interference and jamming [6] . crsns have been promising in various real world scenarios such as indoor sensing applications, multimedia applications, multi class heterogeneous sensing applications and real time surveillance applications [7] .",{'crsns'},1.0,used-for,"crsns can be used in various real world scenarios such as indoor sensing applications, multimedia applications, multi class heterogeneous sensing applications and real time surveillance applications.",crsns,"various real world scenarios such as indoor sensing applications, multimedia applications, multi class heterogeneous sensing applications and real time surveillance applications",no
321,11684494.0,"crsns have been promising in various real world scenarios such as indoor sensing applications, multimedia applications, multi class heterogeneous sensing applications and real time surveillance applications [7] . the dynamic spectrum access (dsa) has powered up these crsns through which they can provide required performance in the diversity of applications by changing the operating parameters dynamically and adapting according to the channels condition.",{'crsns'},1.0,used-for,"crsns can be used in various real world scenarios such as indoor sensing applications, multimedia applications, multi class heterogeneous sensing applications and real time surveillance applications.",crsns,"various real world scenarios such as indoor sensing applications, multimedia applications, multi class heterogeneous sensing applications and real time surveillance applications",no
322,11684494.0,"the dynamic spectrum access (dsa) has powered up these crsns through which they can provide required performance in the diversity of applications by changing the operating parameters dynamically and adapting according to the channels condition. in crsns, there are two types of users which utilize the spectrum.",{'crsns'},0.0,,,,,
323,11684494.0,"in crsns, there are two types of users which utilize the spectrum. the users which have a license to access the channel are called primary users (pr) and the unlicensed opportunistic users are called as cognitive users (cr).",{'crsns'},1.0,part-of,primary users are a part of crsns that have a license to access teh channel.,primary user,crsns,yes
324,14340467.0,"supercompilation is a program transformation technique that was first described by v. f. turchin in the 1970s. in supercompilation, turchin's relation as a similarity relation on call-stack configurations is used both for call-by-value and call-by-name semantics to terminate unfolding of the program being transformed.",{'supercompilation'},1.0,is-a,supercompilation is a program transformation technique that was first described by v. f. turchin in the 1970s.,supercompilation,program transformation technique,no
325,14340467.0,,,,part-of,turchin's relation is a part of supercompilation that as a similarity relation on call-stack configurations is used both for call-by-value and call-by-name semantics to terminate unfolding of the program being transformed.,turchin relation,supercompilation,yes
326,14340467.0,"supercompilation is a program transformation method based on fold/unfold operations [18, 17, 4] . given a program and its parameterized input configuration, a supercompiler partially unfolds the computation tree of the program on the input configuration and then tries to fold the tree back into a graph, which presents the residual program.",{'supercompilation'},1.0,based-on,supercompilation is based on fold/unfold operations.,supercompilation,fold/unfold operations,no
327,14340467.0,,,,is-a,"supercompilation is a program transformation method that, given a program and its parameterized input configuration, partially unfolds the computation tree of the program on the input configuration and then tries to fold the tree back into a graph, which presents the residual program.",supercompilation,program transformation method,no
328,14340467.0,"although turchin's relation is a useful tool that helps to solve both termination and generalization problems [20] (also see section 2 of this paper), the proof of its well-binariness given by v. turchin in [20] was presented in a semi-formal way. for the call-by-value semantics, the formal proof of this property of turchin's relation is given in [12] .",{'turchin relation'},1.0,is-a,"turchin's relation is a useful tool that helps to solve both termination and generalization problems, but the proof of its well-binariness was presented in a semi-formal way. ",turchin relation,useful tool,no
329,14340467.0,"turchin's relation. as a consequence, one can use turchin's relation in composition with the homeomorphic embedding relation (or any other relation, which is well-binary on the arbitrary sequences of terms) without the loss of well-binariness. 4 .",{'turchin relation'},1.0,used-for,"turchin's relation can be used in composition with the homeomorphic embedding relation (or any other relation, which is well-binary on the arbitrary sequences of terms) without the loss of well-binariness.",turchin relation,"in composition with the homeomorphic embedding relation (or any other relation, which is well-binary on the arbitrary sequences of terms) without the loss of well-binariness",no
330,13674581.0,we implement the encoder as a bidirectional recurrent neural network (bi-rnn) that goes over the search engine result page from top to bottom and from bottom to top and outputs contextual embeddings of the results. we implement the decoder as a recurrent neural network (rnn) with an attention mechanism.,{'bidirectional recurrent neural network'},0.0,,,,,
331,2084051.0,"moreover, these so-called sparse memory networks allow the information-theoretic community detection method known as the map equation to identify overlapping and nested flow modules in data from a range of different higher-order interactions such as multistep, multi-source, and temporal data. we derive the map equation applied to sparse memory networks and describe its search algorithm infomap, which can exploit the flexibility of sparse memory networks.",{'map equation'},1.0,is-a,"map equation is an information-theoretic community detection method that can identify overlapping and nested flow modules in data from a range of different higher-order interactions such as multistep, multi-source, and temporal data, and can exploit the flexibility of sparse memory networks with its search algorithm infomap.",map equation,information-theoretic community detection method,no
332,2084051.0,"to take advantage of higher-order network flows, researchers have therefore developed different representations, models, and community-detection algorithms that broadly fall into two research topics: memory networks and multilayer networks. in memory networks, higher-order network flows can represent multistep pathways such as flight itineraries [4, [13] [14] [15] , and in multilayer networks, they can represent temporal or multi-source data such as multiseason air traffic [8, 11, 16, 17] (figure 1b) .",{'memory network'},1.0,is-a,memory network is a research topic that can represent multistep pathways such as flight itineraries in higher-order network flows.,memory network,research topic,no
333,2084051.0,,,,compare,"memory networks are an alternative to multilayer networks, that can represent multistep pathways such as flight itineraries in higher-order network flows, opposed to temporal or multi-source data such as multiseason air traffic.",memory network,multilayer network,no
334,2084051.0,"in memory networks, higher-order network flows can represent multistep pathways such as flight itineraries [4, [13] [14] [15] , and in multilayer networks, they can represent temporal or multi-source data such as multiseason air traffic [8, 11, 16, 17] (figure 1b) . whereas memory networks can capture where flows move to depending on where they come from (figure 1e ), multilayer networks can capture where flows the system represented as an undirected network with nodes for the objects.",{'memory network'},1.0,is-a,memory networks are a network that can represent multistep pathways such as flight itineraries in higher-order network flows and can capture where flows move to depending on where they come from .,memory network,network,no
335,2084051.0,,,,compare,"memory networks are an alternative to multilayer networks, that can represent multistep pathways such as flight itineraries in higher-order network flows and can capture where flows move to depending on where they come from, opposed to representing temporal or multi-source data such as multiseason air traffic and capturing where flows the system represented as an undirected network with nodes for the objects.",memory network,multilayer network,no
336,2084051.0,"whereas memory networks can capture where flows move to depending on where they come from (figure 1e ), multilayer networks can capture where flows the system represented as an undirected network with nodes for the objects. the links show where flows coming in to the center node are constrained to go next; (e) the system represented as a memory network with physical nodes for the objects and state nodes for constraining flows along their links.",{'memory network'},1.0,compare,"memory networks are an alternative to multilayer networks, that can capture where flows move to depending on where they come from, opposed to where flows the system represented as an undirected network with nodes for the objects.",memory network,multilayer network,no
337,2084051.0,"in sparse memory networks, state nodes are not bound to represent, for example, previous steps in memory networks or layers in multilayer networks, but are free to represent abstract states such as lumped states [18] or states in multilayer memory networks, which we demonstrate with multistep and multiquarter air traffic data. in this way, a sparse memory network is a multiaspect graph with two aspects: the physical object and the flow state such as memory or layer [17] .",{'memory network'},1.0,is-a,a multiaspect graph is a sparse memory network that has two aspects: the physical object and the flow state such as memory or layer.,multiaspect graph,sparse memory network,no
338,35400066.0,"in this work, the graphs we consider have a special structure, in the form of a multiplex network, in the sense that each graph can be decomposed into a sequence of subgraphs, each of which corresponds to a layer of the network, and there exist interconnections linking nodes across different layers. we refer the reader to [20] for a mathematical formulation of multilayer networks, of which multiplex networks are a subset.",{'multiplex network'},1.0,part-of,"multiplex networks are a part of multilayer networks, that can decompose each graph into a sequence of subgraphs, each of which corresponds to a layer of the network, and there exist interconnections linking nodes across diferent layers.",multiplex network,multilayer network,no
339,35400066.0,"we refer the reader to [20] for a mathematical formulation of multilayer networks, of which multiplex networks are a subset. unlike a multilayer network, a multiplex network only allows for a single type of inter-layer connections via which any given node is connected only to its counterpart nodes in the other layers.",{'multiplex network'},1.0,part-of,multiplex networks are a part of multilayer networks.,multiplex network,multilayer network,no
340,35400066.0,,,,compare,"a multiplex network is an alternative to a multilayer network, that only allows for a single type of inter-layer connections via which any given node is connected only to its counterpart nodes in the other layers.",multiplex network,multilayer network,no
341,86843720.0,"fruit detection can be considered a special type of object detection that has many similarities with face detection task [11] - [13] . due to the advantage of high precision, cascaded convolutional networks (ccn) based face detection has acquired a remarkable breakthrough [14] , [15] .",{'object detection'},0.0,,,,,
342,553292.0,"this paper brings together two lines of research: implicit characterization of complexity classes by linear logic (ll) on the one hand, and computation over an arbitrary ring in the blum-shub-smale (bss) model on the other. given a fixed ring structure k we define an extension of terui's light affine lambda-calculus typed in lal (light affine logic) with a basic type for k. we show that this calculus captures the polynomial time function class fp(k): every typed term can be evaluated in polynomial time and conversely every polynomial time bss machine over k can be simulated in this calculus.",{'linear logic'},0.0,,,,,
343,553292.0,"linear logic (ll, [gir87] ) has provided one line of research in icc which fits in the proofs-as-programs paradigm: variants of ll with strict resource duplication disciplines such as light linear logic ( [gir98] , or its variant light affine logic, [asp98] ) or soft linear logic ( [laf04] ) capture deterministic polytime computation. light affine logic (lal) has in particular been studied using specific term calculi ([asp98, rov00]); among these, terui's light affine lambda-calculus enjoys good properties and has allowed to prove new properties on lal (like the strong polytime bound, see [ter01] ).","{'linear logic', 'light linear logic', 'soft linear logic'}",1.0,type-of,light linear logic is a type of linear logic that has strict resource duplication disciplines and captures deterministic polytime computation. ,light linear logic,linear logic,yes
344,553292.0,,,,type-of,light affine logic is a type of light linear logic that has strict resource duplication disciplines and captures deterministic polytime computation in the proofs-as-programs paradigm of linear logic. ,light affine logic,light linear logic,yes
345,553292.0,,,,type-of,soft linear logic is a type of light linear logic that has strict resource duplication disciplines and captures deterministic polytime computation in the proofs-as-programs paradigm of linear logic. ,soft linear logic,light linear logic,yes
346,29884254.0,"we present a real-time framework which allows interactive visualization of relativistic effects for time-resolved light transport. we leverage data from two different sources: real-world data acquired with an effective exposure time of less than 2 picoseconds, using an ultrafast imaging technique termed femto-photography, and a transient renderer based on ray-tracing.",{'time - resolve light transport'},1.0,is-a,femto-photography is an ultrafast imaging technique.,femto - photography,ultrafast imaging technique.,no
347,9317676.0,strong [2] uses robustness analysis for coverage of all executions from a given initial set by constructing bisimulation functions. currently this tool computes bisimulation functions for only linear or affine hybrid systems and does not handle nonlinear systems.,{'bisimulation function'},0.0,,,,,
348,11274975.0,"we consider the task of visual net surgery, in which a cnn can be reconfigured without extra data to recognize novel concepts that may be omitted from the training set. while most prior work make use of linguistic cues for such ""zero-shot"" learning, we do so by using a pictorial language representation of the training set, implicitly learned by a cnn, to generalize to new classes.",{'cnn'},0.0,,,,,
349,134602.0,current mac protocols do not eliminate idle listening. event-driven wake-up radios provide an opportunity to solve idle listening.,{'idle listening'},0.0,,,,,
350,36972568.0,"(feng and lapata, 2010) presented a probabilistic approach for automatic image annotation and text illustration, based on the assumption that images and their co-occurring textual data are generated by mixtures of latent topics. the problem of joint modelling the text and image components of multimedia documents (cross-modal retrieval), has been also studied by (rasiwasia et al., 2010) .",{'latent topic'},1.0,is-a,cross-modal retrieval is the problem of joint modelling the text and image components of multimedia documents.,cross - modal retrieval,problem of joint modelling the text and image components of multimedia documents,no
351,13756507.0,"however, existing methods compose deep learning architectures with the latent factor model ignoring a major class of cf models, neighborhood or memory-based approaches. we propose collaborative memory networks (cmn), a deep architecture to unify the two classes of cf models capitalizing on the strengths of the global structure of latent factor model and local neighborhood-based structure in a nonlinear fashion.",{'latent factor model'},1.0,is-a,collaborative memory networks (cmn) are a deep architecture that unifies the two classes of cf models capitalizing on the strengths of the global structure of latent factor model and local neighborhood-based structure in a nonlinear fashion.,collaborative memory network,deep architecture,no
352,13756507.0,"we propose collaborative memory networks (cmn), a deep architecture to unify the two classes of cf models capitalizing on the strengths of the global structure of latent factor model and local neighborhood-based structure in a nonlinear fashion. motivated by the success of memory networks, we fuse a memory component and neural attention mechanism as the neighborhood component.","{'collaborative memory network', 'latent factor model'}",1.0,is-a,collaborative memory networks (cmn) are a deep architecture that unifies the two classes of cf models capitalizing on the strengths of the global structure of latent factor model and local neighborhood-based structure in a nonlinear fashion.,collaborative memory network,deep architecture,no
353,13756507.0,"on the other hand, latent factor models capture the overall global structure of the user and item relationships but often ignore the presence of a few strong associations. the following weaknesses between the local neighborhood-based and global latent factor models lead to the development of hybrid models such as svd\+\+ [17] and generalizations such as factorization machines [24] which integrate both neighborhood-based approaches and latent factor models to enrich predictive capabilities.",{'latent factor model'},1.0,is-a,latent factor models are models that capture the overall global structure of the user and item relationships but often ignore the presence of a few strong associations.,latent factor model,model,no
354,13756507.0,,,,is-a,factorization machines are generalizations that integrate both neighborhood-based approaches and latent factor models to enrich predictive capabilities.,factorization machine,generalization,no
355,13756507.0,,,,part-of,latent factor models are a part of factorization machines that are integrated to enrich predictive capabilities.,latent factor model,factorization machine,no
356,13756507.0,,,,compare,latent factor models are like neighborhood-based approaches in that they are both integrated in factorization machines to enrich predictive capabilities.,latent factor model,neighborhood-based approach,no
357,13756507.0,"however, existing composite architectures incorporate the latent factor model ignoring the integration of neighborhood-based approaches in a nonlinear fashion. hence, we propose to represent the neighborhood-based component with a memory network [30, 35] to capture higher order complex relations between users and items.",{'latent factor model'},1.0,used-for,a memory network is used to represent the neighborhood-based component to capture higher order complex relations between users and items.,memory network,represent the neighborhood-based component to capture higher order complex relations between users and items,no
358,13756507.0,"convolutional neural networks (cnn) in recommendation systems have been used to capture localized item feature representations of music [31] , text [16, 29] and images [40] . previous methods represent text as bag-of-words representations, cnn overcomes this limitation by learning weight filters to identify the most prominent phrases within the text.","{'convolutional neural network', 'cnn'}",1.0,part-of,"convolutional neural networks (cnn) are a part of recommendation systems that have been used to capture localized item feature representations of music, text, and images, and overcome the limitation of representing text as bag-of-words representations by learning weight filters to identify the most prominent phrases within the text.",convolutional neural network,recommendation system,no
359,13756507.0,attention mechanisms have been recently explored in recommender systems. gong and zhang [6] perform hashtag recommendation with a cnn augmented with an attention channel to concentrate on the most informative (trigger) words.,{'attention mechanism'},0.0,,,,,
360,15329160.0,"other potential advantages of multiphase drives over the three-phase ones are [1] - [3] : 1) lower torque pulsations at high frequency; 2) reduced rotor harmonic currents for induction motor drives; 3) higher power per rms ampere ratio for the same machine volume; and 4) reduced harmonic content of the dc link current in the case of voltage source inverter (vsi)-fed drives. these aspects can justify the higher complexity of the multiphase drive in special custom applications, such as electrical ship propulsion, traction drives, electric/hybrid vehicles, high power pumps and aerospace [1] - [3] .",{'multiphase drive'},1.0,compare,multiphase drives are an alternative to three-phase drives that have 1) lower torque pulsations at high frequency; 2) reduced rotor harmonic currents for induction motor drives; 3) higher power per rms ampere ratio for the same machine volume; and 4) reduced harmonic content of the dc link current in the case of voltage source inverter (vsi)-fed drives.,multiphase drive,three-phase drive,no
361,15329160.0,,,,used-for,"multiphase drives are used in special custom applications, such as electrical ship propulsion, traction drives, electric/hybrid vehicles, high power pumps and aerospace.",multiphase drive,"special custom applications, such as electrical ship propulsion, traction drives, electric/hybrid vehicles, high power pumps and aerospace",no
362,1982750.0,"this paper is the continuation of works about analysis of secure watermarking schemes in the case of woa (watermarked only attack) framework. in previous works, two new bpsk spread-spectrum watermarking modulations, natural watermarking (nw) and circular watermarking (cw), have been proposed and have been shown to be more secure than classical modulations.",{'woa'},1.0,is-a,natural watermarking is a bpsk spread-spectrum watermarking modulation that has been shown to be more secure than classical modulations.,natural watermarking,bpsk spread-spectrum watermarking modulation,no
363,1982750.0,,,,compare,natural watermarking is like circular watermarking in that they are both bpsk spread-spectrum watermarking modulations that have been shown to be more secure than classical modulations.,circular watermarking,bpsk spread-spectrum watermarking modulation,no
364,28809978.0,"cyberguide is also a hand held electronic tourist guide system that supplies the user with context sensitive information [1] . initially cyberguide was developed for indoor tours at the gvu, and then it was extended to operate outdoors with gps.",{'cyberguide'},1.0,is-a,"cyberguide is a hand held electronic tourist guide system that supplies the user with context sensitive information, was initially developed for indoor tours at the gvu, and was extended to operate outdoors with gps.",cyberguide,hand held electronic tourist guide system,no
365,10716250.0,most of these results pursue controller design for sampled-data nonlinear systems based on the approximate discrete-time model of the system when sampling is sufficiently fast. it is important in the discretization approach to consider approximate discrete-time models simply because exact models are impossible or hard to obtain in most nonlinear systems of practical interest.,{'approximate discrete - time model'},0.0,,,,,
366,9689599.0,oblivious ram has been a perennial research topic since it was first introduced by goldreich [8] . oram allows for an access pattern to an adversarially controlled ram to be effectively obfuscated.,{'oblivious ram'},1.0,is-a,"oram is oblivious ram, that allows for an access pattern to an adversarially controlled ram to be effectively obfuscated.",oram,oblivious ram,yes
367,9689599.0,"oram allows for an access pattern to an adversarially controlled ram to be effectively obfuscated. conceptually, a client's data is stored in an encrypted and shuffled form in the oram, such that accessing pieces of data will not produce any recognizable pattern to an adversary which observes these accesses.",{'oram'},0.0,,,,,
368,9689599.0,"conceptually, a client's data is stored in an encrypted and shuffled form in the oram, such that accessing pieces of data will not produce any recognizable pattern to an adversary which observes these accesses. being a powerful cryptographic primitive, many additional uses besides storage can be envisioned for oram, such as an aid for homomorphic circuit evaluation, secure multi-party computation, and privacy-preserving data outsourcing.",{'oram'},1.0,is-a,"oram is a powerful cryptographic primitive that has many additional uses besides storage, such as an aid for homomorphic circuit evaluation, secure multi-party computation, and privacy-preserving data outsourcing.",oram,powerful cryptographic primitive,no
369,9689599.0,"being a powerful cryptographic primitive, many additional uses besides storage can be envisioned for oram, such as an aid for homomorphic circuit evaluation, secure multi-party computation, and privacy-preserving data outsourcing. given the advent of cloud computing and storage, and all their potential for abuse and violation of privacy, oram schemes are important for the real-world today.",{'oram'},1.0,is-a,"oram is a powerful cryptographic primitive that has many additional uses besides storage, such as an aid for homomorphic circuit evaluation, secure multi-party computation, and privacy-preserving data outsourcing.",oram,powerful cryptographic primitive,no
370,212725562.0,"results on mnist show that the nature of the trigger, training batch size, and dataset poisoning percentage all affect successful embedding of trojans. we test neural cleanse against the trojaned mnist models and successfully detect anomalies in the trained models approximately 18% of the time.",{'mnist'},0.0,,,,,
371,33249035.0,"google's tensor processing unit (tpu) has recently gained attention as a new and novel approach to increasing the efficiency and speed of neural network processing. according to google, the tpu can compute neural networks up to 30x faster and up to 80x more power efficient than cpu's or gpu's performing similar applications [6] .",{'tpu'},1.0,is-a,"tpu is google's tensor processing unit that has recently gained attention as a new and novel approach to increasing the efficiency and speed of neural network processing, and can compute neural networks up to 30x faster and up to 80x more power efficient than cpu's or gpu's performing similar applications, according to google.",tpu,google's tensor processing unit,no
372,33249035.0,"according to google, the tpu can compute neural networks up to 30x faster and up to 80x more power efficient than cpu's or gpu's performing similar applications [6] . the tpu excels because its hardware processing flow is specifically adapted to the inference problem it solves.",{'tpu'},1.0,compare,"the tpu is an alternative to the [cpu, gpu] that can compute neural networks up to 30x faster and up to 80x more power efficient than cpu's or gpu's performing similar applications, according to google, and it excels because its hardware processing flow is specifically adapted to the inference problem it solves.",tpu,"cpu, gpu",no
373,33249035.0,"the tpu excels because its hardware processing flow is specifically adapted to the inference problem it solves. it has been shown this inference task can be programmed to operate using 8 bit data; by optimizing arithmetic circuits to operate specifically on this narrow data width, the tpu has been able to operate faster by placing more multipliers in parallel (on a given die size), thereby breaking barriers set by traditional processors, such as cpus and gpus.",{'tpu'},1.0,is-a,"tpu is a processor that excels because its hardware processing flow is specifically adapted to the inference problem it solves, and it has been shown this inference task can be programmed to operate using 8 bit data; by optimizing arithmetic circuits to operate specifically on this narrow data width, the tpu has been able to operate faster by placing more multipliers in parallel (on a given die size), thereby breaking barriers set by traditional processors, such as cpus and gpus.",tpu,processor,no
374,33249035.0,,,,compare,the tpu is an alternative to traditional processors that has been able to operate faster by placing more multipliers in parallel (on a given die size).,tpu,traditional processor,no
375,33249035.0,"it has been shown this inference task can be programmed to operate using 8 bit data; by optimizing arithmetic circuits to operate specifically on this narrow data width, the tpu has been able to operate faster by placing more multipliers in parallel (on a given die size), thereby breaking barriers set by traditional processors, such as cpus and gpus. [5] it is the goal of this paper to disclose that a new form of general purpose arithmetic, having recently emerged, is an ideal fit to power a new generation of tpu.",{'tpu'},1.0,compare,the tpu is an alternative to traditional processors that has been able to operate faster by placing more multipliers in parallel (on a given die size).,tpu,traditional processor,no
376,33249035.0,"[5] it is the goal of this paper to disclose that a new form of general purpose arithmetic, having recently emerged, is an ideal fit to power a new generation of tpu. the new generation of tpu will have the advantage of supporting wide precision arithmetic, yet retain the awesome performance and energy efficiencies of the original google tpu.",{'tpu'},0.0,,,,,
377,1530286.0,"[25] showed that the parameterized complexity of balanced graph partitioning is w [1]-hard when parameterized by the combined parameters (k, ), where k is (an upper bound on) the cut size, and  is (an upper bound on) the number of resulting components after the cut. it was observed in [25] , however, that the employed fpt -reduction yields graphs of unbounded treewidth, which motivated the authors to ask about the parameterized complexity of the problem for graphs of bounded treewidth, and in particular for trees.",{'parameterize complexity'},0.0,,,,,
378,2017183.0,"to the best of our knowledge, this is the first work to propose sparse convolutional layers based on voting and l 1 regularisation for efficient processing of full 3d point clouds with cnns at scale. in particular, the contributions of this paper can be summarised as follows: 1) the construction of efficient convolutional layers as basic building blocks for cnn-based point cloud processing by leveraging a voting mechanism to exploit the inherent sparsity in the input data; 2) the use of rectified linear units and an l 1 sparsity penalty to specifically encourage data sparsity in the intermediate representations in order to exploit sparse convolutional layers throughout the entire cnn stack.",{'cnn'},0.0,,,,,
379,2017183.0,"in particular, the contributions of this paper can be summarised as follows: 1) the construction of efficient convolutional layers as basic building blocks for cnn-based point cloud processing by leveraging a voting mechanism to exploit the inherent sparsity in the input data; 2) the use of rectified linear units and an l 1 sparsity penalty to specifically encourage data sparsity in the intermediate representations in order to exploit sparse convolutional layers throughout the entire cnn stack. we demonstrate that vote3deep models with as few as three layers achieve state-of-the-art performance amongst purely laser-based approaches across all classes considered on the popular kitti object detection benchmark.",{'rectify linear unit'},1.0,is-a,vote3deep is a model that has been demonstrated to achieve state-of-the-art performance with as few as three layers amongst purely laser-based approaches across all classes considered on the popular kitti object detection benchmark.,vote3deep,model,no
380,2017183.0,we demonstrate that vote3deep models with as few as three layers achieve state-of-the-art performance amongst purely laser-based approaches across all classes considered on the popular kitti object detection benchmark. vote3deep models exceed the previous state of the art in 3d point cloud based object detection in average precision by a margin of up to 40% while only running slightly slower in terms of detection speed.,{'vote3deep'},1.0,is-a,vote3deep is a model that has been demonstrated to achieve state-of-the-art performance with as few as three layers amongst purely laser-based approaches across all classes considered on the popular kitti object detection benchmark.,vote3deep,model,no
381,2017183.0,,,,compare,"vote3deep is an alternative to previous state of the art models, that exceeds them in 3d point cloud based object detection in average precision by a margin of up to 40% while only running slightly slower in terms of detection speed.",vote3deep,previous state of the art model,no
382,2017183.0,"a number of works have attempted to apply cnns in the context of 3d point cloud data. a cnn-based approach in [7] obtains comparable performance to [5] on kitti for car detection by projecting the point cloud into a 2d depth map, with an additional channel for the height of a point from the ground.",{'cnn'},0.0,,,,,
383,2017183.0,a combination of three cnns is suggested in [15] . each cnn processes a different 2d plane and the three streams are joined in the last layer.,{'cnn'},0.0,,,,,
384,202772066.0,"the proposed approach performs task inference directly within the model, is able to dynamically expand to capture new concepts over its lifetime, and incorporates additional rehearsal-based techniques to deal with catastrophic forgetting. we demonstrate the efficacy of curl in an unsupervised learning setting with mnist and omniglot, where the lack of labels ensures no information is leaked about the task.",{'catastrophic forgetting'},0.0,,,,,
385,14727625.0,"abstract we introduce the discretizable distance geometry problem in r 3 (ddgp 3 ), which consists in a subclass of instances of the distance geometry problem for which an embedding in r 3 can be found by means of a discrete search. we show that the ddgp 3 is a generalization of the discretizable molecular distance geometry problem (dmdgp), and we discuss the main differences between the two problems.",{'distance geometry problem'},1.0,part-of,the discretizable distance geometry problem in r 3 (ddgp 3 ) is a part of a subclass of instances of the distance geometry problem for which an embedding in r 3 can be found by means of a discrete search.,distance geometry problem,subclass of instances of the distance geometry problem for which an embedding in r 3 can be found by means of a discrete search,no
386,14727625.0,,,,is-a,the discretizable distance geometry problem in r 3 (ddgp 3 ) is a generalization of the discretizable molecular distance geometry problem (dmdgp).,distance geometry problem,generalization of the discretizable molecular distance geometry problem (dmdgp),no
387,14727625.0,"we show that the ddgp 3 is a generalization of the discretizable molecular distance geometry problem (dmdgp), and we discuss the main differences between the two problems. we prove that the ddgp 3 is np-hard and we extend the branch & prune (bp) algorithm, previously used for the dmdgp, for solving instances of the ddgp 3 .",{'discretizable molecular distance geometry problem'},0.0,,,,,
388,14727625.0,"we prove that the ddgp 3 is np-hard and we extend the branch & prune (bp) algorithm, previously used for the dmdgp, for solving instances of the ddgp 3 . protein graphs may or may not be in dmdgp and/or ddgp 3 depending on vertex orders and edge density.",{'dmdgp'},0.0,,,,,
389,14727625.0,"protein graphs may or may not be in dmdgp and/or ddgp 3 depending on vertex orders and edge density. we show experimentally that as distance thresholds decrease, pdb protein graphs which fail to be in the dmdgp still belong to ddgp 3 , which means that they can still be solved using a discrete search.",{'dmdgp'},0.0,,,,,
390,51922320.0,"as a face sketch is usually generated by emphasizing the edges of the facial components (i.e., the shape) more than the spatial regions, dog seems to have potential to be utilized in that it increases the visibility of the edges of a face image regardless of lighting variations. as the shape appearance is obvious, a shape descriptor like histogram of oriented gradient (hog) can be employed to extract the features.",{'face sketch'},1.0,is-a,hog is a shape descriptor that stands for histogram of oriented gradient and can be employed to extract the features of a face as the shape appearance is obvious.,hog,shape descriptor,no
391,51922320.0,,,,used-for,hog is used for face sketch by extracting the features as the shape appearance is obvious.,hog,face sketch by extracting the features as the shape appearance is obvious,no
392,51922320.0,"[8] reported that the outer regions of forensic sketches are more salient than the inner regions. to reduce this influence, we introduce new reference points that are picked at the outer regions for face alignment.",{'forensic sketch'},0.0,,,,,
393,51882477.0,"however, object algebras do not capture delimited control and must be passed as an explicit parameter to programs. the design by biboudis et al. facilitates switching backend to execute a stream program, e.g., between push and pull streams.",{'object algebra'},0.0,,,,,
394,6568132.0,"finally, glav is a hybrid approach that combines both lav and gav approaches. gav is appropriate for query processing in stable environments.",{'gav'},1.0,used-for,gav is used for query processing in stable environments.,gav,query processing in stable environments,no
395,6568132.0,,,,compare,"gav is like lav in that they are approaches that are combined to create the hybrid approach, glav.",gav,lav,no
396,6737447.0,"the sketch engine [18] system provides a good comparison point to position terminoweb. overall, terminoweb's corpus analysis capabilities are simpler than the ones in sketch engine.",{'sketch engine'},1.0,is-a,"sketch engine is a system that provides a good comparison point to position terminoweb., which has simpler corpus analysis capabilities.",sketch engine,system,no
397,14828654.0,"our earlier work on process mining has primarily focused on process discovery, i.e., automatically constructing models describing knowledge extracted from event logs. in this paper, we present another approach supported by our prom framework and based on both a standard xml format and temporal logic.","{'process mining', 'process discovery'}",0.0,,,,,
398,14828654.0,"this tool has been developed in the context of the prom framework 1 . the prom framework offers a wide range of tools related to process mining, i.e., extracting information from event logs",{'prom framework'},1.0,compare,"the prom framework is like process mining in that it offers a wide range of tools related to process mining, i.e., extracting information from event logs.",prom framework,process mining,no
399,14828654.0,"this paper reports on the language developed to formulate properties in the context of event logs, the approach used to check these properties, the implementation in the prom framework, and the relation between this work and process discovery. it is important to note that process discovery is difficult in situations where a lot of flexibility is offered.",{'prom framework'},0.0,,,,,
400,14828654.0,section 2 introduces a running example that will be used to illustrate the concept of process mining. the prom framework and the xml format used to store event logs is presented in section 3.,{'process mining'},0.0,,,,,
401,14828654.0,"the work reported in this paper is closely related to earlier work on process mining, i.e., discovering a process model based on some event log. the idea of applying process mining in the context of workflow management was first introduced in [9] .",{'process mining'},1.0,is-a,process mining is discovering a process model based on some event log.,process mining,discovering a process model based on some event log,no
402,14828654.0,herbst and karagiannis also address the issue of process mining in the context of workflow management using an inductive approach [21] . they use stochastic task graphs as an intermediate representation and generate a workflow model described in the adonis modeling language.,{'process mining'},0.0,,,,,
403,14828654.0,"for more information on process mining we refer to a special issue of computers in industry on process mining [7] and a survey paper [6] . given the scope of this paper, we are unable to provide a complete listing of the many papers on process mining published in recent years.",{'process mining'},0.0,,,,,
404,14828654.0,in [27] zur muehlen describes the pisa tool which can be used to extract performance metrics from workflow logs. similar diagnostics are provided by the aris process performance manager (ppm) [23] .,{'workflow log'},0.0,,,,,
405,195346727.0,"for example, the ilsvrc imagenet classification top-5 error rate was decreased from 16.4% to 3.57% progressively, from alexnet to inception and inception. while a main advantage of convolutional neural network is that it makes traditional computer vision solutions end-to-end, the network architecture itself is hand-crafted.",{'ilsvrc'},0.0,,,,,
406,195346727.0,"with all blocks finished training, block list controller backward the early stop accuracy with redefined reward to the agent for updating q-value. we also use experience replay (lin 1993 ) and epsilon-greedy strategy (mnih et al. 2015) to help the agent choose higher performing blocks.",{'q - value'},0.0,,,,,
407,195346727.0,"the vgg uses only 3x3 convolutional layers stacked on top of each other in increasing depth as a simple block and reduce the volume size by using max pooling. the inception network uses a multilevel feature extractor strategy by computing 1x1, 3x3, and 5x5 convolutions within the same module of the network to construct the block structure.",{'increase depth'},0.0,,,,,
408,195346727.0,"the inception network uses a multilevel feature extractor strategy by computing 1x1, 3x3, and 5x5 convolutions within the same module of the network to construct the block structure. the resnet uses blocks with short cut connection that make it easy for network layers to represent the identity mapping, thus, the resnet can be stacked very deeply with a lot of layers.",{'inception network'},0.0,,,,,
409,195346727.0,"our approach is motivated by the recently proposed metaqnn (baker et al. 2016) , which uses a qlearning (watkins and dayan 1992) based meta-modeling to search architecture configurations. although metaqnn can yield good performance on small datasets such as cifar-10, cifar-100 (krizhevsky and hinton 2009) in a small search space, the direct use of metaqnn for architecture design on big datasets like imagenet (deng et al. 2009 ) is computationally expensive and the designed architecture is hard to generalize, because they search the whole neural network architecture space directly without block design.",{'dayan'},0.0,,,,,
410,15300703.0,"for predictive video coding, our results show that despite its higher compression efficiency, inter video coding always depletes much more energy than intra coding. therefore, we propose to use image compression based intra coding to improve energy efficiency in the predictive video coding paradigm.",{'intra coding'},1.0,compare,"intra coding is like inter video coding, except inter video coding always depletes much more energy than intra coding.",intra coding,inter video coding,no
411,,,,,compare,"intra coding is like inter video coding, except inter video coding has higher compression efficiency than intra coding.",intra coding,inter video coding,no
412,15300703.0,"therefore, we propose to use image compression based intra coding to improve energy efficiency in the predictive video coding paradigm. for distributed video coding, our results show that the wyner-ziv encoder has consistently better energy efficiency than the prism encoder.",{'intra coding'},0.0,,,,,
413,56740.0,it is shown how a 1-safe petri net and a requirement on the behaviour of the net can be translated into a logic program such that the bounded model checking problem for the net can be solved by computing stable models of the corresponding program. the use of the stable model semantics leads to compact encodings of bounded reachability and deadlock detection tasks as well as the more general problem of bounded model checking of linear temporal logic.,{'stable model'},1.0,used-for,stable model semantics is used for compact encodings of bounded reachability and deadlock detection tasks as well as the more general problem of bounded model checking of linear temporal logic.,stable model semantic,compact encodings of bounded reachability and deadlock detection tasks as well as the more general problem of bounded model checking of linear temporal logic,no
414,,,,,used-for,stable models are used to solve the bounded model checking problem for the net.,stable model,solve the bounded model checking problem for the net,no
415,56740.0,"much of this work has been based on the stable model semantics (gl88) and there are efficient systems dlv (http://www.dbai.tuwien.ac.at/proj/dlv/) and smodels (http://www.tcs.hut.fi/software/smodels/) for computing stable models of logic programs. using such an answer set programming system a problem is solved by writing a logic program whose stable models capture the solutions of the problem and then employing the system to compute a solution, i.e., a stable model.","{'stable model semantic', 'stable model'}",1.0,used-for,stable models are used to to capture the solutions of the problem and then employing the system to compute a solution.,stable models,capture the solutions of the problem and then employing the system to compute a solution,no
416,,,,,part-of,stable models are a part of logic programs.,stable models,logic programs,no
417,202763316.0,"some other methods [60, 22, 55, 13] follow similar pipelines but pool features extracted from these transformed patches to obtain invariant descriptors. gift also transforms images, but instead of using feature pooling, it applies group convolutions to further exploit the underlying structures of features extracted from the group of transformed images to retain distinctiveness of the resulting descriptors.",{'pool feature'},1.0,used-for,pool features are used to obtain invariant descriptors.,pool features,obtain invariant descriptors,no
418,,,,,compare,pool features is like group concolutions in that both are used to transform images.,pool features,group concolutions,yes
419,,,,,used-for,group convolution is used to exploit the underlying structures of features extracted from the group of transformed images to retain distinctiveness of the resulting descriptors.,group convolution,exploit the underlying structures of features extracted from the group of transformed images to retain distinctiveness of the resulting descriptors,no
420,202763316.0,"descriptors can also be directly extracted from feature maps of cnns [20, 11, 7] . however, cnns are not invariant to geometric transformations naturally.",{'feature map'},1.0,part-of,feature maps are a part-of cnns.,feature maps,cnns,yes
421,,,,,used-for,feature maps are used to extract descriptors.,feature maps,extract descriptors,no
422,202763316.0,"however, data augmentation cannot guarantee the invariance on unseen data. the universal correspondence network (ucn)",{'datum augmentation'},0.0,,,,,
423,202763316.0,the most related work is the group equivariant cnn [8] which uses group convolution and subgroup pooling to learn equivariant feature representations. it applies group convolutions directly on a large group which is the product of the translation group and the geometric transformation group.,{'group convolution'},1.0,used-for,group convolution is used to learn equivariant feature representations,group convolution,learn equivariant feature representations,no
424,15738974.0,"layer extraction problem is closely related to various other problems like image and video segmentation, image and video matting and interactive image editing. besides there are many applications of video segmentation including advanced video editing and object removal [21] .",{'matting'},0.0,,,,,
425,8948094.0,"although transactions can be implemented distributively, transactional memory is not a concept which can easily be generalized to the distributed setting. thus we see transactional memory as an orthogonal concept which may be integrated in our model to allow truly parallel tasks within a single cobox, for example.",{'transactional memory'},0.0,,,,,
426,8948094.0,"although transactions can be implemented distributively, transactional memory is not a concept which can easily be generalized to the distributed setting. thus we see transactional memory as an orthogonal concept which may be integrated in our model to allow truly parallel tasks within a single cobox, for example.",{'transactional memory'},0.0,,,,,
427,3633374.0,"third, novelty search ignores rewards altogether, while ours optimizes the policy using both the reward signals and the distance measure. a work parallel to ours similarly employs novelty search for exploration [19] .",{'novelty search'},1.0,used-for,novelty search is used for exploration.,novelty search,exploration,no
428,3633374.0,"this series of works aim to improve the performance of exploration under uncertain dynamics by optimizing a maximum entropy objective. in [28, 29] , the authors construct this objective function by augmenting the reward function with policy entropy of visited states.",{'maximum entropy objective'},0.0,,,,,
429,153314513.0,"(3) speculate but do not change microarchitectural state until the speculation can be resolved. the insight behind this idea is that speculative execution by itself is not the problem, rather the problem is speculative execution of instructions that should not have been executed to begin with, i.e., transient instructions.",{'microarchitectural state'},0.0,,,,,
430,153314513.0,"we compare both the non-speculative solutions and the ghost loads with the current state-of-the-art solution, invisispec [39] . we show that, even though ghost loads take a similar approach to invisispec, such a detailed performance evaluation is critical, as the added complexity introduced by invisispec is not supported by the performance achieved.",{'invisispec'},1.0,compare,invisispec is like ghost loads in that both have a similar approach.,invisispec,ghost loads,no
431,,,,,compare,invisispec is like ghost loads except invisispec had added complexity.,invisispec,ghost loads,no
432,153314513.0,"this work was inspired by the meltdown [24] and spectre [19] attacks published in the early 2018. however, as we explain in the introduction, our goal is not to solve just these attacks but to provide and evaluate a solution that prevents information leakage from cache memory accesses during speculative execution in general.",{'meltdown'},0.0,,,,,
433,153314513.0,"however, as we explain in the introduction, our goal is not to solve just these attacks but to provide and evaluate a solution that prevents information leakage from cache memory accesses during speculative execution in general. for meltdown and spectre, cpu vendors have promised specific solutions in future microcode updates.",{'speculative execution'},0.0,,,,,
434,7104902.0,"among those, we include the very well known google scholar 3 , the dblp database 4 and the citeseer x [8] search engine. arguing that those were only focusing on data exploration, a more recent generation including the microsoft academic search 5 and arnetminer [12] systems has highlighted the importance trend discovery and prediction, and proposed novel features for those purposes.",{'citeseer'},1.0,compare,"citeseer is like [google scholar, dblp database] in that they are search engines focusing on data exploration.",citeseer,"[google scholar, dblp database]",no
435,,,,,compare,"arnetminer is like microsoft academic search in that both systems have highlighted the importance of trend discovery and prediction, and proposed novel features for those purposes.",arnetminer,microsoft academic search,no
436,201718834.0,"thus, in this paper, we evaluate rnn, lstm, and gru to compare their performances on a reduced ted-lium speech data set. the results show that lstm achieves the best word error rates, however, the gru optimization is faster while achieving word error rates close to lstm.",{'lstm'},0.0,,,,,
437,201718834.0,"for example, a deep learning architecture called convolutional neural networks (cnns) are designed to emulate the behavior of visual cortex. cnns perform very well on any visual recognition tasks.",{'convolutional neural network'},1.0,type-of,convolutional neural network is a type-of deep learning architecture.,convolutional neural network,deep learning architecture,no
438,201718834.0,cnns perform very well on any visual recognition tasks. the cnn architecture consists of special layers called convolutional layers and pooling layers.,{'visual recognition task'},1.0,part-of,pooling layers are part of cnn architecture.,pooling layer,cnn architecture,no
439,,,,,part-of,convolutional layers are part of cnn architecture.,convolutional laye,cnn architecture,no
440,201718834.0,lstm prove to be effective in speech recognition tasks [7] where the special memory cells of lstms are used to identify long dependencies. slightly different than lstm is the gated recurrent unit (gru) introduced in 2014 [9] .,{'lstm'},1.0,compare,"lstm is like gate recurrent units, except for some differences.",lstm,gate recurrent unit',yes
441,201718834.0,"language modeling is key to many problems such as speech recognition, machine translation or image captioning. rnns and lstms have both been used to map sequences to sequences as well.","{'language modeling', 'machine translation'}",1.0,used-for,lstms are used for mapping sequences to seqences.,lstm,map sequences to sequences,no
442,,,,,part-of,"language modeling is part of [speech recognition, machine translation, image captioning]",language modeling,"[speech recognition, machine translation, image captioning]",yes
443,201718834.0,"our work is similar to baidu research [26] where a bidirectional rnn is used to speed up the speech recognition performance using gpu (graphics processing unit) parallelization. we have used a single gpu structure for our experiments to evaluate and compare the results of three recurrent networks, namely bidirectional rnn, bidirectional lstm, and bidirectional gru.",{'bidirectional rnn'},1.0,compare,"bidirectional rnn is like [bidirectional lstm, bidirectional gru], in that they are recurrent networks.",bidirectional rnn,"[bidirectional lstm, bidirectional gru]",no
444,18322761.0,"gene-set enrichment analysis (gsea; jiang and gentleman, 2007) can be a useful complement to the feature-by-feature analysis. given a collection of predefined sets of genes that share a common biological function or jointly participate in a specific biological process, gsea performs a statistical test for each gene set to determine whether the member genes are 'enriched' among the most statistically significant results.",{'gsea'},1.0,type-of,gsea is a type-of statistical test that determines whether member genes are 'enriched' among the most statistically significant results for each gene set in a collection of predefined sets of genes that share a common biological function or jointly participate in a specific biological process.,gsea,tatistical test that determines whether member genes are 'enriched' among the most statistically significant results for each gene set in a collection of predefined sets of genes that share a common biological function or jointly participate in a specific biological process,no
445,,,,,used-for,gsea is used to determine whether member genes are 'enriched' among the most statistically significant results for each gene set in a collection of predefined sets of genes that share a common biological function or jointly participate in a specific biological process.,gsea,determine whether member genes are 'enriched' among the most statistically significant results for each gene set in a collection of predefined sets of genes that share a common biological function or jointly participate in a specific biological process,no
446,6994401.0,abstract: a solution to the singularity problem is presented from the approach of the operational space formulation which involves both motion and force control. a brief summary of the operational space formulation and how singularity presents a problem is explained.,{'operational space formulation'},1.0,part-of,operational space formulation is part of a solution to the singularity problem.,operational space formulation,a solution to the singularity problem,no
447,119285256.0,the asvspoof 2017 challenge [18] was focused on the exploiting shortcomings of existing state-ofthe-art to detect replay attacks under diverse conditions. efforts have been made to investigate replay attacks on asv systems [12] [13] [14] [15] [16] [17] .,{'asvspoof 2017 challenge'},0.0,,,,,
448,119285256.0,"most of the presented works in asvspoof 2017 challenge used a combination of different features and classifiers to improve performance of replay detection system. the combined feature vector include constant q cepstral coefficients, mel-frequency cepstral coefficients, linear frequency cepstral coefficients, rectangular filter cepstral coefficients, perceptual linear predictive and deep features as front-ends [14, 15] .",{'asvspoof 2017 challenge'},1.0,part-of,constant q cepstral coefficients are part of the combined feature vector.,constant q cepstral coefficient,the combined feature vector,no
449,,,,,part-of,deep feature are part of the combined feature vector.,deep feature,the combined feature vector,no
450,,,,,used-for,constant q cepstral coefficients are used for front-ends.,constant q cepstral coefficient,front-ends,no
451,,,,,used-for,deep features are used for front-ends.,deep features,front-ends,no
452,119285256.0,"the combined feature vector include constant q cepstral coefficients, mel-frequency cepstral coefficients, linear frequency cepstral coefficients, rectangular filter cepstral coefficients, perceptual linear predictive and deep features as front-ends [14, 15] . magnitude-based features are widely used in replay attack detection, [14, 15] , and frequency modulation (fm) features have been used in speech recognition and speaker recognition [16, 17] .","{'constant q cepstral coefficient', 'deep feature'}",1.0,part-of,constant q cepstral coefficients are part of the combined feature vector.,constant q cepstral coefficient,combined feature vector,no
453,,,,,part-of,deep features are part of the combined feature vector.,deep features,combined feature vector,no
454,,,,,used-for,constant q cepstral coefficients are used for front-ends.,constant q cepstral coefficient,front-ends,no
455,,,,,used-for,deep features are usedfor front-ends.,deep features,front-ends,no
456,119285256.0,"magnitude-based features are widely used in replay attack detection, [14, 15] , and frequency modulation (fm) features have been used in speech recognition and speaker recognition [16, 17] . it has been demonstrated that replay attack introduces distortions in the spoofed speech [9, 10] .",{'replay attack detection'},0.0,,,,,
457,1417924.0,"in particular, many structural decomposition methods have been developed which are based on some notion of decomposition of the graph or hypergraph structure underlying a conjunctive query and which are used to define some notion of width. hypertree decompositions, which are used to define the hypertree-width of a cq, are a very powerful decomposition method (for details, see section 2)",{'structural decomposition method'},1.0,based-on,structural decomposition methods are based on some notion of decomposition of the graph or hypergraph structure underlying a conjunctive query and which are used to define some notion of width.,structural decomposition method,some notion of decomposition of the graph or hypergraph structure underlying a conjunctive query and which are used to define some notion of width,no
458,,,,,used-for,hypertree decompositions are used to define the hypertree-width of a cq.,hypertree decomposition,define the hypertree-width of a cq,yes
459,,,,,type-of,hypertree decomposition is a type of decomposition method.,hypertree decomposition,decomposition method,no
460,3738244.0,"novel types of sensors, called event cameras, offer great potential to overcome these issues. unlike standard cameras, which transmit intensity frames at a fixed framerate, event cameras, such as the dynamic vision sensor (dvs) [4] , only transmit changes of intensity.",{'event camera'},1.0,compare,"event camera are like standard cameras, except event cameras only transmit changes of intensity.",event camera,standard cameras,no
461,,,,,type-of,event cameras are a type of sensor.,event camera,sensor,no
462,3738244.0,"while there is a considerable body of literature investigating the use of standard cameras with an imu to perform state estimation, as well as recent work using an event camera with an imu, combining all three sensing modalities is yet an open problem. additionally, in the core application that we envision-flying autonomously a quadrotor with an event camera-there is no specific literature, although attempts to use an event camera for quadrotor flight can be traced to a single paper [10] , which is currently limited to vertical landing maneuvers.",{'event camera'},0.0,,,,,
463,139106327.0,"recently, transfer learning for tsc using deep neural networks has been explored, e.g., using rnns in [7] - [9] , and using cnns in [10] , [11] . these approaches pre-train a deep network on time series from diverse domains, and then either use it as a time series feature extractor for the target task as in timenet [7] , [8] , or use the pre-trained network to initialize the parameters of the neural network for the target task [9] - [11] .",{'cnn'},0.0,,,,,
464,139106327.0,"these approaches pre-train a deep network on time series from diverse domains, and then either use it as a time series feature extractor for the target task as in timenet [7] , [8] , or use the pre-trained network to initialize the parameters of the neural network for the target task [9] - [11] . when pre-training a deep network on time series from diverse domains, the rate of change of relevant information in time series can vary significantly across tasks and domains.",{'deep network'},0.0,,,,,
465,42358455.0,"perhaps even more promising and exciting, however, is recent work on using reo for programming multicore applications. when it comes to multicore programming, reo has a number of advantages over conventional programming languages, which feature a fixed set of low-level synchronization constructs (locks, mutexes, etc.).",{'reo'},1.0,used-for,reo is used for programming multicore applications.,reo,programming multicore applications,no
466,,,,,compare,"reo is like conventional programming languages, except reo does not feature a fixed set of low-level synchronization constructs (locks, mutexes, etc.).",reo,conventional programming languages,no
467,42358455.0,"essentially, this means that one can construct every reo connector expressible in terms of pa from instances of only two different primitive connectors. pourvatan et al. explored the decomposition of complete constraint automata [31] , an extension of constraint automata.",{'reo connector'},0.0,,,,,
468,53250058.0,there exist different criteria for this acquisition function () that basically tries to obtain a balanced tradeoff between exploitation of promising surfaces of the input space and exploration of unknown surfaces. some examples of acquisition functions are the expected improvement (ei),{'acquisition function'},0.0,,,,,
469,173188459.0,"for example, choosing the longest candidate answer gives the accuracy of 25.33% and 30.41% for movieqa [14] and tvqa [15] , respectively, where the random baseline is 20%. several multi-modal videoqa datasets have been introduced including movieqa [14] , pororoqa [20] , and tvqa [15] .","{'movieqa', 'tvqa'}",1.0,type-of,movieqa is a type-of multi-modal videoqa dataset.,movieqa,multi-modal videoqa datasets,no
470,,,,,type-of,tvqa is a type-of multi-modal videoqa datasets.,tvqa,multi-modal videoqa datasets,no
471,,,,,compare,"movieqa is like [tvqa, pororoqa] in that they are multi-modal videoqa datasets.",movieqa,"[tvqa, pororoqa]",yes
472,61153556.0,"typical sensors for object detection include cameras, radars, and lidars. in general, different sensors have their unique sensing properties, which brings each type of sensor an advantage over others when performing object detection.",{'object detection'},0.0,,,,,
473,24998483.0,"for these reasons, mcg may show ischemia-induced deviations from the normal direction of depolarization and repolarization with better accuracy than that of ecg (tsukada et al., 2000; yamada and yamaguchi, 2005) . mcg is affected less by conductivity variations in the body (lungs, muscles, and skin) than ecg.",{'mcg'},1.0,compare,"mcg is like ecg, except mcg is affected less by conductivity variations in the body (lungs, muscles, and skin).",mcg,ecg,no
474,,,,,compare,"mcg is like ecg, except mcg may show ischemia-induced deviations from the normal direction of depolarization and repolarization with better accuracy.",mcg,ecg,no
475,24998483.0,"mcg is affected less by conductivity variations in the body (lungs, muscles, and skin) than ecg. in addition, because mcg is a fully non-contact method, therefore problems in the skinelectrode contact as encountered in ecg are avoided (kanzaki et al., 2003; tsukada et al., 1999; tavarozzi et al., 2002) .",{'mcg'},1.0,compare,"mcg is like ecg, except mcg is affected less by conductivity variations in the body (lungs, muscles, and skin).",mcg,ecg,no
476,,,,,type-of,mcg is a type of non-contact method.,mcg,non-contact method,no
477,,,,,compare,"mcg is like ecg, except mcg avoids problems with skinelectrode contact.",mcg,ecg,no
478,195874058.0,"this justifies the extraction of high-level features to produce a vector representation of the structure and the semantics of the data [22] . traditional metrics can be used to compare vector representations: euclidean, cosine or mahalanobis.",{'vector representation'},0.0,,,,,
479,208212749.0,"however, the existing methods mostly perform image classification. in this paper we present an efficient method based on object detection to access deeper information the content of an image.",{'image classification'},0.0,,,,,
480,208212749.0,"however, researchers tend to use object detection to analyze images [6] [7] . studies that have used object detection in ecology so far perform on datasets featuring large objects on relatively low resolution copyright 978-1-7281-1817-8/19/$31.00 2019",{'object detection'},1.0,used-for,object deteted is used to analyze images.,object detection,analyze images,no
481,208212749.0,"to perform object detection, we rely on the use of deep learning and more precisely convolutional neural networks (cnn). here, we use the yolov3 model [9] , which is now a state of the art network for object detection.","{'object detection', 'cnn'}",1.0,used-for,cnns are used to perform object detection.,cnn,object detection,yes
482,67872943.0,"watershed algorithm [2] , which performs region base growing is based on the initial seed point and often encounters problems of over-segmentation. therefore, to obtain ideal results, watershed algorithm usually needs some complex post-processing methods.",{'watershed algorithm'},1.0,used-for,watershed algorithm is used for region base growing.,watershed algorithm,region base growing,no
483,67872943.0,"following the basic network architecture of u-net, we revised the down-sampling module to contain both residual module [14] as well as inception module [15] to extract more powerful features. residual connection has been proved to better represent image features, which has been first experimented on image classification task.",{'inception module'},1.0,used-for,inception module is used to extract more powerful features.,inception module,extract more powerful features,no
484,67872943.0,"inception module is well known for its computational efficiency while incorporating multiscale features with different kernel sizes, which has also been proved in image classification. so we included inception module together with residual block in down-sample part.","{'image classification', 'inception module'}",0.0,,,,,
485,192628427.0,"faster r-cnn's region proposal network (rpn) was already successfully applied to window detection in ""deepfacade"", see (liu et al., 2017) . the authors customized a deep convolutional neural network for pixel classification by choosing a problem specific loss function.",{'rpn'},1.0,used-for,"rpn is used for window detection in ""deepfacade"".",rpn,"window detection in ""deepfacade""",no
486,192628427.0,"then pixel based classifications are refined with bounding boxes, which are generated by the rpn of faster r-cnn (based on a vgg16 network (simonyan , zisserman, 2014) ). since faster r-cnn is used to refine an existing classification, the classification part of faster r-cnn is not used in their workflow.","{'fast r - cnn', 'rpn'}",1.0,part-of,rpn is part-of faster r-cnn.,rpn,fast r-cnn,yes
487,,,,,used-for,rpn is used to generate bounding boxes to refine pixel based classifications.,rpn,generate bounding boxes to refine pixel based classifications,no
488,192628427.0,"since faster r-cnn is used to refine an existing classification, the classification part of faster r-cnn is not used in their workflow. in contrast to this, we directly apply faster r-cnn to window and door segmentation as well as to classification.",{'fast r - cnn'},0.0,,,,,
489,192628427.0,"faster r-cnn and in (rahmani , mayer, 2018) an rpn is used for the segmentation of facades, see section 1. another improvement of faster r-cnn was proposed in (he et al., 2017) : ""masked r-cnn"" is a combination of two already existing state-of-the-art models, an rpn and a binary mask classifier.","{'fast r - cnn', 'rpn'}",1.0,part-of,rpn is part-of masked r-cnn.,rpn,masked r-cnn,no
490,192628427.0,"another improvement of faster r-cnn was proposed in (he et al., 2017) : ""masked r-cnn"" is a combination of two already existing state-of-the-art models, an rpn and a binary mask classifier. within bounding boxes, a classified object is labeled as it is the case with semantic segmentation.","{'fast r - cnn', 'rpn'}",1.0,part-of,rpn is part-of masked r-cnn.,rpn,masked r-cnn,no
491,192628427.0,"the authors translate multiview 2.5d depth maps into voxel representations, which serve as input for a cnn that classifies and autocompletes the 3d object. networks like pointnet\+\+ (qi et al., 2017) are capable of using 3d point clouds directly as an input.",{'cnn'},0.0,,,,,
492,192628427.0,"networks like pointnet\+\+ (qi et al., 2017) are capable of using 3d point clouds directly as an input. pointnet\+\+ is the successor of pointnet, which had issues if applied on data with a non-consistent point density.",{'pointnet\+\+'},1.0,based-on,pointnet\+\+ is based on pointnet.,pointnet\+\+,pointnet,yes
493,192628427.0,"pointnet\+\+ is the successor of pointnet, which had issues if applied on data with a non-consistent point density. pointnet\+\+ addresses this problem by extracting spherical point neighborhoods and applying pointnet on each hierarchical level.","{'pointnet\+\+', 'pointnet'}",1.0,based-on,pointnet\+\+ is based on pointnet.,pointnet\+\+,pointnet,yes
494,4556070.0,"this paper introduces a new open source platform for end-toend speech processing named espnet. espnet mainly focuses on end-to-end automatic speech recognition (asr), and adopts widely-used dynamic neural network toolkits, chainer and pytorch, as a main deep learning engine.",{'espnet'},1.0,used-for,espnet is used for end-toend speech processing.,espnet,end-toend speech processing,no
495,,,,,part-of,chainer is part-of espnet.,chainer,espnet,yes
496,,,,,part-of,pytorch is part-of espnet.,pytorch,espnet,yes
497,,,,,compare,"chianer is like pytorch, in that both are widely-used dynamic neural network toolkits.",pytorch,chainer,yes
498,4556070.0,"espnet mainly focuses on end-to-end automatic speech recognition (asr), and adopts widely-used dynamic neural network toolkits, chainer and pytorch, as a main deep learning engine. espnet also follows the kaldi asr toolkit style for data processing, feature extraction/format, and recipes to provide a complete setup for speech recognition and other speech processing experiments.","{'espnet', 'pytorch', 'chainer'}",1.0,part-of,chainer is part-of espnet.,chainer,espnet,yes
499,,,,,part-of,pytorch is part-of espnet.,pytorch,espnet,yes
500,,,,,compare,"chianer is like pytorch, in that both are widely-used dynamic neural network toolkits.",pytorch,chainer,yes
501,,,,,based-on,"espnet is based on the kaldi asr toolkit style for data processing, feature extraction/format, and recipes.",espnet,"the kaldi asr toolkit style for data processing, feature extraction/format, and recipes",no
502,4556070.0,"espnet also follows the kaldi asr toolkit style for data processing, feature extraction/format, and recipes to provide a complete setup for speech recognition and other speech processing experiments. this paper explains a major architecture of this software platform, several important functionalities, which differentiate espnet from other open source asr toolkits, and experimental results with major asr benchmarks.",{'espnet'},1.0,based-on,"espnet is based on the kaldi asr toolkit style for data processing, feature extraction/format, and recipes.",espnet,"the kaldi asr toolkit style for data processing, feature extraction/format, and recipes",no
503,4556070.0,"especially, these efforts have been driven by popular products including google voice search, amazon alexa, and apple siri and open source activities including kaldi [1] , htk [2] , sphinx [3] , julius [4] , rasr [5] in addition to general research activities. these open source toolkits include feature extraction, acoustic modeling based on a hidden markov model (hmm), gaussian mixture model, and deep neural network (dnn), and decoding 1 , and these enable us to use a full set of state-of-the-art asr research and development achievement.",{'kaldi'},1.0,compare,"kaldi is like to [htk, sphinx , julius, rasr], in that they are open source activities.",kaldi,"[htk, sphinx , julius, rasr]",no
504,,,,,type-of,acoustic modeling is a type-of open source toolkit.,acoustic modeling,open source toolkit,no
505,,,,,based-on,acoustic modeling is based on hidden markov mode.,acoustic modeling,hidden markov mode,no
506,4556070.0,"this paper describes a new open source toolkit named espnet (end-to-end speech processing toolkit), which aims to provide a neural end-to-end platform for asr and other speech processing. unlike the above open source tools based on hybrid dnn/hmm architecutres [7] , espnet provides a single neural network architecture to perform speech recognition in an end-to-end manner.",{'espnet'},1.0,type-of,espnet is a type of open source toolkit.,espnet,open source toolkit,no
507,,,,,used-for,espnet is used to perform speech recognition in an end-to-end manner.,espnet,perform speech recognition in an end-to-end manner,no
508,4556070.0,"unlike the above open source tools based on hybrid dnn/hmm architecutres [7] , espnet provides a single neural network architecture to perform speech recognition in an end-to-end manner. espnet adopts widely-used dynamic neural network toolkits, chainer [8] and pytorch [9] , as a main deep learning engine.",{'espnet'},1.0,used-for,espnet is used to perform speech recognition in an end-to-end manner.,espnet,perform speech recognition in an end-to-end manner,no
509,,,,,part-of,chainer is part-of espnet.,espnet,chainer,yes
510,4556070.0,"espnet adopts widely-used dynamic neural network toolkits, chainer [8] and pytorch [9] , as a main deep learning engine. espnet also follows the style of kaldi asr toolkit [1] for data processing, feature extraction/format, and recipes to provide a complete setup for speech recognition and other speech processing experiments.","{'espnet', 'chainer'}",1.0,part-of,chainer is part-of espnet.,espnet,chainer,yes
511,,,,,based-on,"espnet based on the style of kaldi asr toolkit [1] for data processing, feature extraction/format, and recipes.",espnet,"the style of kaldi asr toolkit [1] for data processing, feature extraction/format, and recipes",no
512,,,,,used-for,espnet used-for speech recognition and other speech processing experiments.,espnet,speech recognition and other speech processing experiments.,no
513,4556070.0,"espnet fully utilizes benefits of two major end-to-end asr implementations based on both connectionist temporal classification (ctc) [10, 11, 12] and attention-based encoder-decoder 1 language modeling is often performed by external language model toolkits, for example srilm [6] network [13, 14, 15, 16] . attention-based methods use an attention mechanism to perform alignment between acoustic frames and recognized symbols, while ctc uses markov assumptions to efficiently solve sequential problems by dynamic programming.",{'espnet'},1.0,part-of,attention mechanisms are part of attention-based methods.,attention mechanism,attention-based methods,no
514,,,,,used-for,attention mechanisms are used to perform alignment between acoustic frames and recognized symbols.,attention mechanism,perform alignment between acoustic frames and recognized symbols,no
515,4556070.0,"attention-based methods use an attention mechanism to perform alignment between acoustic frames and recognized symbols, while ctc uses markov assumptions to efficiently solve sequential problems by dynamic programming. espnet adopts hybrid ctc/attention end-to-end asr [17] , which effectively utilizes the advantages of both architectures in training and decoding.",{'attention mechanism'},1.0,part-of,attention mechanisms are part of attention-based methods.,attention mechanism,attention-based methods,no
516,,,,,used-for,attention mechanisms are used to perform alignment between acoustic frames and recognized symbols.,attention mechanism,perform alignment between acoustic frames and recognized symbols,no
517,4556070.0,"with these state-of-theart end-to-end asr techniques, espnet also provides a number of recipes for major asr benchmarks including wall street journal (wsj) [18] , librispeech [19] , ted-lium",{'espnet'},1.0,type-of,ted - lium is a type of asr benchmark.,ted - lium,asr benchmark,no
518,,,,,compare,"ted - lium is like [wall street journal (wsj), librispeech], in that they are asr benchmarks.",ted - lium,"[wall street journal (wsj), librispeech]",no
519,899695.0,"when allocating cluster resources, slaq explores the quality-runtime trade-offs across multiple jobs to maximize system-wide quality improvement. to do so, slaq leverages the iterative nature of ml training algorithms, by collecting quality and resource usage information from concurrent jobs, and then generating highlytailored quality-improvement predictions for future iterations.",{'slaq'},0.0,,,,,
520,899695.0,"to do so, slaq leverages the iterative nature of ml training algorithms, by collecting quality and resource usage information from concurrent jobs, and then generating highlytailored quality-improvement predictions for future iterations. experiments show that slaq achieves an average quality improvement of up to 73% and an average delay reduction of up to 44% on a large set of ml training jobs, compared to resource fairness schedulers.",{'slaq'},1.0,compare,slaq is an alternative to resource fairness schedulers in that slaq achieves an average quality improvement of up to 73% and an average delay reduction of up to 44% on a large set of ml training jobs.,slaq,resource fairness schedulers,no
521,899695.0,"we present slaq, a cluster scheduling system for ml training jobs that aims to maximize the overall job quality. slaq dynamically allocates resources based on job resource demands, intermediate model quality, and the system's workload.",{'slaq'},1.0,is-a,slaq is a cluster scheduling system for ml training jobs that aims to maximize the overall job quality.,slaq,cluster scheduling system for ml training jobs that aims to maximize the overall job quality,no
522,899695.0,"slaq dynamically allocates resources based on job resource demands, intermediate model quality, and the system's workload. the intuition behind slaq is that in the context of approximate ml training, more resources should be allocated to jobs that have the most potential for quality improvement.",{'slaq'},0.0,,,,,
523,899695.0,"slaq leverages the fact that most ml training algorithms are implemented as an iterative optimization process. by continually monitoring the history of quality improvement and runtime, slaq generates highlytailored and accurate quality predictions for future training iterations.",{'slaq'},0.0,,,,,
524,899695.0,"by continually monitoring the history of quality improvement and runtime, slaq generates highlytailored and accurate quality predictions for future training iterations. slaq estimates the impact of resource allocation on model quality, and explores the qualityruntime trade-offs across multiple jobs.",{'slaq'},0.0,,,,,
525,899695.0,"slaq estimates the impact of resource allocation on model quality, and explores the qualityruntime trade-offs across multiple jobs. based on this information, slaq adjusts their resource allocations of all running jobs to best utilize the limited cluster resources.",{'slaq'},0.0,,,,,
526,899695.0,slaq uses online prediction: it predicts the time and quality of the coming iterations based on statistics collected from previous iterations. slaq supports configurable high-level goals when scheduling jobs.,{'slaq'},0.0,,,,,
527,899695.0,"when maximizing the minimum quality, slaq can achieve the equivalent of max-min fairness applied to quality (rather than resource allocation). while we designed our scheduler for ml training applications, slaq can schedule many applications with approximate intermediate results.",{'slaq'},0.0,,,,,
528,899695.0,"we implemented slaq as a new scheduler within the apache spark framework [19] . slaq can use its qualitydriven scheduling for many of the ml algorithms available in mllib [5] , spark's machine learning package.",{'slaq'},1.0,is-a,mllib is spark's machine learning package.,mllib,spark's machine learning package,no
529,899695.0,"slaq can use its qualitydriven scheduling for many of the ml algorithms available in mllib [5] , spark's machine learning package. in fact, slaq supports unmodified ml applications using existing mllib optimizers, as well as applications using new optimization algorithms with only minor modifications.","{'mllib', 'slaq'}",1.0,is-a,mllib is spark's machine learning package.,mllib,spark's machine learning package,no
530,899695.0,slaq is designed for ml training in general exploratory settings on multi-tenant clusters. automated model search systems could work in conjuction with slaq for faster decisions and better cluster utilization.,{'slaq'},0.0,,,,,
531,24033213.0,"in this paper, we propose a convolutional neural network (cnn) model for solving geometric pattern recognition problems. the cnn receives as input multiple ordered input images and outputs the next image according to the pattern.",{'convolutional neural network'},0.0,,,,,
532,24033213.0,"the cnn receives as input multiple ordered input images and outputs the next image according to the pattern. our cnn is able to solve problems involving rotation, reflection, color, size and shape patterns and score within the top 5% of human performance.",{'cnn'},0.0,,,,,
533,24033213.0,"our architecture uses convolutional neural networks (cnns) (lecun et al. 1990 ). for multiple choice type problems, we use a classification architecture containing a discriminator (see e.g. (krizhevsky, sutskever, and hinton 2012) ).","{'convolutional neural network', 'cnn'}",0.0,,,,,
534,12575862.0,"community detection has attracted increasing attention during the past decade, and many algorithms have been proposed to find the underlying community structure in a given network. many of these algorithms are based on modularity maximization, and these methods suffer from the resolution limit.",{'community detection'},0.0,,,,,
535,12575862.0,"many of these algorithms are based on modularity maximization, and these methods suffer from the resolution limit. in order to detect the underlying cluster structure, we propose a new convex formulation to decompose a partially observed adjacency matrix of a network into low-rank and sparse components.",{'modularity maximization'},0.0,,,,,
536,12575862.0,"although this is not always true, it has formed the motivation for developing many algorithms based on modularity maximization [9] . modularity maximization is an npcomplete problem [6] and the algorithms are only able to find a good approximation to the global solution.",{'modularity maximization'},1.0,type-of,modularity maximization is a type of npcomplete problem.,modularity maximization,npcomplete problem,no
537,12575862.0,"we will discuss this property in more detail in the next section, and develop an alternating direction method of multipliers (admm) algorithm for the proposed model. finally, in section 3, we first discuss how to generate a random family of networks for which modularity maximization fails, then compare our results with those generated by louvain method [4] , which is a greedy algorithm to solve the modularity maximization problem.","{'admm', 'alternate direction method'}",0.0,,,,,
538,11589076.0,"as a result, cache-oblivious search trees have been suggested in the literature. in this paper, we present a new locality measure that can be used to derive cache-oblivious data structures.",{'cache - oblivious search tree'},0.0,,,,,
539,13144767.0,"the fact that the hidden layer is not touched after initialization and training consists of solving a linear system, makes the elm very fast compared to other learning methods based on for example backpropagation or gradient-descent [1, 2] . however, an aspect of the elm that has not received much attention so far is how to exactly initialize the hidden layer.",{'elm'},0.0,,,,,
540,13144767.0,"section 2 of the paper discusses the background and theory of elm, and gives a short overview of elm variants as well as preliminaries and methods relevant for this paper. in particular, it is discussed how to perform efficient model selection and optimization of the l2 regularization parameter in elm, which is important for training robust models.",{'elm'},0.0,,,,,
541,13144767.0,"the main idea behind the elm is the fact that theoretically it is sufficient to generate the hidden layer weights in a random way. as long as the weights are independent and the transfer functions are infinitely differentiable [1, 2] the elm is a universal approximator and can approximate any function, given enough data and given enough neurons.",{'elm'},1.0,is-a,"elm is a universal approximator and can approximate any function, given enough data and given enough neurons.",elm,universal approximator,no
542,13144767.0,"furthermore, combined with bip pretraining (which essentially makes the elm insensitive to the initial jwj and jxj), any difference between elms that only differ in the way they generate the weights, will have to come from the diversity of cos ; and hence the angles between the weights and the input data. finally, since the only thing that is adapted in the binary and ternary weight scheme is the way to generate the random weights, the computational time of the elm is not affected compared to the traditional random weights, and any advantages that may result from the different weight generation scheme will come for free.",{'elm'},0.0,,,,,
543,190001673.0,"in particular, each node only attends to its neighbors in gats whereas ag-gcns measure the relatedness among all nodes. the network topology in gats remains the same, while fully connected graphs will be built in ag-gcns to capture long-range semantic interactions.",{'gat'},1.0,compare,gats is like ag-gcns except that each node only attends to its neighbors.,gats,ag-gcns,no
544,198147929.0,[26] proposed a multi-scale auto-encoder network with both gradient difference loss and adversarial loss. prednet [24] is inspired by the concept of predictive coding from the neuroscience literature.,{'adversarial loss'},1.0,is-a,prednet is a method inspired by the concept of predictive coding from neuroscience literature.,prednet,method inspired by the concept of predictive coding from neuroscience literature,no
545,198147929.0,[42] proposed a convolutional network which offered a method to obtain time-series information between images and srivastava et al. [33] demonstrated that long short-term memory was able to capture pixellevel dynamics by conducting a sequence-to-sequence model.,{'convolutional network'},1.0,used-for,long short-term memory is used to capture pixellevel dynamics by conducting a sequence-to-sequence model.,long short-term memory,capture pixellevel dynamics by conducting a sequence-to-sequence model,no
546,,,,,is-a,convolutional network is a method used to obtain time-series information between images.,convolutional network,method used to obtain time-series information between images,no
547,115126.0,"it was observed in [gk11, brs11] that the snowflake of a finite metric space in l 2 may be embedded in dimension which is close to the intrinsic dimension of the space (measured by its doubling dimension), and this may be independent of n. in [gk11] the case of l 1 was considered as well, however the resulting dimension had doubly exponential dependence on the doubling dimension.",{'doubling dimension'},1.0,is-a,doubling dimension is a measure of the intrinsic dimension of a finite metric space. ,doubling dimension,measure of the intrinsic dimension of a finite metric space ,no
548,115126.0,"in [gk11] the case of l 1 was considered as well, however the resulting dimension had doubly exponential dependence on the doubling dimension. we demonstrate that the basic embedding can be used to build a snowflake for  p for all 1  p  2 with dimension polynomial in the doubling dimension; this is found in lemma 4.4.",{'doubling dimension'},0.0,,,,,
549,115126.0,"indyk [ind06] devised an analogue to the jl-lemma which uses p-stable distributions to produce estimates of interpoint distances; strictly speaking, this is not an embedding into  p (e.g. it uses median over the coordinates). motivated by the nearest neighbor search problem, indyk and naor [in07] proposed a weaker form of dimension reduction, and showed that every doubling subset s   2 admits this type of dimension reduction into  2 of dimension o(ddim(s)).",{'p - stable distribution'},1.0,used-for,p-stable distributions are used to produce estimates of interpoint distances by an analogue to the jl-lemma.,p-stable distributions,produce estimates of interpoint distances by an analogue to the jl-lemma,no
550,115126.0,"it was observed in [gk11, brs11] that the snowflake of a finite metric space in l 2 may be embedded in dimension which is close to the intrinsic dimension of the space (measured by its doubling dimension), and this may be independent of n. in [gk11] the case of l 1 was considered as well, however the resulting dimension had doubly exponential dependence on the doubling dimension.",{'doubling dimension'},1.0,is-a,doubling dimension is a measure of the intrinsic dimension of a finite metric space. ,doubling dimension,measure of the intrinsic dimension of a finite metric space ,no
551,115126.0,"in [gk11] the case of l 1 was considered as well, however the resulting dimension had doubly exponential dependence on the doubling dimension. we demonstrate that the basic embedding can be used to build a snowflake for  p for all 1  p  2 with dimension polynomial in the doubling dimension; this is found in lemma 4.4.",{'doubling dimension'},0.0,,,,,
552,115126.0,"indyk [ind06] devised an analogue to the jl-lemma which uses p-stable distributions to produce estimates of interpoint distances; strictly speaking, this is not an embedding into  p (e.g. it uses median over the coordinates). motivated by the nearest neighbor search problem, indyk and naor [in07] proposed a weaker form of dimension reduction, and showed that every doubling subset s   2 admits this type of dimension reduction into  2 of dimension o(ddim(s)).",{'p - stable distribution'},1.0,used-for,p-stable distributions are used to produce estimates of interpoint distances by an analogue to the jl-lemma.,p-stable distributions,produce estimates of interpoint distances by an analogue to the jl-lemma,no
553,22688536.0,"a software product line for m-learning focusing on programming is discussed in [59] and a software product line for games is presented in [60] . recently, researchers have expressed e-learning processes using software product lines [61] .",{'software product line'},1.0,used-for,software product lines are used to express e-learning processes.,software product lines,express e-learning processes,no
554,4939967.0,"their framework is based on a genetic algorithm which generates test suites for mutation testing. to maximize the mutation score of a test suite, the proposed genetic algorithm needs to execute ws-bpel programs under test many times, which is very timeconsuming and thus not efficient.",{'mutation testing'},0.0,,,,,
555,207212496.0,"in this framework, the magnetization-prepared two rapid acquisition gradient echoes (mp2rage) (marques et al., 2010; marques and gruetter, 2013) was developed as an extension of the mprage (mugler and brookeman, 1990) , one of the most common mr sequence used for anatomical t 1 -weighted imaging. mp2rage not only provides a so-called ""uniform"" t 1 -weighted image suitable for morphological analysis, but is also a fast t 1 mapping sequence, recently used to investigate the healthy cervical sc at 3t (rasoanandrianina et al., 2019) and at 7t (massire et al., 2016 ).",{'mp2rage'},1.0,is-a,mp2rage is an extension of the mprage.,mp2rage,extension of the mprage,no
556,,,,,is-a,"mp2rage is a fast t 1 mapping sequence that provides a so-called ""uniform"" t 1 -weighted image suitable for morphological analysis.",mp2rage,"fast t 1 mapping sequence that provides a so-called ""uniform"" t 1 -weighted image suitable for morphological analysis",no
557,,,,,used-for,mp2rage is used to investigate the healthy cervical sc at 3t and at 7t.,mp2rage,investigate the healthy cervical sc at 3t and at 7t,no
558,207212496.0,"mp2rage not only provides a so-called ""uniform"" t 1 -weighted image suitable for morphological analysis, but is also a fast t 1 mapping sequence, recently used to investigate the healthy cervical sc at 3t (rasoanandrianina et al., 2019) and at 7t (massire et al., 2016 ). mp2rage appears particularly well-suited for cervical sc uhf-imaging due to various assets, including: an adiabatic inversion radiofrequency pulse, robust gradient echo (gre) readouts, an overall low specific absorption rate (sar), an intrinsic volume co-registration and an overall immunity to b 1  bias (marques et al., 2010) .",{'mp2rage'},1.0,used-for,"mp2rage is used for cervical sc uhf-imaging due to various assets, including: an adiabatic inversion radiofrequency pulse, robust gradient echo (gre) readouts, an overall low specific absorption rate (sar), an intrinsic volume co-registration and an overall immunity to b 1 bias.",mp2rage,cervical sc uhf-imaging,no
559,2747778.0,"although the recent research challenge tempeval (uzzaman et al., 2013; bethard and savova, 2016) offers an evaluation in the clinical domain besides newswire, most participants used the provided annotated corpus to train supervised models in addition to employing hand-coded rules. previous work on adapting temporal taggers primarily focus on scaling up to more languages.",{'tempeval'},0.0,,,,,
560,2747778.0,"previous work on adapting temporal taggers primarily focus on scaling up to more languages. heideltime was extended to multilingual (strtgen and gertz, 2015) , collo-",{'temporal tagger'},0.0,,,,,
561,10022612.0,we detail a machine-checked proof of soundness of our separation logic. this is the first large-scale machine-checked proof of a separation logic w.r.t.,{'separation logic'},0.0,,,,,
562,56475910.0,"cnn architecture consists of several types of layers including convolution, pooling, and fully connected. the network expert has to make multiple choices while designing a cnn such as the number and ordering of layers, the hyperparameters for each type of layer (receptive field size, stride, etc.).",{'pooling'},1.0,type-of,pooling is a type of layer in cnn architecture.,pooling,layer,no
563,,,,,compare,"pooling is like [convolution, fully connected] in that they are both types of layer in cnn architecture.",pooling,"convolution, fully connected",no
564,,,,,is-a,stride is a hyperparameter for layers in a cnn.,stride,hyperparameter,yes
565,,,,,compare,stride is like receptive field size in that they are both hyperparameters for layers in a cnn.,stride,receptive field size,yes
566,2992810.0,"this paper is the basic one of the series resulting from the minisymposium entitled ""recent advances for the parareal in time algorithm"" that was held at dd15. the parareal in time algorithm is presented in its current version (predictor-corrector) and the combination of this new algorithm with other more classical iterative solvers for parallelization which makes it possible to really consider the time direction as fertile ground to reduce the time integration costs.",{'parareal'},0.0,,,,,
567,555949.0,"nodetrix representations are a popular way to visualize clustered graphs; they represent clusters as adjacency matrices and intercluster edges as curves connecting the matrix boundaries. we study the complexity of constructing nodetrix representations focusing on planarity testing problems, and we show several np-completeness results and some polynomial-time algorithms.",{'nodetrix representation'},1.0,is-a,nodetrix representations are a way to visualize clustered graphs by representing clusters as adjacency matrices and intercluster edges as curves connecting the matrix boundaries. ,nodetrix representations,way to visualize clustered graphs by representing clusters as adjacency matrices and intercluster edges as curves connecting the matrix boundaries,no
568,555949.0,"we study the complexity of constructing nodetrix representations focusing on planarity testing problems, and we show several np-completeness results and some polynomial-time algorithms. building on such algorithms we develop a javascript library for nodetrix representations aimed at reducing the crossings between edges incident to the same matrix.",{'nodetrix representation'},0.0,,,,,
569,1922244.0,"the special relation of the verb and particle within a vpc is often distinctively marked at several annotation layers in treebanks. for instance, in the penn treebank, the particle is assigned a specific part of speech tag (rp) and it also has a specific syntactic label (prt)",{'treebank'},1.0,type-of,penn treebank is a type of treebank where the particle is assigned a specific part of speech tag (rp) and it also has a specific syntactic label (prt).,penn treebank,treebank where the particle is assigned a specific part of speech tag (rp) and it also has a specific syntactic label (prt),no
570,202728624.0,"we use match points technique after feature extraction process using sift and surf. for splicing detection, we extracted the edges of the integral images of y , c b , and cr image components.",{'surf'},0.0,,,,,
571,18469143.0,this paper shows the results of a systematic mapping study which was performed to obtain an updated overview of the current approaches used in spqp research. a systematic mapping study is a defined method with which to build a classification scheme and structure a field of interest [75] .,{'systematic mapping study'},1.0,used-for,systematic mapping study is used to obtain an updated overview of the current approaches used in spqp research.,systematic mapping study,obtain an updated overview of the current approaches used in spqp research,no
572,,,,,is-a,systematic mapping study is a defined method with which to build a classification scheme and structure a field of interest.,systematic mapping study,defined method with which to build a classification scheme and structure a field of interest,no
573,18469143.0,"a systematic mapping study is a defined method with which to build a classification scheme and structure a field of interest [75] . many systematic studies have been carried out in the sq field, such as [25, 42, 68, 80, 94] , but to the best of our knowledge, no systematic mapping study of spqp approaches has been published to date.",{'systematic mapping study'},1.0,is-a,systematic mapping study is a defined method with which to build a classification scheme and structure a field of interest.,systematic mapping study,defined method with which to build a classification scheme and structure a field of interest,no
574,10165852.0,"[1, 7] combine the matching scores of the face, fingerprint and hand geometry using three different techniques, the sum rule, decision tree, and linear discriminant analysis. experiments indicate that the fusion scheme using the sum rule with normalized scores gives the best performance.",{'sum rule'},0.0,,,,,
575,37148999.0,"several logic styles are proposed in the literature, such as sense amplifier based logic (sabl) [14] , wave dynamic differential logic (wddl)",{'sabl'},1.0,type-of,sense amplifier based logic (sabl) is a type of logic style.,sabl,logic style,yes
576,,,,,compare,sense amplifier based logic (sabl) is like wave dynamic differential logic (wddl) in that they are both logic styles.,sabl,wave dynamic differential logic,yes
577,37148999.0,"it is worth mentioning that both sabl and wddl are full-custom full-swing styles. on the other hand, dycml [17] which is a low-swing, self-timed logic, shows 18% less power consumption compared to static cmos using the khazad s-box as a test case and implemented using 0.13 m 1.2 v cmos partially depleted (pd) soi technology [21] .","{'sabl', 'wddl'}",1.0,is-a,"[sabl, wddl] is a full-custom full-swing style.","sabl, wddl",full-custom full-swing style,no
578,,,,,compare,sabl is like wddl in that they are both full-custom full-swing styles.,sabl,wddl,yes
579,58013574.0,"[33] made about robust principal component analysis (rpca), numerous methods have been proposed to detect infrared small targets. these methods consider that the target components and background components can be approximately represented by a sparse matrix and a low-rank matrix, respectively.","{'rpca', 'robust principal component analysis'}",1.0,used-for,low-rank matrix is used to represent background components in methods proposed to detect infrared small targets.,low-rank matrix,represent background components in methods proposed to detect infrared small targets,no
580,58013574.0,"[35] generated an image patch set by multiscale patch transformation and achieved the matrix recovery using an adaptive weighting parameter. additionally, other components analysis-based methods such as singular value decomposition [36] and partial sum minimization of singular values [37] have been proposed.",{'matrix recovery'},1.0,compare,partial sum minimization is like singular value decomposition in that they are both components analysis-based methods.,partial sum minimization,singular value decomposition,no
581,,,,,is-a,partial sum minimization is a components analysis-based method.,partial sum minimization,components analysis-based method,no
582,12361289.0,"conformal prediction was originally designed for an online setting, in which test instances are predicted successively, each prediction being reviewed before the next instance is predicted. in this transductive setting, conformal prediction, at least in theory, requires the learning of a new model for each new test instance to be predicted, which of course may be computationally prohibitive for many applications.",{'conformal prediction'},0.0,,,,,
583,12361289.0,"in this transductive setting, conformal prediction, at least in theory, requires the learning of a new model for each new test instance to be predicted, which of course may be computationally prohibitive for many applications. instead, inductive conformal prediction (icp), which was also introduced in [1] , may be used.",{'conformal prediction'},0.0,,,,,
584,12361289.0,"instead, inductive conformal prediction (icp), which was also introduced in [1] , may be used. in icp, just one model is induced from the training data and then used for predicting all test instances.",{'icp'},0.0,,,,,
585,12361289.0,"nguyen et al. use conformal prediction in [10] to identify and observe a moving human or object inside a building. yang et al. use the outlier measure of a random forest to design a conformity measure, and the resulting predictor is tested on a few medical diagnosis problems [11] .",{'conformal prediction'},1.0,used-for,conformal prediction is used to identify and observe a moving human or object inside a building.,conformal prediction,identify and observe a moving human or object inside a building,no
586,12361289.0,"in [12] , devetyarov and nouretdinov use random forests as on-line and off-line conformal predictors, with the overall purpose to compare the efficiency of three different conformity measures. bhattacharyya also investigates different conformity functions for random forests, but in an inductive setting [13] .",{'random forest'},1.0,used-for,"random forests are used for on-line and off-line conformal predictors, with the overall purpose to compare the efficiency of three different conformity measures.",random forests,"on-line and off-line conformal predictors, with the overall purpose to compare the efficiency of three different conformity measures",no
587,159041803.0,the proposed scheduling strategy is built on top of the study of the triples in dyldo dataset and wikidata. nishioka et al. analyzed 173 weekly snapshots of dyldo dataset and 25 monthly snapshots of wikidata to identify the ephemerality and stability of the triples in these datasets.,{'wikidata'},0.0,,,,,
588,9998157.0,well-known among these are the leach (low-energy adaptive clustering hierarchy) [1] and pegasis (power-efficient gathering in sensor information systems),"{'leach', 'low - energy adaptive clustering hierarchy'}",0.0,,,,,
589,9998157.0,"leach operates in two phases: a set-up phase and a steady-state phase. in the set-up phase, the sensor nodes are grouped into clusters with the assignment of a cluster head for each cluster; in the steady-state phase, the sensor nodes transmit the collected data to their individual cluster heads and after gathering data from all of the sensor nodes in its cluster, a cluster head transmits the aggregated data to the sink.","{'leach', 'set - phase'}",1.0,is-a,leach is a system that operates in two phases: a set-up phase and a steady-state phase.,leach,system that operates in two phases: a set-up phase and a steady-state phase,yes
590,9998157.0,"in the set-up phase, the sensor nodes are grouped into clusters with the assignment of a cluster head for each cluster; in the steady-state phase, the sensor nodes transmit the collected data to their individual cluster heads and after gathering data from all of the sensor nodes in its cluster, a cluster head transmits the aggregated data to the sink. in pegasis, a chain of sensor nodes is formed using a greedy approach, starting from the node farthest to the sink.",{'set - phase'},1.0,is-a,"pegasis is a method in which a chain of sensor nodes is formed using a greedy approach, starting from the node farthest to the sink.",pegasis,"method in which a chain of sensor nodes is formed using a greedy approach, starting from the node farthest to the sink",no
591,1112834.0,"the properties of wmns, such as shared wireless medium, open network architecture and stringent resource constraints for mc make the secure communication a hard task to achieve. owing to these characteristics, wmns are vulnerable to several types of security attacks at different layers.",{'wmn'},1.0,is-a,wmn is a method which is vulnerable to several types of security attacks at different layers.,wmn,method which is vulnerable to several types of security attacks at different layers,no
592,3849381.0,"recently, convolutional networks have been used for automatic feature extraction of large image databases, where they have obtained state-of-the-art results. in this work we introduce eegnet, a compact fully convolutional network for eeg-based bcis developed using deep learning approaches.",{'convolutional network'},1.0,used-for,"convolutional networks are used for automatic feature extraction of large image databases, where they have obtained state-of-the-art results.",convolutional networks,"automatic feature extraction of large image databases, where they have obtained state-of-the-art results",no
593,,,,,is-a,eegnet is a compact fully convolutional network for eeg-based bcis developed using deep learning approaches.,eegnet,compact fully convolutional network for eeg-based bcis developed using deep learning approaches,no
594,3849381.0,"in this work we introduce eegnet, a compact fully convolutional network for eeg-based bcis developed using deep learning approaches. methods: eegnet is a 4-layer convolutional network that uses filter factorization for learning a compact representation of eeg time series.",{'eegnet'},1.0,is-a,eegnet is a compact fully convolutional network for eeg-based bcis developed using deep learning approaches.,eegnet,compact fully convolutional network for eeg-based bcis developed using deep learning approaches,no
595,,,,,is-a,eegnet is a 4-layer convolutional network that uses filter factorization for learning a compact representation of eeg time series.,eegnet,4-layer convolutional network that uses filter factorization for learning a compact representation of eeg time series,no
596,3849381.0,"methods: eegnet is a 4-layer convolutional network that uses filter factorization for learning a compact representation of eeg time series. eegnet is one of the smallest convolutional networks to date, having less than 2200 parameters for a binary classification.",{'eegnet'},1.0,is-a,eegnet is a 4-layer convolutional network that uses filter factorization for learning a compact representation of eeg time series.,eegnet,4-layer convolutional network that uses filter factorization for learning a compact representation of eeg time series,no
597,,,,,type-of,"eegnet is a type of convolutional network which is one of the smallest to date, having less than 2200 parameters for a binary classification.",eegnet,convolutional network,no
598,3849381.0,"al. used deep belief networks (dbns) and restricted boltzmann machines (rbms), together with hidden markov models, to temporally model different stages of sleep using eeg [36] . mirowski et al. used a temporal convolutional network on eeg signals for predicting epileptic events [37] .",{'rbms'},1.0,used-for,temporal convolutional network is used for predicting epileptic events.,temporal convolutional network,predicting epileptic events,no
599,3849381.0,"al. investigated using convolutional networks on frequency-transformed eeg signals for classification among different classes of listened music [34, 38] . temporal convolutional networks have also been used for the detection of visual-evoked potentials in [39] and in [33] .",{'convolutional network'},1.0,used-for,convolutional networks are used for classification among different classes of listened music.,convolutional networks,classification among different classes of listened music,no
600,,,,,used-for,temporal convolutional networks are used for the detection of visual-evoked potentials.,temporal convolutional networks,the detection of visual-evoked potentials,no
601,3849381.0,"in this work we introduce eegnet, a compact fully convolutional network for eeg-based bcis developed using deep learning methodologies. eegnet differs from previous convolutional models for eeg in several ways.",{'eegnet'},1.0,is-a,eegnet is a compact fully convolutional network for eeg-based bcis developed using deep learning methodologies.,eegnet,compact fully convolutional network for eeg-based bcis developed using deep learning methodologies,no
602,3849381.0,"finally, our model omits fully-connected layers in an effort to reduce the total number of parameters, a strategy inspired by the work of [40] . we evaluate our model against the current state-of-the-art approaches for four data collections representing four different bci paradigms: p300 visual-evoked potential (p300), error-related negativity (ern), movement-related cortical potential (mrcp) and the sensory motor rhythm (smr).",{'fully - connect layer'},1.0,is-a,error-related negativity (ern) is a type of bci paradigm.,error-related negativity,type of bci paradigm,no
603,,,,,compare,"error-related negativity (ern) is like [p300 visual-evoked potential (p300), movement-related cortical potential (mrcp), sensory motor rhythm (smr)] in that they are both bci paradigms.",error-related negativity,"p300 visual-evoked potential (p300), movement-related cortical potential (mrcp), sensory motor rhythm (smr)",no
604,3849381.0,"we evaluate our model against the current state-of-the-art approaches for four data collections representing four different bci paradigms: p300 visual-evoked potential (p300), error-related negativity (ern), movement-related cortical potential (mrcp) and the sensory motor rhythm (smr). for binary classification problems, eegnet has approximately 2200 parameters, which is half the total number of parameters compared to the model proposed by [41] and has much fewer parameters than the  10k parameters of the smallest model proposed by [32] .",{'error - relate negativity'},0.0,,,,,
605,209515914.0,"there have been several research work and surveys on channel modeling for uav communications, such as [15]- [18] . for instance, a comprehensive survey on channel modeling for uav communications is provided in [15] .",{'uav communication'},0.0,,,,,
606,202719449.0,"our method learns an orthogonal transformation on the input space, which seeks to minimize the variance of word representations on paraphrased contexts. experiments show that the retrofitted model significantly outperforms the original elmo on various sentence classification and language inference tasks.",{'word representation'},0.0,,,,,
607,202719449.0,"unlike traditional word embeddings that represent words with fixed vectors, these embedding models encode both words and their contexts and generate context-specific representations. while contextualized embeddings are useful, we observe that a language model-based embedding model, elmo (peters et al., 2018) , cannot accurately capture the semantic equivalence of contexts.",{'traditional word embedding'},1.0,used-for,traditional word embeddings are used to represent words with fixed vectors.,traditional word embeddings,represent words with fixed vectors,no
608,,,,,is-a,elmo is a language model-based embedding model that cannot accurately capture the semantic equivalence of contexts.,elmo,language model-based embedding model,no
609,202719449.0,"while contextualized embeddings are useful, we observe that a language model-based embedding model, elmo (peters et al., 2018) , cannot accurately capture the semantic equivalence of contexts. specifically, in cases where the contexts of a word have equivalent or similar meanings but are changed in sentence formation or word order, elmo may assign very different representations to the word.",{'elmo'},1.0,is-a,elmo is a language model-based embedding model that cannot accurately capture the semantic equivalence of contexts.,elmo,language model-based embedding model,no
610,202719449.0,"specifically, in cases where the contexts of a word have equivalent or similar meanings but are changed in sentence formation or word order, elmo may assign very different representations to the word. table 1 shows two examples, where elmo generates very different representations for the boldfaced words under semantic equivalent contexts.",{'elmo'},0.0,,,,,
611,202719449.0,"cove (mccann et al., 2017) trains a neural machine translation model and extracts representations of input sentences from the source language encoder. elmo (peters et al., 2018) pretrains lstm-based language models from both directions and combines the vectors to construct contextualized word representations.","{'neural machine translation model', 'cove'}",1.0,is-a,cove is a method which trains a neural machine translation model and extracts representations of input sentences from the source language encoder.,cove,method which trains a neural machine translation model and extracts representations of input sentences from the source language encoder,no
612,,,,,is-a,elmo is a method which pretrains lstm-based language models from both directions and combines the vectors to construct contextualized word representations.,elmo,method which pretrains lstm-based language models from both directions and combines the vectors to construct contextualized word representations,no
613,25062322.0,"developments in programmable networks by martin casado, nick mckeown and scott shenker at stanford university resulted in a novel paradigm of sdn. road to sdn with a brief discussion on the history of programmable networks can be found in [11] .",{'programmable network'},0.0,,,,,
614,25062322.0,openflow is the most widely used protocol used by the end devices to communicate with the sdn controller. openflow supported devices are often called openflow switches.,{'openflow'},1.0,is-a,openflow is a widely used protocol used by the end devices to communicate with the sdn controller.,openflow,widely used protocol used by the end devices to communicate with the sdn controller,no
615,,,,,is-a,openflow switch is an openflow supported device.,openflow switch,openflow supported device,no
616,25062322.0,openflow supported devices are often called openflow switches. an openflow switch separates the data plane and control plane functions.,{'openflow switch'},1.0,is-a,openflow switch is an openflow supported device which separates the data plane and control plane functions.,openflow switch,openflow supported device which separates the data plane and control plane functions,no
617,25062322.0,"flow tables in the switches are maintained by the data plane. in flow tables, each flow table entry contains a set of packet fields to match an action (such as send-out-port, modify-field, or drop).",{'flow table'},0.0,,,,,
618,25062322.0,"in flow tables, each flow table entry contains a set of packet fields to match an action (such as send-out-port, modify-field, or drop). upon receiving a packet which is never seen by the openflow switch and no matching flow entries is found.",{'flow table'},0.0,,,,,
619,25062322.0,decision taken by the sdn controller can be of dropping the packet or adding flow entry in the openflow switch for forwarding in future. flow tables have flow entries which are defined by flow rules defined in openflow.,"{'flow entry', 'openflow switch'}",1.0,is-a,flow table is a table which has flow entries which are defined by flow rules defined in openflow.,flow table,table which has flow entries which are defined by flow rules defined in openflow,yes
620,18909556.0,"abstract-in this paper, optimal power control policies for an interference channel with two energy harvesting transmitters and two corresponding receivers are considered. energy harvesting transmitters have strict power constraints due to the harvesting process as well as battery capacity constraints.",{'energy harvesting transmitter'},1.0,is-a,energy harvesting transmitter is a transmitter which has strict power constraints due to the harvesting process as well as battery capacity constraints.,energy harvesting transmitter,transmitter which has strict power constraints due to the harvesting process as well as battery capacity constraints,no
621,30894155.0,"we can distinguish between early fusion, late fusion and kernel fusion methods [20] . in early fusion the audio and the visual features are combined before classification [12] while in late fusion the classification scores from the individual feature models are combined [9, 11, 16] .",{'late fusion'},1.0,is-a,late fusion is a method in which the classification scores from the individual feature models are combined.,late fusion,method in which the classification scores from the individual feature models are combined,no
622,67855432.0,"it is tailored for image deblurring instead of just applying gan on the deblurring problem. motivated by that, dark channel prior is carefully picked to be incorporated into the loss function for network training.",{'gan'},0.0,,,,,
623,67855432.0,"the work of kupyn [9] trains the popular generative adversarial network (gan) on the same dataset with fewer parameters, gains higher psnr values than that of nah et al. [8] on the gopro dataset, and beats the others on kohler dataset [10] using ssim.",{'few parameter'},0.0,,,,,
624,67855432.0,"to address this artifact, we utilize the dark channel prior. dark channel is defined as minimal intensity among three color channels of pixels in a local area.",{'dark channel'},1.0,is-a,dark channel is a minimal intensity among three color channels of pixels in a local area.,dark channel,minimal intensity among three color channels of pixels in a local area,no
625,67855432.0,"[4] applied dark channel prior to image deblurring. they theoretically and empirically proved that comparing with blur images, the dark channel of sharp image is more sparse.",{'dark channel'},0.0,,,,,
626,67855432.0,"they theoretically and empirically proved that comparing with blur images, the dark channel of sharp image is more sparse. and their results demonstrate that dark channel prior contributes to suppressing ringing and other artifacts.",{'dark channel'},0.0,,,,,
627,13971486.0,"this paper presents a fully automatic method for proving the sequential consistency of an entire parameterized family of protocols, with the number of processors fixed, but the number of addresses and data values being unbounded parameters. using some practical, reasonable assumptions (data independence, processor symmetry, location symmetry, simple store ordering, some syntactic restrictions), the method automatically generates a finite-state abstract protocol from the parameterized protocol description; proving sequential consistency of the abstract model, via known methods, guarantees sequential consistency of the entire protocol family.",{'sequential consistency'},0.0,,,,,
628,13971486.0,"some works verify weaker properties than sequential consistency, over parameterized memory protocols. for example, mcmillan [23] uses compositional model checking to generate invariants that can be used to verify safety and liveness properties of the flash cache coherence protocol.",{'sequential consistency'},0.0,,,,,
629,13971486.0,"for example, mcmillan [23] uses compositional model checking to generate invariants that can be used to verify safety and liveness properties of the flash cache coherence protocol. pong and dubois [28] , delzanno [12] , and emerson and kahlon [13] have produced automatic methods to verify safety properties over parameterized memory protocols, but these methods model the protocols at a very high level of abstraction, where implementation details are hidden.",{'flash cache coherence protocol'},0.0,,,,,
630,12670908.0,"however, these approaches used a software tpm either in the kernel level [9] or as an embedded library [10] , but not in a trustworthy environment that is separated from other code in the system. starting from windows phone 8.1, all windows phone devices include software tpm.",{'software tpm'},1.0,is-a,software tpm is a software included on all windows phone devices starting from windows phone 8.1.,software tpm,software included on all windows phone devices starting from windows phone 8.1,no
631,173187842.0,"the past few years have seen an intense research interest in making models robust to adversarial examples [37] . yet despite a wide range of proposed defenses, the state-of-the-art in adversarial robustness is far from satisfactory.",{'adversarial example'},0.0,,,,,
632,173187842.0,"adversarial examples first appeared in [37] , and prompted a host of ""defenses"" and ""attacks"". while several defenses were broken by subsequent attacks [4, 1, 3] , the general approach of adversarial training [23, 36, 48 ] empirically seems to offer gains in robustness.",{'adversarial example'},0.0,,,,,
633,173187842.0,"they propose a training objective that replaces pseudo-labels with soft labels weighted according to an adversarial loss, and report results on mnist, cifar-10 and svhn with some training labels removed. the experiments in [47, 26] do not augment cifar-10 with new unlabeled data and do not improve the state-of-the-art in adversarial robustness.","{'adversarial loss', 'mnist'}",0.0,,,,,
634,173187842.0,"[41] is the closest to ours-they also study self-training in the gaussian model and propose a version of robust self-training which they apply on cifar-10 augmented with tiny images. using the additional data they obtain new state-of-the-art results in heuristic defenses, comparable to ours.",{'tiny image'},0.0,,,,,
635,1090603.0,they yield adversarial examples misclassified by amazon and google at rates of 96.19% and 88.94%. we also find that this black-box attack strategy is capable of evading defense strategies previously found to make adversarial example crafting harder.,{'adversarial example'},0.0,,,,,
636,71152353.0,"abstract in recent years, network embedding has attracted more and more attention due to its effectiveness and convenience to compress the network structured data. in this paper, we propose a communitybased variational autoencoder (comvae) model to learn network embedding, which consists of a community detection module and a deep learning module.",{'network embedding'},1.0,is-a,network embedding is a method known for its effectiveness and convenience to compress the network structured data.,network embedding,method known for its effectiveness and convenience to compress the network structured data,no
637,71152353.0,"of the original network, the embeddings can be applied to downstream tasks such as network reconstruction [9] , node classification [10] , [11] , link prediction [12] and visualization [13] . in other words, for better performance in various downstream tasks, how to extract the most vital information effectively from the original network is both a target and a challenge for network embedding.",{'downstream task'},0.0,,,,,
638,71152353.0,"firstly, compared to the traditional autoencoder, the sampling procedure of the variational autoencoder leads to more robust outcomes. secondly, it is easier to train the variational autoencoder and tune the parameters, since it does not suffer from the problems such as mode collapse.",{'variational autoencoder'},1.0,compare,"variational autoencoder is like traditional autoencoder except that the sampling procedure leads to more robust outcomes, and it is easier to train and tune the parameters, since it does not suffer from the problems such as mode collapse.",variational autoencoder,traditional autoencoder,no
639,71152353.0,"to the best of our knowledge, it is the first attempt to embed networks via a variational autoencoder which integrates both local information and community information. extensive experiments are conducted on two types of real-world datasets to demonstrate the performance of comvae via four downstream tasks, namely network reconstruction, node classification, link prediction and visualization.",{'variational autoencoder'},1.0,compare,"node classification is like [network reconstruction, link prediction, visualization] in that they are both downstream tasks used to demonstrate the performance of comvae.",node classification,"network reconstruction, link prediction, visualization",no
640,,,,,is-a,node classification is a downstream task used to demonstrate the performance of comvae.,node classification,downstream task used to demonstrate the performance of comvae,no
641,25808647.0,"[6] , where the speaker factor is assumed to be an additive component to the phone variation (represented by gaussian components). this model was extended to a low-rank formulation, leading to the joint factor analysis (jfa) model [7] and its 'simplified' version, the famous i-vector model [8] .",{'speaker factor'},0.0,,,,,
642,25808647.0,"version, plda [10] . a dnn-based i-vector model was also proposed [11] , [12] , where a phonetic deep neural network (dnn) is used to enhance the factorization for speaker factors by providing phonetic information.",{'plda'},0.0,,,,,
643,29790076.0,"existing approaches, such as rdf2vec, use local information, i.e., they rely on local sequences generated for nodes in the rdf graph. for word embeddings, global techniques, such as glove, have been proposed as an alternative.",{'rdf2vec'},1.0,is-a,"rdf2vec is an approach that uses local information, i.e., relies on local sequences generated for nodes in the rdf graph.",rdf2vec,"approach that uses local information, i.e., relies on local sequences generated for nodes in the rdf graph",no
644,,,,,is-a,glove is a global technique that has been proposed as an alternative to rdf2vec for word embeddings.,glove,global technique that has been proposed as an alternative to rdf2vec for word embeddings,no
645,29790076.0,"for word embeddings, global techniques, such as glove, have been proposed as an alternative. in this paper, we show how the idea of global embeddings can be transferred to rdf embeddings, and show that the results are competitive with traditional local techniques like rdf2vec.",{'glove'},0.0,,,,,
646,29790076.0,"the rdf2vec approach is closely related to the approaches deepwalk [21] and deep graph kernels [31] . deepwalk uses language modeling approaches to learn social representations of vertices of graphs by modeling short random-walks on large social graphs, like blogcatalog, flickr, and youtube.",{'deepwalk'},1.0,is-a,"deepwalk is an approach which uses language modeling approaches to learn social representations of vertices of graphs by modeling short random-walks on large social graphs, like blogcatalog, flickr, and youtube.",deepwalk,"approach which uses language modeling approaches to learn social representations of vertices of graphs by modeling short random-walks on large social graphs, like blogcatalog, flickr, and youtube",yes
647,29790076.0,"inspired by techniques from nlp, such as word2vec [14] , they train neural networks for automatically learning the mapping of rdf nodes to feature vectors. vector space embeddings have been shown to outperform traditional methods for creating propositional feature vectors from rdf [22] , e.g., in tasks like content-based recommender systems [24] .",{'word2vec'},1.0,is-a,content-based recommender system is a task where vector space embeddings have been shown to outperform traditional methods for creating propositional feature vectors from rdf.,content-based recommender system,task where vector space embeddings have been shown to outperform traditional methods for creating propositional feature vectors from rdf,no
648,3168458.0,"a recent measurement study on pplive [4] reports that users suffer from long start-up delays and playout lags, and suggests that better segment scheduling algorithms are needed [6] . the main goals of scheduling algorithms in p2p streaming systems are to achieve a target quality of service and balance the load on peers.",{'pplive'},0.0,,,,,
649,3168458.0,"the main goals of scheduling algorithms in p2p streaming systems are to achieve a target quality of service and balance the load on peers. constructing optimal segment schedules to maximize the video quality, however, is computationally complex (np-complete) and therefore, many p2p streaming systems, such as [3] , [9] , [10] , resort to heuristic algorithms for segment scheduling.",{'p2p streaming system'},1.0,is-a,p2p streaming system is a system which uses heuristic algorithms for segment scheduling.,p2p streaming system,system which uses heuristic algorithms for segment scheduling,no
650,3168458.0,"the authors of [2] propose using network coding to bypass the scheduling problem among small blocks belonging to the same relatively large segment. however, employing network coding may impose higher processing overhead on peers, which may require special hardware to speed the decoding process [13] , and is not easy to deploy.",{'network coding'},1.0,used-for,network coding is used to bypass the scheduling problem among small blocks belonging to the same relatively large segment.,network coding,bypass the scheduling problem among small blocks belonging to the same relatively large segment,no
651,16709187.0,the compiled native code generated by a just-in-time (jit) compiler in managed language virtual machines (vm) is placed in a region of memory called the code cache. code cache management (ccm) in a vm is responsible to find and evict methods from the code cache to maintain execution correctness and manage program performance for a given code cache size or memory budget.,{'code cache'},1.0,is-a,code cache is a region of memory which holds the compiled native code generated by a just-in-time (jit) compiler in managed language virtual machines (vm).,code cache,region of memory,no
652,16709187.0,the ccm algorithm in current vms is also responsible for finding and evicting compiled regions to accommodate native code from later compilations if the code cache is full. the ccm algorithm has a choice when selecting a method to purge from the code cache.,{'code cache'},0.0,,,,,
653,16709187.0,"zhang and krintz were among the first researchers to study and present the effect of method eviction from the code cache on memory consumption and program speed in a jvm [25, 26] . similar to our present research, this work evaluated the efficiency of offline and online profiling techniques to find the appropriate set of methods to evict from the code cache.",{'code cache'},0.0,,,,,
654,16709187.0,"intel's pin dbt also supports a full code cache flush [15] . dynamorio adaptively scales up the code cache size based on the program's working set size, but does not implement algorithms to evict compiled blocks to reduce memory consumption in the code cache [7] .",{'code cache'},1.0,is-a,"dynamorio is a method that adaptively scales up the code cache size based on the program's working set size, but does not implement algorithms to evict compiled blocks to reduce memory consumption in the code cache.",dynamorio,"method that adaptively scales up the code cache size based on the program's working set size, but does not implement algorithms to evict compiled blocks to reduce memory consumption in the code cache",yes
655,54198236.0,"deep neural decision forests [8] was proposed to enable a decision tree with deep representation learning ability. in [8] , the outputs of the last fully connected layer of a cnn are utilized as stochastic splitting functions.",{'deep neural decision forest'},1.0,used-for,deep neural decision forest is used to enable a decision tree with deep representation learning ability.,deep neural decision forest,enable a decision tree with deep representation learning ability,no
656,9672153.0,"in addition, because they are a closed class, with stable senses, the requisite datasets for this task are enduring and can be used as long as the problem of preposition disambiguation remains. the data used in this task was developed in the preposition project (tpp, litkowski & hargraves (2005) and litkowski & hargraves (2006) ), 1 with further refinements to fit the requirements of a semeval task.",{'preposition disambiguation'},0.0,,,,,
657,52440472.0,"low-rank clustering methods [16] , [37] , [38] incorporate the nuclear norm in (1) to generate a block-diagonal solution with dense connections. however, the nuclear norm does not enforce subset selection well when noise exists, and the generated coefficient matrix is too dense to be an efficient representation.","{'dense connection', 'nuclear norm'}",0.0,,,,,
658,551912.0,"answering these questions entails discovering the mapping from image a to image b and then extending the mapping to image c and searching for the image d such that the relation from a to b holds for c to d. we pose this problem as learning an embedding that encourages pairs of analogous images with similar transformations to be close together using convolutional neural networks with a quadruple siamese architecture. we introduce a dataset of visual analogy questions in natural images, and show first results of its kind on solving analogy questions on natural images.",{'convolutional neural network'},0.0,,,,,
659,551912.0,our experiments are conducted on datasets containing natural images as well as synthesized images and the results include quantitative evaluations of visalogy across different sizes of distractor sets. the performance in solving analogy questions is directly affected by the size of the set from which the candidate images are selected.,{'synthesize image'},0.0,,,,,
660,551912.0,"different forms of visual reasoning has been explored in the question-answering domain. recently, the visual question answering problem has been studied in several papers [24, 25, 26, 27, 28, 29] .",{'visual reasoning'},0.0,,,,,
661,551912.0,"in another recent approach [26] , knowledge extracted from web visual data is used to answer open-domain questions. while these works all use visual reasoning to answer questions, none have considered solving analogy questions.",{'open - domain question'},1.0,is-a,open-domain question is a question that can be answered using knowledge extracted from web visual data.,open-domain question,question that can be answered using knowledge extracted from web visual data,no
662,86767378.0,"deep convolutional networks (convnets) have significantly improved the state-of-the-art for visual recognition, * equal contribution figure 1 : high-level overview of the proposed method. we transfer knowledge to the target domain by weighting and mixing gradients from source domains, such that the combined gradient should minimize the loss for a few validation samples from the target domain. by finding complex mappings from x to y. unfortunately, these impressive gains in performance come only when massive amounts of paired labeled data (x, y) s.t.","{'deep convolutional network', 'convnet'}",0.0,,,,,
663,212633831.0,"for example, flow-based models rely on invertible transformations with tractable jacobian determinant, while sum-product networks rely on special graph structures (with sums and products as internal nodes) to obtain tractable density. to overcome the limitations caused by the constraint of specifying a normalized explicit density, generative adversarial networks (gans) (goodfellow et al., 2014) proposed to learn implicit density generative models within a minimax framework, where the generative model is a direct differentiable mapping from noise space to sample space.",{'sum - product network'},1.0,is-a,sum-product network is a network that relies on special graph structures (with sums and products as internal nodes) to obtain tractable density. ,sum-product network,network that relies on special graph structures (with sums and products as internal nodes) to obtain tractable density,no
664,,,,,used-for,"generative adversarial networks (gans) is used to learn implicit density generative models within a minimax framework, where the generative model is a direct differentiable mapping from noise space to sample space.",gans,"learn implicit density generative models within a minimax framework, where the generative model is a direct differentiable mapping from noise space to sample space",no
665,212633831.0,"to overcome the limitations caused by the constraint of specifying a normalized explicit density, generative adversarial networks (gans) (goodfellow et al., 2014) proposed to learn implicit density generative models within a minimax framework, where the generative model is a direct differentiable mapping from noise space to sample space. so far many variants of gans have been proposed in order to minimize various discrepancy measures (nowozin et al., 2016;","{'gan', 'generative adversarial network'}",0.0,,,,,
666,19404950.0,"fuzzy set theory and the fuzzy linguistic approach [1, 2, 3, 4] have long been used as powerful tools for preference modeling under uncertainty in diverse decision frameworks, including (i) group decision making (gdm) problems, where multiple dms with diverse points of view attempt to make a common decision; and (ii) multi-criteria decision making problems, in which alternatives are evaluated according to several criteria [5] . recently, the concept of hesitant fuzzy linguistic term sets (hfltss) [6] has attained special attention to represent (and deal with) uncertain linguistic preferential information [7, 8] in a variety of the above mentioned decision frameworks.","{'fuzzy linguistic approach', 'fuzzy set theory'}",1.0,compare,"fuzzy set theory is like fuzzy linguistic approach in that they have both long been used as powerful tools for preference modeling under uncertainty in diverse decision frameworks, including (i) group decision making (gdm) problems, where multiple dms with diverse points of view attempt to make a common decision; and (ii) multi-criteria decision making problems, in which alternatives are evaluated according to several criteria.",fuzzy set theory ,fuzzy linguistic approach,yes
667,,,,,is-a,"[fuzzy set theory, fuzzy linguistic approach] is a powerful tool used for preference modeling under uncertainty in diverse decision frameworks, including (i) group decision making (gdm) problems, where multiple dms with diverse points of view attempt to make a common decision; and (ii) multi-criteria decision making problems, in which alternatives are evaluated according to several criteria.","fuzzy set theory, fuzzy linguistic approach","powerful tool used for preference modeling under uncertainty in diverse decision frameworks, including (i) group decision making (gdm) problems, where multiple dms with diverse points of view attempt to make a common decision; and (ii) multi-criteria decision making problems, in which alternatives are evaluated according to several criteria",no
668,59291898.0,"clicks(w,t) / views(w,t), where wctr is the click-through rate of a word present in the headlines collins et al. introduce a validation test on the standard ctr metric in a study to analyze the role of position bias in information retrieval recommender systems [5] .",{'wctr'},1.0,is-a,wctr is a click-through rate of a word present in the headlines.,wctr,click-through rate of a word present in the headlines,no
669,6830642.0,"also, for internet auctions, yokoo et al. pointed out the possibility of a new type of fraud called false-name bids that exploit the anonymity available on the internet [11, 16] . false-name bids are submitted under fictitious names, e.g., multiple e-mail addresses.",{'false - bid'},0.0,,,,,
670,210839022.0,"the core idea of capsule network is the unit named capsule, which consists of a group of neurons in which its activity vector can represent the instantiation parameters of a specific type of entity. the length of activity vector denotes the probability that the entity exists and its orientation can encode the properties of the entity.","{'capsule network', 'activity vector', 'capsule'}",1.0,is-a,"capsule is a unit which is the core idea of capsule network, and which consists of a group of neurons in which its activity vector can represent the instantiation parameters of a specific type of entity. ",capsule,"unit which is the core idea of capsule network, and which consists of a group of neurons in which its activity vector can represent the instantiation parameters of a specific type of entity.",yes
671,210839022.0,"the length of activity vector denotes the probability that the entity exists and its orientation can encode the properties of the entity. inspired by that, we propose capsar (capsule network with sentiment-aspect reconstruction) framework by leveraging capsules to denote sentiment categories and enforce the potential aspect information as the corresponding properties.",{'activity vector'},0.0,,,,,
672,210839022.0,"[wang et al., 2018b ] firstly adopted capsules into document-level sentiment analysis, but their capsule is still based on rnn and attentions, which is different with the capsule designs in [sabour et al., 2017] . aspect level sentiment classification.",{'capsule'},0.0,,,,,
673,210839022.0,aspect level sentiment classification. aspect level sentiment classification is an emerging essential research topic in the field of sentiment analysis.,{'aspect level sentiment classification'},1.0,is-a,aspect level sentiment classification is an emerging essential research topic in the field of sentiment analysis.,aspect level sentiment classification,emerging essential research topic in the field of sentiment analysis,no
674,210839022.0,"recently, proposed to use capsules to perform aspectcategory level sentiment analysis. however as their previous work [wang et al., 2018b] , the basic capsule module is based on attention mechanisms, which is entirely different with ours.",{'capsule'},1.0,used-for,capsules are used to perform aspectcategory level sentiment analysis.,capsules,perform aspectcategory level sentiment analysis,no
675,206429130.0,"at each of a fixed set of locations, indicated by solid boxes, predictions are made for a collection of ""default"" boxes of different aspect ratios. in the ssd detector, for each default box a score for each object categery (conf) is predicted, as is an offset in the positioning of the box (loc).",{'different aspect ratio'},0.0,,,,,
676,206429130.0,"in the ssd detector, for each default box a score for each object categery (conf) is predicted, as is an offset in the positioning of the box (loc). this work adds a prediction for the pose of an object in the default box, represented by one of a fixed set of possible poses, p1 . . .",{'default box'},0.0,,,,,
677,43966534.0,"in [7] , a novel path unaware layered routing protocol (pulrp) was proposed for dense 3d uwsns. pulrp is proved to have higher pdr compared to the under-water diffusion (uwd) algorithm proposed in [13] and dijkstra's shortest path algorithm.",{'pulrp'},1.0,is-a,pulrp is a novel path unaware layered routing protocol proposed for dense 3d uwsns.,pulrp,novel path unaware layered routing protocol proposed for dense 3d uwsns,no
678,,,,,compare,"pulrp is like [under-water diffusion (uwd) algorithm, dijkstra's shortest path algorithm] except that it is proved to have higher pdr. ",pulrp,"under-water diffusion (uwd) algorithm, dijkstra's shortest path algorithm",no
679,43966534.0,"pulrp is proved to have higher pdr compared to the under-water diffusion (uwd) algorithm proposed in [13] and dijkstra's shortest path algorithm. however, a significant limitation in most underwater sensor nodes is low battery capacity.",{'pulrp'},1.0,compare,"pulrp is like [under-water diffusion (uwd) algorithm, dijkstra's shortest path algorithm] except that it is proved to have higher pdr. ",pulrp,"under-water diffusion (uwd) algorithm, dijkstra's shortest path algorithm",no
680,40094999.0,"our algorithm, chexnet, is a 121-layer convolutional neural network trained on chestx-ray14, currently the largest publicly available chest xray dataset, containing over 100,000 frontalview x-ray images with 14 diseases. four practicing academic radiologists annotate a test set, on which we compare the performance of chexnet to that of radiologists.",{'chexnet'},1.0,is-a,"chexnet is a 121-layer convolutional neural network trained on chestx-ray14, currently the largest publicly available chest xray dataset, containing over 100,000 frontalview x-ray images with 14 diseases.",chexnet,"121-layer convolutional neural network trained on chestx-ray14, currently the largest publicly available chest xray dataset, containing over 100,000 frontalview x-ray images with 14 diseases",no
681,40094999.0,"four practicing academic radiologists annotate a test set, on which we compare the performance of chexnet to that of radiologists. we find that chexnet exceeds average radiologist performance on the f1 metric.",{'chexnet'},1.0,is-a,chexnet is an algorithm that exceeds average radiologist performance on the f1 metric.,chexnet,algorithm that exceeds average radiologist performance on the f1 metric,no
682,40094999.0,we find that chexnet exceeds average radiologist performance on the f1 metric. we extend chexnet to detect all 14 diseases in chestx-ray14 and achieve state of the art results on all 14 diseases.,{'chexnet'},1.0,is-a,chexnet is an algorithm that is used to detect all 14 diseases in chestx-ray14 and achieve state of the art results on all 14 diseases.,chexnet,algorithm that is used to detect all 14 diseases in chestx-ray14 and achieve state of the art results on all 14 diseases,no
683,40094999.0,"first, instead of outputting one binary label, chexnet outputs a vector t of binary labels indicating the absence or presence of each of the following 14 pathology classes: atelectasis, cardiomegaly, consolidation, edema, effusion, emphysema, fibrosis, hernia, infiltration, mass, nodule, pleural thickening, pneumonia, and pneumothorax. second, we replace the final fully connected layer in chexnet with a fully connected layer producing a 14-dimensional output, after which we apply an elementwise sigmoid nonlinearity.","{'effusion', 'hernia', 'pneumothorax', 'cardiomegaly', 'pleural thickening', 'atelectasis'}",1.0,compare,"atelectasis is like [cardiomegaly, consolidation, edema, effusion, emphysema, fibrosis, hernia, infiltration, mass, nodule, pleural thickening, pneumonia, pneumothorax] in that they are both pathology classes. ",atelectasis,"cardiomegaly, consolidation, edema, effusion, emphysema, fibrosis, hernia, infiltration, mass, nodule, pleural thickening, pneumonia, pneumothorax",yes
684,11214925.0,a number of techniques have been proposed to establish pairwise keys in resource constrained sensor networks. a basic probabilistic key predistribution scheme was introduced in eschenauer and gligor [2002] and improved in chan et al.,{'pairwise key'},0.0,,,,,
685,200110957.0,"hybrid learning increases the effectiveness of interaction and expands the network in the learning process, even all students and collaborators can network with the business world as source mobilization [14] . in the indonesian context, quipper as a hybrid learning media has been used in research and provides more value to instructional teachers [15, 16] .",{'hybrid learning'},1.0,is-a,hybrid learning is a method that increases the effectiveness of interaction and expands the network in the learning process.,hybrid learning,method that increases the effectiveness of interaction and expands the network in the learning process,no
686,,,,,is-a,quipper is a hybrid learning media in the indonesian context that has been used in research and provides more value to instructional teachers.,quipper,hybrid learning media in the indonesian context that has been used in research and provides more value to instructional teachers,no
687,195798786.0,"further, a study of one month of crash data from uber showed that npes were uncommon, and that nearly all remaining npes were due to interactions with unchecked code, suppression of nullaway warnings, or post-checking code modification. none of the npes were due to nullaway's unsound assumptions for checked code.",{'npe'},0.0,,,,,
688,2019311.0,"generative adversarial networks (gans) have been shown to be able to sample impressively realistic images. gan training consists of a saddle point optimization problem that can be thought of as an adversarial game between a generator which produces the images, and a discriminator, which judges if the images are real.","{'gan', 'generative adversarial network'}",,,,,,
689,2019311.0,"gan training consists of a saddle point optimization problem that can be thought of as an adversarial game between a generator which produces the images, and a discriminator, which judges if the images are real. both the generator and the discriminator are commonly parametrized as deep convolutional neural networks.","{'gan training', 'discriminator'}",,,,,,
690,2019311.0,both the generator and the discriminator are commonly parametrized as deep convolutional neural networks. the goal of this paper is to disentangle the contribution of the optimization procedure and the network parametrization to the success of gans.,"{'discriminator', 'deep convolutional neural network'}",,,,,,
691,2019311.0,"the goal of this paper is to disentangle the contribution of the optimization procedure and the network parametrization to the success of gans. to this end we introduce and study generative latent optimization (glo), a framework to train a generator without the need to learn a discriminator, thus avoiding challenging adversarial optimization problems.",{'gan'},1.0,is-a,generative latent optimization is a framework to train a generator without the need to learn a discriminator. ,generative latent optimization ,framework to train a generator without the need to learn a discriminator,no
692,2019311.0,"to this end we introduce and study generative latent optimization (glo), a framework to train a generator without the need to learn a discriminator, thus avoiding challenging adversarial optimization problems. we show experimentally that glo enjoys many of the desirable properties of gans: learning from large data, synthesizing visually-appealing samples, interpolating meaningfully between samples, and performing linear arithmetic with noise vectors.","{'generative latent optimization', 'discriminator'}",1.0,is-a,generative latent optimization is a framework to train a generator without the need to learn a discriminator. ,generative latent optimization ,framework to train a generator without the need to learn a discriminator,yes
693,,,,,compare,"generative latent optimization is like gans in that they learn from large data, synthesize visually-appealing samples, interpolate meaningfully between samples, and perform linear arithmetic with noise vectors.",generative latent optimization ,gans,yes
694,2019311.0,"second, a discriminator plays to distinguish between real and fake samples. during training, the generator and the discriminator learn in turns.",{'discriminator'},0.0,,,,,
695,2019311.0,"during training, the generator and the discriminator learn in turns. first, the discriminator learns to assign high scores to real samples, and low scores to fake samples.",{'discriminator'},0.0,,,,,
696,2019311.0,"first, the discriminator learns to assign high scores to real samples, and low scores to fake samples. second, the generator learns to increase the scores of fake samples, as to fool the discriminator.",{'discriminator'},0.0,,,,,
697,2019311.0,"recently, gans have been used to produce samples of remarkable quality from distributions of natural images, such as handwritten digits, human faces, and house interiors [radford et al., 2015] . furthermore, gans exhibit three strong signs of generalization.","{'gan', 'handwritten digit'}",1.0,type-of,handwritten digits are a type of natural image.,handwritten digits,natural image,no
698,,,,,compare,"handwritten digits are an alternative to [human faces, house interiors] in that they are natural images.",handwritten digits,"[human faces, house interiors]",no
699,2019311.0,"despite their successes, training and evaluating gans is notoriously difficult. the adversarial optimization problem implemented by gans is sensitive to random initialization, architectural choices, and hyper-parameter settings.",{'gan'},0.0,,,,,
700,2019311.0,"the adversarial optimization problem implemented by gans is sensitive to random initialization, architectural choices, and hyper-parameter settings. in many cases, a fair amount of human care is necessary to find the correct configuration to train a gan in a particular dataset.",{'gan'},0.0,,,,,
701,2019311.0,"the difficulty of training gans is aggravated by the challenges in their evaluation: since the likelihood of a gan with respect to the data is intractable, the current gold standard to evaluate the quality of a gan model is to eyeball the samples produced by the generator. the evaluation of the discriminator is also not simple, since the visual features learned by the discriminator do not always transfer well to supervised tasks",{'gan'},0.0,,,,,
702,2019311.0,"we investigate the importance of (a1) and propose a drastic simplification of gan training (section 2). our approach, called generative latent optimization (glo), maps one learnable noise vector to each of the images in our dataset by minimizing a simple reconstruction loss.",{'gan training'},0.0,,,,,
703,2019311.0,"alternatively, one can understand glo as an auto-encoder where the latent representation is not produced by a parametric encoder, but learned freely. in contrast to gans, we track of the correspondence between each learned noise vector and the image that it represents.",{'latent representation'},0.0,,,,,
704,2019311.0,"our experiments provide quantitative and qualitative comparisons to principal component analysis (pca), deep convolutional autoencoders (dcae), and gans. we focus on the mnist, cifar-10, stl-10, celeba, and lsunbedroom datasets.",{'gan'},1.0,compare,"mnist is an alternative to [cifar-10, stl-10, celeba, lsunbedroom] in that they are datasets.",mnist,"[cifar-10, stl-10, celeba, lsunbedroom]",no
705,9508662.0,"however, due to the broad class of agents should be described by second-order dynamic, the consensus problem modeled by double integrator is more challenging [15] , [10] . the coordination of multi-robot systems and consensus problems are related with the synchronization problem which uses a graph theory [26] .",{'consensus problem'},1.0,compare,the consensus problem is like the synchronization problem in that both use graph theory.,consensus problem,synchronization problem,no
706,7808335.0,"the authors in [5] proposed an information and energy cooperation scheme for cr networks, where the pu and su are cooperative with each other and the pu can not only send information for relaying but also feed the su with energy via rf energy transfer. three schemes that enable information as well as energy cooperation were proposed.","{'rf energy transfer', 'relaying'}",0.0,,,,,
707,42750215.0,certificateless signature scheme is used to assure the authentication of legitimate vehicles which can enjoy the provided services. we use attribute-based encryption to guarantee access control based on the purchased services.,{'certificateless signature scheme'},0.0,,,,,
708,42750215.0,"to enforce access control in different services, attributebased encryption (abe) has widely been adopted to offer a number of services embedded within a single package [4, 5] . even though abe ensures that a service is accessed by a legitimate user, bad-intentioned vehicle user might over use the services as long as the access structure permits it.",{'abe'},0.0,,,,,
709,42750215.0,we make use of certificateless signature scheme to assure the authentication of legitimate vehicles which can enjoy the provided services [9] . abe is adopted to guarantee rigorous access control based on the provided access structure [10] .,{'certificateless signature scheme'},0.0,,,,,
710,9482867.0,"the derivation of gamp is based on certain approximations (mainly gaussian and quadratic approximations) of loopy belief propagation. if the measurement matrix is large and has zero mean and iid entries, gamp provides excellent performance, e.g. [3] , [9] .",{'gamp'},1.0,based-on,gamp is based-on gaussian and quadratic approximations of loopy belief propagation.,gamp,gaussian and quadratic approximations of loopy belief propagation,no
711,9482867.0,"to better understand gamp, in [11] the authors characterize its fixed points. specifically, they show that gamp can be obtained from the stationary-point equations of some implicit approximations of naive mean-field approximation [11] .",{'gamp'},0.0,,,,,
712,7600045.0,in a central catadioptric system all the rays which enter the camera are reflections of rays which were originally directed towards a single point in space. geyer and daniilidis (2001) show that the projection from space to an image in any central catadioptric system can be modeled geometrically using a sphere and a projection plane.,{'central catadioptric system'},0.0,,,,,
713,28419705.0,the topological median filter [5] is a recently introduced type of median filter for images. it implements some existing ideas and some new ideas on fuzzy connectedness to improve the extraction of edges in noise over a conventional median filter.,{'topological median filter'},1.0,type-of,a topological median filter is a type of median filter for images.,topological median filter,median filter for images,no
714,,,,,part-of,fuzzy connectedness is part of topological median filters.,fuzzy connectedness,topological median filter,yes
715,,,,,compare,topological median filters are an alterative to conventional median filters in that topological median filters have improved extraction of edges in noise.,topological median filter,conventional median filters,no
716,61668770.0,"object detection is meant to detect the specific location and size of a particular object in an image or a video scene. with the growing need of detection-based security and industrial applications, the object detection in a fast and reliable manner has been attracting much interest.",{'object detection'},0.0,,,,,
717,61668770.0,there were many attempts to respond to real-time constraints for object detection. viola and jones [3] have come up with a method of rectangular haar-like features with adaboost learning algorithm combined with a cascade of strong classifiers.,{'object detection'},0.0,,,,,
718,61668770.0,"in a previous work [6] we have reported on the implementation of object detection using haar-like feature selection using opencv for an embedded platform. and in this paper, we develop an extension to compare two feature selection algorithms which are the viola and jones detection technique based on haar-like feature selection combined with cascade classifier, and the lbp (local binary patterns) for feature selection combined with the same classifier, in terms of performance and accuracy in both standard platform and embedded platform.",{'object detection'},0.0,,,,,
719,61668770.0,[8] which is basically a framework for object detection which has been applied to a large number of objects types. another sophisticated classifier was introduced first by viola and jones [3] to detect faces and was then generalized to detect other object types.,{'object detection'},0.0,,,,,
720,15568669.0,"if p is convex, we show that any minimizing triangulation has dual diameter exactly 2  log 2 (n/3) or 2  log 2 (n/3)  1, depending on n. trivially, in this case any maximizing triangulation has dual diameter n  2.",{'dual diameter'},0.0,,,,,
721,15568669.0,"1, depending on n. trivially, in this case any maximizing triangulation has dual diameter n  2. furthermore, we investigate the relationship between the dual diameter and the number of ears (triangles with exactly two edges incident to the boundary of p) in a triangulation.",{'dual diameter'},0.0,,,,,
722,15568669.0,"furthermore, we investigate the relationship between the dual diameter and the number of ears (triangles with exactly two edges incident to the boundary of p) in a triangulation. for convex p, we show that there is always a triangulation that simultaneously minimizes the dual diameter and maximizes the number of ears.",{'dual diameter'},0.0,,,,,
723,15568669.0,"for convex p, we show that there is always a triangulation that simultaneously minimizes the dual diameter and maximizes the number of ears. in contrast, we give examples of general simple polygons where every triangulation that maximizes the number of ears has dual diameter that is quadratic in the minimum possible value.",{'dual diameter'},0.0,,,,,
724,15568669.0,"in that setting, however, the running time is not actually determined by the number of ears, but by the dual diameter of the triangulation. thus, bushy triangulations are only useful for geodesic problems if there is a connection between maximizing the number of ears and minimizing the dual diameter.",{'dual diameter'},0.0,,,,,
725,15568669.0,"on the other hand, we show that there exist simple polygons where the dual diameter of any mindt is substantially smaller than that of any triangulation that maximizes the number of ears. likewise, there exist simple polygons where the dual diameter of any triangulation that minimizes the number of ears is in o(  n), while the maximum dual diameter is linear.",{'dual diameter'},0.0,,,,,
726,10135233.0,"in static environments, sampling-based planners include rapidly-exploring dense tree algorithms (rdts, also known as rrts) [4] and sampling-based roadmaps (sbrs, including probabilistic roadmaps (prms) [5] ).",{'sampling - base planner'},1.0,part-of,"sampling-based planners are a part of static environments that include rapidly-exploring dense tree algorithms (rdts, also known as rrts) and sampling-based roadmaps (sbrs, including probabilistic roadmaps (prms)).",sampling - base planner,static environment,no
727,10135233.0,,,,type-of,probabilistic roadmaps are a type of sampling-based roadmap that are included in sampling-based planners in static environments. ,probabilistic roadmap,sampling - base planner,yes
728,841734.0,"results: this study proposes an effective quantification method, called neurphologyj, capable of automatically quantifying neuronal morphologies such as soma number and size, neurite length, and neurite branching complexity (which is highly related to the numbers of attachment points and ending points). neurphologyj is implemented as a plugin to imagej, an open-source java-based image processing and analysis platform.",{'neurphologyj'},1.0,is-a,"neurphologyj is a quantification method that is capable of automatically quantifying neuronal morphologies such as soma number and size, neurite length, and neurite branching complexity (which is highly related to the numbers of attachment points and ending points), and is implemented as a plugin to imagej, an open-source java-based image processing and analysis platform.",neurphologyj,quantification method,no
729,841734.0,"neurphologyj is implemented as a plugin to imagej, an open-source java-based image processing and analysis platform. the high performance of neurphologyj arises mainly from an elegant image enhancement method.",{'neurphologyj'},0.0,,,,,
730,841734.0,"we evaluated neurphologyj by comparing it with both the computer-aided manual tracing method neuronj and an existing imagej-based plugin method neuritetracer. our results reveal that neurphologyj is comparable to neuronj, that the coefficient correlation between the estimated neurite lengths is as high as 0.992.",{'neurphologyj'},1.0,compare,neurphologyj is like the computer-aided manual tracing method neuronj in that the coefficient correlation between the estimated neurite lengths is as high as 0.992.,neurphologyj,computer-aided manual tracing method neuronj,no
731,841734.0,"our results reveal that neurphologyj is comparable to neuronj, that the coefficient correlation between the estimated neurite lengths is as high as 0.992. neurphologyj can accurately measure neurite length, soma number, neurite attachment points, and neurite ending points from a single image.",{'neurphologyj'},1.0,compare,neurphologyj is like neuronj in that the coefficient correlation between the estimated neurite lengths is as high as 0.992.,neurphologyj,neuronj,no
732,841734.0,,,,used-for,"neurphologyj is used to accurately measure neurite length, soma number, neurite attachment points, and neurite ending points from a single image.",neurphologyj,"accurately measure neurite length, soma number, neurite attachment points, and neurite ending points from a single image",no
733,841734.0,we were also able to calculate the ic50 of nocodazole using neurphologyj. this reveals that neurphologyj is effective enough to be utilized in applications of pharmacological discoveries.,{'neurphologyj'},1.0,used-for,neurphologyj can be used in applications of pharmacological discoveries.,neurphologyj,applications of pharmacological discoveries,no
734,841734.0,"here we describe an effective neuronal quantification method, called neurphologyj, capable of automatically quantifying neuronal morphology from large volumes of 2d fluorescent images that are generated in a typical drug screen. the automated tracing method neuritetracer and the computer-aided manual tracing method neuronj were used to evaluate the performance of neurphologyj. our results reveal that neurphologyj",{'neurphologyj'},1.0,is-a,"neurphologyj is an effective neuronal quantification method, that is capable of automatically quantifying neuronal morphology from large volumes of 2d fluorescent images that are generated in a typical drug screen.",neurphologyj,effective neuronal quantification method,no
735,12522511.0,"since the adaptation data are gathered continuously, simple modifications of the accumulated statistics have to be carried out in order to make the adaptation more accurate. another proposed improvement efficiently employs the combination of fmllr and map.",{'adaptation datum'},0.0,,,,,
736,17074164.0,"since the introduction of abe in implementing fine-grained access control systems [11] , a lot of works have been proposed to design flexible abe schemes. abe comes in two flavors called key-policy abe (kp-abe) and cp-abe [14] .",{'abe'},0.0,,,,,
737,17074164.0,"[17] introduced a novel technique called match-then-decrypt into the decryption of anonymous abe, which can greatly improve the decryption efficiency of anonymous abe. although anonymous abe can realize secure anonymous phr sharing, before its widely deployment, another important security issue, user accountability, has to be addressed.",{'anonymous abe'},0.0,,,,,
738,2515249.0,"one of the first approaches for masking the propagation delays has been the interleaved polling with adaptive cycle time (ipact) approach [9] , [24] which interleaves the report-gate cycles of the individual onus so that they can mask each others propagation delays. the basic ipact approach implements the online scheduling framework [25] in that the olt considers a single onu report when making bandwidth allocation and scheduling decisions; the online scheduling framework is referred to as interleaved polling in [14] , [26] .",{'interleaved polling'},1.0,is-a,"interleaved polling is an online scheduling framework that, with adaptive cycle time, interleaves the report-gate cycles of the individual onus so that they can mask each others propagation delays.",interleaved polling,online scheduling framework,no
739,16085684.0,clef-ip is another important evaluation platform for comparing performance of patent retrieval systems. clef-ip has been running since 2009 and participants have explored standard information retrieval approaches in this domain.,{'clef - ip'},1.0,is-a,"clef-ip is an important evaluation platform that is used for comparing performance of patent retrieval systems, has been running since 2009, and has been used by participants to explore standard information retrieval approaches.",clef - ip,important evaluation platform,no
740,19237033.0,"while our results only represent a single data point, they illustrate the need to look at mptcp from a more holistic point of view and not treat the connections separately, as is currently being done. we call for new approaches and research into how multiple parallel connections offered by mptcp should be used in an efficient and fair manner.",{'mptcp'},0.0,,,,,
741,19237033.0,mptcp adds a scheduling layer over existing tcp connections and routes application packets to one of the subflows based on a decision parameter. efficient scheduling decisions can improve the delay performance of mptcp.,"{'mptcp', 'subflow'}",0.0,,,,,
742,19237033.0,"efficient scheduling decisions can improve the delay performance of mptcp. several schedulers have been proposed by researchers but due to its compliance with modular tcp design, the default scheduler injects packets on a subflow with the lowest smoothed tcp rtt (srtt) value [19] .",{'mptcp'},0.0,,,,,
743,19237033.0,"in this paper, we argue that mptcp should take a more comprehensive view over individual subflows and attempt to optimize the overall performance, as opposed to treating them as separate parallel entities. mptcp currently is limited to the tcp-level information provided by the individual tcp subflows, but we claim that a more holistic approach is needed to exploit the possibilities offered by multiple flows to the full extent.",{'mptcp'},0.0,,,,,
744,19237033.0,"to illustrate one aspect of the problem and to provide motivation for future work, we present several issues in current implementation and working of mptcp due to its reliance on tcp layer information. we show via controlled experiments that the default minsrtt scheduler of mptcp essentially forces the protocol to use only one of the many available flows and thus leads to lower performance.",{'mptcp'},0.0,,,,,
745,19237033.0,"we show via controlled experiments that the default minsrtt scheduler of mptcp essentially forces the protocol to use only one of the many available flows and thus leads to lower performance. to demonstrate the possible performance that can be achieved by mptcp, we develop the queueaware scheduler which considers network interface device queue size while making scheduling decisions.",{'mptcp'},0.0,,,,,
746,52920970.0,"in this work, we identify a shortcoming in systems with graph representation for computation, such as tensorflow and pytorch, that result in high variance in iteration time -random order of received parameters across workers. we develop a system, tictac, to improve the iteration time by fixing this issue in distributed deep learning with parameter servers while guaranteeing near-optimal overlap of communication and computation.",{'pytorch'},1.0,is-a,pytorch is a system with graph representation for computation that results in high variance in iteration time -random order of received parameters across workers. ,pytorch,system with graph representation for computation,no
747,52920970.0,,,,compare,pytorch is like tensorflow in that they are systems with graph representation for computation that results in high variance in iteration time -random order of received parameters across workers. ,pytorch,tensorflow,no
748,14864905.0,this paper is primarily interested in random forests for variable selection. mainly methodological the main contribution is twofold: to provide some insights about the behavior of the variable importance index based on random forests and to use it to propose a two-steps algorithm for two classical problems of variable selection starting from variable importance ranking.,{'random forest'},0.0,,,,,
749,19194935.0,"existing work in source code mining include code search, clone detection, software evolution, models of software development processes, bug localization, software bug prediction, code summarization and so on. our work can be categorized as code summarization and comment generation.","{'bug localization', 'clone detection', 'code summarization'}",0.0,,,,,
750,19194935.0,"like source code summarization, allamanis et al. [2] proposed a continuous embedding model to suggest accurate method and class names.",{'source code summarization'},0.0,,,,,
751,58981439.0,"the skeletal graphs generated from the sampled frames represent human poses related to the object position in both the spatial and temporal domains, and these graphs are used as inputs to the graph convolutional networks. through experiments over an open benchmark and our own data sets, we verify the validity of our framework in that our method outperforms the state-of-the-art method for skeleton-based action recognition.",{'graph convolutional network'},0.0,,,,,
752,58981439.0,"the pose graph is constructed by using spatial human poses (black dots and lines), spatial object poses (red dots and lines), and temporal connections (blue lines). in spatial and temporal domains, the graph is used as the input to gcns.",{'pose graph'},1.0,used-for,the pose graph is used for the input to gcns in spatial and temporal  domains.,pose graph,input to gcns in spatial and temporal  domains,no
753,58981439.0,,,,part-of,"the pose graph a part of spatial and temporal domains that is constructed by using spatial human poses (black dots and lines), spatial object poses (red dots and lines), and temporal connections (blue lines). ",pose graph,spatial and temporal domain,no
754,58981439.0,"the applications of skeleton-based action recognition in real-world scenarios are difficult due to two major problems. first, conventional studies [18, 23, 28, 39] for skeleton-based action recognition usually use constrained datasets, assuming that skeletal data are provided.",{'skeleton - base action recognition'},0.0,,,,,
755,58981439.0,"recent advancements in deep neural networks have led to the development of graph convolutional networks (gcns) to understand the form of graph structures [2, 6, 7, 19, 22, 26] . gcns generalize convolutional neural networks (cnns) from low-dimensional grids of images to high-dimensional domains represented by arbitrarily structured graphs.","{'gcns', 'graph convolutional network'}",1.0,is-a,"gcns are graph convolutional networks, that generalize convolutional neural networks (cnns) from low-dimensional grids of images to high-dimensional domains represented by arbitrarily structured graphs.",gcns,graph convolutional network,yes
756,58981439.0,,,,compare,graph convolutional networks (gcns) are like convolutional neural networks (cnns) in that they generalize them from low-dimensional grids of images to high-dimensional domains represented by arbitrarily structured graphs.,graph convolutional network,convolutional neural network,yes
757,58981439.0,"spectral perspective methods convert graph data into a spectrum and apply cnns to the spectral domain [6, 7, 22] . different from the spectral perspective methods, spatial perspective methods directly use graph convolutions to define parameterized filters [2, 26] .",{'cnn'},1.0,used-for,graph convolutions are used to define parameterized filters in spatial perspective methods.,graph convolution,define parameterized filters in spatial perspective methods,no
758,58981439.0,"different from the spectral perspective methods, spatial perspective methods directly use graph convolutions to define parameterized filters [2, 26] . the convolution operation in the spatial perspective resembles the convolution operation on images.",{'graph convolution'},1.0,used-for,graph convolutions are used to define parameterized filters in spatial perspective methods.,graph convolution,define parameterized filters in spatial perspective methods,no
759,58981439.0,the convolution operation in the spatial perspective resembles the convolution operation on images. we propose a model using gcns for action recognition following the concepts of the spatial perspective.,{'convolution operation'},0.0,,,,,
760,214802675.0,"in this paper, we study the effectiveness of machine translation based pre-training for data-to-text generation in non-english languages. since the structured data is generally expressed in english, text generation into other languages involves elements of translation, transliteration and copying -elements already encoded in neural machine translation systems.",{'machine translation'},0.0,,,,,
761,214802675.0,"based on our experiments on czech, a morphologically complex language, we find that pre-training lets us train end-to-end models with significantly improved performance, as judged by automatic metrics and human evaluation. we also show that this approach enjoys several desirable properties, including improved performance in low data scenarios and robustness to unseen slot values.",{'human evaluation'},0.0,,,,,
762,214802675.0,(2019) propose the mass technique and obtain state-of-the-art results for summarization and unsupervised machine translation. freitag and roy (2018) show that denoising autoencoders can be leveraged for unsupervised language generation from structured data.,{'unsupervised machine translation'},1.0,used-for,denoising autoencoders can be used for unsupervised language generation from structured data.,denoise autoencoder,unsupervised language generation from structured data,no
763,8981605.0,"however, hardware techniques for early register release all suffer from the fact that, without speculative releases, they must wait for the redefining instruction to enter the reorder buffer so that they can be certain that no more instructions will need to read the value. this paper proposes compiler directed early register release.",{'early register release'},0.0,,,,,
764,18902415.0,"methods based on sensor pattern noise (spn) have drawn positive attention from the forensic community due to the fact that they can identify not only camera models of the same make, but also individual instances of the same model. the deterministic component of spn is caused by many factors such as imperfections during the sensor manufacturing process, different sensitivity of pixels with respect to light due to the inhomogeneity of silicon wafers, variable sensitivity of each sensel to light, and the uniqueness of manufacturing imperfections that even sensors of the same model would possess.",{'sensor pattern noise'},1.0,is-a,"sensor pattern noise (spn) is a method that has drawn positive attention from the forensic community due to the fact that they can identify not only camera models of the same make, but also individual instances of the same model. ",sensor pattern noise,method,no
765,3527504.0,leach and heed are two typical voronoi structure based clustering algorithms that have inspired many other algorithms. dwehc [20] made an improvement on heed by using sensors' location information.,"{'leach', 'heed'}",1.0,is-a,leach is a typical voronoi structure based clustering algorithm that has inspired many other algorithms. ,leach,typical voronoi structure based clustering algorithm,
766,3527504.0,,,,is-a,heed is a typical voronoi structure based clustering algorithm that has inspired many other algorithms. ,heed,typical voronoi structure based clustering algorithm,
767,3527504.0,,,,compare,leach is like heed in that they are two typical voronoi structure based clustering algorithms that have inspired many other algorithms. ,leach,heed,
768,3527504.0,"even for classic clustering algorithms like leach and heed, they only discussed communication connectivity problem, ignoring the fact that the network coverage could change during the network operations. to expose the network coverage problem in current work, three communication schemes are examined: direct routing, general leach and heed.",{'leach'},0.0,,,,,
769,3527504.0,"to expose the network coverage problem in current work, three communication schemes are examined: direct routing, general leach and heed. the experiment settings are the same as in heed, shown in table 9 in section 6 experimental construction.",{'heed'},0.0,,,,,
770,3527504.0,"the experiment settings are the same as in heed, shown in table 9 in section 6 experimental construction. in heed, each ch is set to use a single hop to communicate with the bs.",{'heed'},0.0,,,,,
771,3527504.0,"leach and heed performed significantly better than the direct transmission approach. however, the comparison between leach and heed requires careful analysis.",{'leach'},0.0,,,,,
772,3527504.0,"however, the comparison between leach and heed requires careful analysis. the first node died earlier in heed than that in leach.","{'leach', 'heed'}",0.0,,,,,
773,3527504.0,"the first node died earlier in heed than that in leach. after the first node died in leach, all the sensors run out of power in a short period of time.","{'heed', 'leach'}",0.0,,,,,
774,3527504.0,"after the first node died in leach, all the sensors run out of power in a short period of time. therefore, the last node died later in heed than that in leach.",{'leach'},0.0,,,,,
775,3527504.0,"therefore, the last node died later in heed than that in leach. depends on the definition for network lifetime (from the system starts till the first or the last node dies), leach and heed can have different performances.","{'heed', 'leach'}",0.0,,,,,
776,208909720.0,"while the biggest performance gains have originated from improved architectures [13, 18, 45, 47] and feature extractors [17, 71] , some works focused on formulating better loss functions [31, 49] . since its introduction in the pascal voc object detection challenge [11] mean average precision (map ) has become the main evaluation metric for detection benchmarks.",{'feature extractor'},0.0,,,,,
777,53286980.0,"in this work, we propose a novel end-to-end structureaware convolutional network (sacn) that takes the benefit of gcn and conve together. sacn consists of an encoder of a weighted graph convolutional network (wgcn), and a decoder of a convolutional network called conv-transe. wgcn utilizes knowledge graph node structure, node attributes and edge relation types.","{'gcn', 'conve'}",1.0,compare,"gcn is like conve in that their benefits are taken for a novel end-to-end structureaware convolutional network (sacn) that consists of an encoder of a weighted graph convolutional network (wgcn), and a decoder of a convolutional network called conv-transe.",gcn,conve,yes
778,53286980.0,"the most recent conve (dettmers et al. 2017 ) model uses 2d convolution over embeddings and multiple layers of nonlinear features, and achieves the state-of-the-art performance on common benchmark datasets for knowledge graph link prediction. in conve, the embeddings of s and r are reshaped and concatenated into an input matrix and fed to the convolution layer.",{'2d convolution'},1.0,is-a,"conve is a model that uses 2d convolution over embeddings and multiple layers of nonlinear features, and achieves the state-of-the-art performance on common benchmark datasets for knowledge graph link prediction.",conve,model,no
779,53286980.0,,,,used-for,"2d convolution is used for the most recent conve model over embeddings and multiple layers of nonlinear features, and it achieves the state-of-the-art performance on common benchmark datasets for knowledge graph link prediction.",2d convolution,"the most recent conve model over embeddings and multiple layers of nonlinear features, and it achieves the state-of-the-art performance on common benchmark datasets for knowledge graph link prediction",no
780,53286980.0,"in conve, the embeddings of s and r are reshaped and concatenated into an input matrix and fed to the convolution layer. convolutional filters of n  n are used to output feature maps that are across different dimensional embedding entries.",{'conve'},0.0,,,,,
781,53286980.0,"in this paper, we propose an end-to-end graph structureaware convolutional networks (sacn) that take all benefits of gcn and conve together. sacn consists of an encoder of a weighted graph convolutional network (wgcn), and a decoder of a convolutional network called conv-transe. wgcn utilizes knowledge graph node structure, node attributes and relation types.","{'gcn', 'conve'}",1.0,compare,"gcn is like conve in that their benefits are taken for a novel end-to-end structureaware convolutional network (sacn) that consists of an encoder of a weighted graph convolutional network (wgcn), and a decoder of a convolutional network called conv-transe.",gcn,conve,yes
782,53286980.0,"the output of wgcn becomes the input of the decoder conv-transe. conv-transe is similar to conve but with the difference that conv-transe keeps the translational characteristic between entities and relations. we show that conv-transe performs better than conve, and our sacn improves further on top of conv-transe in the standard benchmark datasets.","{'conve', 'conv'}",0.0,,,,,
783,53286980.0,"conve was the first model using 2d convolutions over embeddings of different embedding dimensions, with the hope of extracting more feature interactions. convkb replaced 2d convolutions in conve with 1d convolutions, which constrains the convolutions to be the same embedding dimensions and keeps the translational property of transe. convkb can be considered as a special case of conv-transe that only uses filters with width equal to 1.","{'2d convolution', 'conve'}",1.0,is-a,"conve is a model that was the first to use 2d convolutions over embeddings of different embedding dimensions, with the hope of extracting more feature interactions.",conve,model,no
784,53286980.0,,,,used-for,"2d convolutions are used for extracting more feature interactions in the conve model, and were replaced with 1d convolutions by convkb, which constrains the convolutions to be the same embedding dimensions and keeps the translational property of transe.",2d convolutions,"extracting more feature interactions in the conve model, and were replaced with 1d convolutions by convkb, which constrains the convolutions to be the same embedding dimensions and keeps the translational property of transe",no
785,53286980.0,"the other major difference of conve and convkb is on the loss functions used in the models. conve used the cross-entropy loss that could be sped up with 1-n scoring in the decoder, while convkb used a hinge loss that was computed from positive examples and sampled negative examples.",{'conve'},1.0,compare,"conve is an alternative to convkb that used the cross-entropy loss that could be sped up with 1-n scoring in the decoder, while convkb used a hinge loss that was computed from positive examples and sampled negative examples.",conve,convkb,no
786,53286980.0,"conve used the cross-entropy loss that could be sped up with 1-n scoring in the decoder, while convkb used a hinge loss that was computed from positive examples and sampled negative examples. we take the decoder from conve because we can easily integrate the encoder of gcn and the decoder of conve into an end-to-end training framework, while convkb is not suitable for our approach.",{'conve'},1.0,compare,"conve is an alternative to convkb that used the cross-entropy loss that could be sped up with 1-n scoring in the decoder, while convkb used a hinge loss that was computed from positive examples and sampled negative examples.",conve,convkb,no
787,53286980.0,this success paves the way for a new generation of web-scale recommender systems based on gcns. therefore we believe that our proposed model could take advantage of huge graph structures and high computational efficiency of conv-transe.,{'gcns'},0.0,,,,,
788,5947935.0,"after the introduction of new radios, researchers introduced new lpl and ps protocols: x-mac [8] , c-mac [10] , wisemac [6] , csma-mps [11] , and speckmac [12] are among the most popular contributions.",{'wisemac'},1.0,is-a,wisemac is an lpl and ps protocol that was introduced after the introduction of new radios.,wisemac,lpl and ps protocol,no
789,5947935.0,,,,is-a,csma-mps is an lpl and ps protocol that was introduced after the introduction of new radios.,csma - mps,lpl and ps protocol,no
790,5947935.0,,,,compare,"[wisemac, csma-mps] is like [x-mac, c-mac, spekmac] in that they are lpl and ps protocols introduced after the introduction of new radios.","wisemac, csma - mps","x-mac, c-mac, spekmac",no
791,5947935.0,"csma-mps [11] , and speckmac [12] are among the most popular contributions. these protocols are based on repeating either the data packet itself (speckmac and csma-mps), or an advertisement packet (x-mac/c-mac), in place of a long preamble.",{'csma - mps'},1.0,is-a,"csma-mps is a protocol that is based on repeating either the data packet itself (speckmac and csma-mps), or an advertisement packet (x-mac/c-mac), in place of a long preamble.",csma - mps,protocol,no
792,5947935.0,"because we utilize existing mac protocols for our pool, we provide a detailed study of two existing lpl mac protocols, x-mac and speckmac, in a head-to-head comparison, showing the advantages and disadvantages of each approach for both unicast and broadcast packets. we also identify mx-mac, a modified version of csma-mps, that is compatible with the x-mac and speckmac schedules. .",{'speckmac'},1.0,is-a,speckmac is an lpl mac protocol.,speckmac,lpl mac protocol,no
793,5947935.0,"only three lpl protocols can be selected to synchronize on unicast packets: x-mac, c-mac, and mx-mac. these protocols form a subfamily of lpl protocols that can be interrupted by the receiver.",{'lpl protocol'},0.0,,,,,
794,5947935.0,"in [12] , wong and arvind propose speckmac, a family of lpl mac protocols, which include speckmac-b and speckmac-d. the speckmac protocol family is intended for miniature motes called specks. speckmac-b stands for back off and replaces the long preamble with a sequence of wake-up packets containing the destination target and the time when the data packet will be sent.",{'speckmac'},1.0,is-a,"speckmac is a family of lpl mac protocols, that is intended for miniature motes called specks, including speckmac-b and speckmac-d .",speckmac,family of lpl mac protocols,no
795,5947935.0,"in [4] , van dam and langendoen propose to improve s-mac by a novel adaptive active/sleep duty cycle. their protocol, t-mac sends packets in bursts during active periods, and if no activity is detected during a small window of time, nodes return to sleep.",{'s - mac'},1.0,is-a,"t-mac is a novel adaptive active/sleep duty cycle protocol that improves s-mac by sending packets in bursts during active periods, and if no activity is detected during a small window of time, nodes return to sleep.",t - mac,novel adaptive active/sleep duty cycle protocol,no
796,5947935.0,,,,based-on,"t-mac is based on s-mac that sends packets in bursts during active periods, and if no activity is detected during a small window of time, nodes return to sleep.",t - mac,s - mac,yes
797,5947935.0,"their protocol, t-mac sends packets in bursts during active periods, and if no activity is detected during a small window of time, nodes return to sleep. as a consequence, nodes have a shorter duty cycle under t-mac.",{'t - mac'},1.0,is-a,"t-mac is a protocol that sends packets in bursts during active periods, and if no activity is detected during a small window of time, nodes return to sleep, thus, nodes have a shorter duty cycle under t-mac.",t - mac,protocol,no
798,5947935.0,"as a consequence, nodes have a shorter duty cycle under t-mac. in [16] , pham and jha introduce ms-mac, an s-mac-based protocol that adapts s-mac's listening, sleeping, and synchronization cycles to anticipated node movements.",{'t - mac'},1.0,is-a,"ms-mac is an s-mac-based protocol that adapts s-mac's listening, sleeping, and synchronization cycles to anticipated node movements.",ms - mac,s-mac-based protocol,no
799,195346133.0,"when the input is a sequence, recurrent neural networks (rnns) and their variants (lstm, gru, etc.) outperform other classifiers. this is true for both classification tasks, such as video classification and machine translation, and for generative models, such as handwriting text generation.",{'lstm'},1.0,type-of,lstm is a type of recurrent neural networks (rnns) that outperforms other classifiers when the input is a sequence.,lstm,recurrent neural network (rnn),no
800,195346133.0,,,,is-a,"machine translation is a classification task that recurrent neural networks (rnns) and their variants (lstm, gru, etc.) outperform other classifiers on when the input is a sequence.",machine translation,classification task,no
801,195346133.0,,,,is-a,"video classification is a classification task that recurrent neural networks (rnns) and their variants (lstm, gru, etc.) outperform other classifiers on when the input is a sequence.",video classification,classification task,no
802,195346133.0,,,,compare,"video classification is like machine translation in that they are classification tasks that recurrent neural networks (rnns) and their variants (lstm, gru, etc.) outperform other classifiers on when the input is a sequence.",video classification,machine translation,yes
803,195346133.0,"we implement a novel end-to-end method to generate adversarial examples for an rnn malware classifier. unlike previous papers, we focus on the cyber security domain and implement a method that will preserve the functionality of the malware after the perturbation, using a mimicry attack.",{'adversarial example'},0.0,,,,,
804,17219136.0,"we studied three methods to improve identification of difficult small classes by balancing imbalanced class distribution with data reduction. the new method, neighborhood cleaning rule (ncl), outperformed simple random and one-sided selection methods in experiments with ten data sets.",{'imbalanced class distribution'},1.0,is-a,"the neighborhood cleaning rule is a method that aims to improve identification of difficult small classes by balancing imbalanced class distribution with data reduction, and it outperformed simple random and one-sided selection methods in experiments with ten data sets.",neighborhood cleaning rule,method,no
805,21397581.0,"in particular, blackburn [8] analyzed these sequences under the name of 'non-overlapping codes', and provided a simple construction for a class of codes with optimal cardinality. manuscript mu codes have recently found new applications in dna-based data storage [9] , [10] : in this setting, yazdi et al.",{'non - overlapping code'},0.0,,,,,
806,196831588.0,"deep generative models are an attractive choice for outlier detection, because they have the flexibility to model a wide variety of clean distributions. indeed, many types of deep models have been applied to this task, including autoencoders [32, 20, 31] , variational autoencoders (vaes) [1, 27] and generative adversarial networks (gans)",{'deep generative model'},1.0,type-of,"variational autoencoders are a type of deep generative model that has been applied to the task of outlier detection, because they have the flexibility to model a wide variety of clean distributions.",variational autoencoder,deep generative model,yes
807,196831588.0,,,,type-of,"generative adversarial networks (gans) are a type of deep generative model that has been applied to the task of outlier detection, because they have the flexibility to model a wide variety of clean distributions.",generative adversarial network,deep generative model,yes
808,196831588.0,,,,compare,"variational autoencoders are like generative adversarial networks (gans) in that they are types of deep generative model that have been applied to the task of outlier detection, because they have the flexibility to model a wide variety of clean distributions.",variational autoencoder,generative adversarial network (gan),yes
809,196831588.0,,,,compare,"[variational autoencoders, generative adversarial networks (gans)] are like autoencoders in that they are types of deep generative model that have been applied to the task of outlier detection, because they have the flexibility to model a wide variety of clean distributions.","variational autoencoder, generative adversarial network",autoencoder,no
810,196831588.0,"in [27] the authors proposed using a vae as a recurrent unit, iteratively denoising the images. this iterative approach is reminiscent of the solvers used for rpca.","{'vae', 'recurrent unit'}",0.0,,,,,
811,196831588.0,this iterative approach is reminiscent of the solvers used for rpca. however their work is not easily extended to mixed likelihood models and suffers from the same problems as vaes when computing row scores (section 3.3).,{'rpca'},0.0,,,,,
812,13926010.0,"with the growing number of nondominated solutions in the archive, testing a new solution for nondominance against this archive becomes the main bottleneck during optimization. as a remedy to this problem, we will propose a new data structure on the basis of binary decision diagrams (bdds) that permits a nondominance test with a runtime that is independent from the archive size.",{'nondominated solution'},0.0,,,,,
813,13926010.0,"as a remedy to this problem, we will propose a new data structure on the basis of binary decision diagrams (bdds) that permits a nondominance test with a runtime that is independent from the archive size. for this purpose, the region in the objective space weakly dominated by the solutions in the archive is represented by a bdd.",{'archive size'},0.0,,,,,
814,13926010.0,"hence, keeping nondominated solutions in an archive a is an important issue in multi-objective optimization. in general there are two strategies for handling archives: (1) using so called constrained archives requires a method for limiting the number of nondominated solutions in the archive.",{'nondominated solution'},0.0,,,,,
815,13926010.0,"in general there are two strategies for handling archives: (1) using so called constrained archives requires a method for limiting the number of nondominated solutions in the archive. (2) so called unconstrained archives, i.e., archives for storing an unlimited number of nondominated solutions, rely on efficient data structures.",{'nondominated solution'},0.0,,,,,
816,6366442.0,"the doi functions are sensitive to the current state of the knowledge, the particulars of the experiment that generated the data being analyzed, and to the specific analyst who explores the data. our second contribution is the design and development of the renodoi framework, an application to untangle (lt. renodare) large and dense networks using doi functions, and its integration in the network visualization framework cytoscape [6] .",{'doi function'},1.0,is-a,"doi function is a function that is sensitive to the current state of the knowledge, the particulars of the experiment that generated the data being analyzed, and to the specific analyst who explores the data.",doi function,"function that is sensitive to the current state of the knowledge, the particulars of the experiment that generated the data being analyzed, and to the specific analyst who explores the data",no
817,85459529.0,"elman's gave birth to a school of thoughts where theories for curriculum design in human learning became applicable to machine learning. work in curriculum learning [3] , [4] has demonstrated the learning efficiency benefits when applied to machine learning; and improved scalability of specialised data creation through expert demonstration [1] and game play [2] has also been demonstrated.",{'elman'},1.0,is-a,expert demonstration is a method which improves scalability of specialised data creation.,expert demonstration,method which improves scalability of specialised data creation,no
818,15590250.0,"in the fourth section, we explain parallel-in-time numerical method-the parareal method. in the fifth section, we present our novel method, the combination of multilevel summation method and parareal method.",{'parareal method'},0.0,,,,,
819,146120525.0,"arsm first uses variable augmentation, reinforce, and raoblackwellization to re-express the gradient as an expectation under the dirichlet distribution, then uses variable swapping to construct differently expressed but equivalent expectations, and finally shares common random numbers between these expectations to achieve significant variance reduction. experimental results show arsm closely resembles the performance of the true gradient for optimization in univariate settings; outperforms existing estimators by a large margin when applied to categorical variational auto-encoders; and provides a ""try-and-see self-critic"" variance reduction method for discrete-action policy gradient, which removes the need of estimating baselines by generating a random number of pseudo actions and estimating their action-value functions.",{'dirichlet distribution'},0.0,,,,,
820,146120525.0,"here we consider both categorical latent variable models and policy optimization for discrete actions, which arise in a wide array of real-world applications. a number of unbiased estimators for backpropagating the gradient through discrete latent variables have been recently proposed grathwohl et al., 2018; yin & zhou, 2019; andriyash et al., 2018) .",{'policy optimization'},0.0,,,,,
821,146120525.0,"(2017) relax the categorical variables with continuous ones and then apply the reparameterization trick to estimate the gradients, reducing variance but introducing bias. other biased estimators for backpropagating through binary variables include the straight-through estimator (hinton, 2012; bengio et al., 2013) and the ones of gregor et al.",{'reparameterization trick'},0.0,,,,,
822,53721661.0,"object detection is a core computer vision task and there is a growing demand for enabling this capability on embedded devices [1] . state-of-the-art deep learning models, such as faster r-cnn [2] , yolo [3] , and ssd",{'object detection'},1.0,is-a,object detection is a core computer vision task for which there is a growing demand for enabling this capability on embedded devices.,object detection,core computer vision task for which there is a growing demand for enabling this capability on embedded devices,no
823,,,,,is-a,"[faster r-cnn, yolo, ssd] is a state-of-the-art deep learning model.","faster r-cnn, yolo, ssd",state-of-the-art deep learning model,no
824,,,,,compare,"faster r-cnn is like [yolo, ssd] in that they are both state-of-the-art deep learning models.",faster r-cnn,"yolo, ssd",yes
825,53721661.0,"this image is then processed by a structure called the superior colliculus (sc), which was only recently identified as the correct location where the saliency map is generated in primates and humans [19, 20, 21] . such an arrangement has the effect of significantly reducing the visual search space of objects and regions of interest [22] , so that a relatively small and simple neural network suffices for computing and generating a saliency map.",{'saliency map'},0.0,,,,,
826,53721661.0,"inspired by the promise of better region proposal efficiency in natural vision, researchers used saliency-based models to generate object-only region proposals for object detection [13, 14, 15, 16, 17] . their main motivation was that a saliency map, generated non-exhaustively, could highlight regions containing objects, which can then be proposed to an object-category classifier, thereby ignoring background regions altogether and potentially saving thousands of unnecessary classifications.",{'object detection'},1.0,used-for,"saliency map is used to highlight regions containing objects, which can then be proposed to an object-category classifier, thereby ignoring background regions altogether and potentially saving thousands of unnecessary classifications.",saliency map,"highlight regions containing objects, which can then be proposed to an object-category classifier, thereby ignoring background regions altogether and potentially saving thousands of unnecessary classifications",no
827,8318082.0,"our choice of tla+ to specify and verify doris was motivated by the following reasons. tla+ provides a modular structure which allows for an incremental process of specification refinements, according to the abstraction level required.",{'tla+'},1.0,is-a,"tla+ is a method that provides a modular structure which allows for an incremental process of specification refinements, according to the abstraction level required.",tla+,"method that provides a modular structure which allows for an incremental process of specification refinements, according to the abstraction level required",no
828,214713946.0,"firstly, we introduce some basic concepts of transfer learning and then present some preliminaries of adversarial learning, rl and metalearning. secondly, we focus on reviewing the accuracy and transferability to show the advantages of adversarial learning, like generative adversarial networks (gans), in typical computer vision tasks in autonomous systems, including image style transfer, image super-resolution, image deblurring/dehazing/rain removal, semantic segmentation, depth estimation and person reidentification.",{'metalearning'},1.0,compare,"image style transfer is like [image super-resolution, image deblurring/dehazing/rain removal, semantic segmentation, depth estimation, person reidentification] in that they are both advantages of adversarial learning in typical computer vision tasks in autonomous systems.",image style transfer,"image super-resolution, image deblurring/dehazing/rain removal, semantic segmentation, depth estimation, person reidentification",yes
829,,,,,is-a,"[image style transfer, semantic segmentation, person reidentification] is an advantage of adversarial learning in typical computer vision tasks in autonomous systems.","image style transfer, semantic segmentation, person reidentification",advantage of adversarial learning in typical computer vision tasks in autonomous systems,no
830,214713946.0,"secondly, we focus on reviewing the accuracy and transferability to show the advantages of adversarial learning, like generative adversarial networks (gans), in typical computer vision tasks in autonomous systems, including image style transfer, image super-resolution, image deblurring/dehazing/rain removal, semantic segmentation, depth estimation and person reidentification. then, we further review the performance of rl and meta-learning from the aspects of accuracy and transferability in autonomous systems, involving robot navigation and robotic manipulation.","{'semantic segmentation', 'image style transfer', 'gan', 'generative adversarial network', 'person reidentification'}",0.0,,,,,
831,214713946.0,"then, we further review the performance of rl and meta-learning from the aspects of accuracy and transferability in autonomous systems, involving robot navigation and robotic manipulation. finally, we discuss several challenges and future topics for using adversarial learning, rl and meta-learning in autonomous systems.",{'meta - learning'},0.0,,,,,
832,6669851.0,"femtocell deactivation: if the femtocell bss are deployed uniformly in the network, as illustrated in fig. 1(a) , the ones located within the inner region are deactivated, marked as red filled squares therein. the de facto overall femtocell bs density is decreased as compared with the uniform deployment.",{'femtocell'},0.0,,,,,
833,18996878.0,"quantum programming is about quantum software design, i.e., to design algorithms considering the quantum computing paradigm. in this section we briefly review the formalism needed to understand the basic principles of quantum programming.",{'quantum programming'},1.0,is-a,"quantum programming is a type of programming concerned with quantum software design, i.e., to design algorithms considering the quantum computing paradigm. ",quantum programming,"programming concerned with quantum software design, i.e., to design algorithms considering the quantum computing paradigm",no
834,13027224.0,"three parameters of earcons were used to encode information about the ride: timbre, intensity and register. each earcon encoded the type of ride, the intensity of the ride, and the cost of the ride.",{'earcon'},0.0,,,,,
835,16136603.0,"pagerank has proven to be a useful tool for ranking nodes in a graph in many contexts, but it is clear that many refinements can be made for specific purposes. for example, pagerank can be manipulated by link spammers to boost certain nodes' ranking, and it interprets all links between nodes as positive votes for importance even if some links are meant to show distrust.",{'pagerank'},1.0,is-a,pagerank is a useful tool for ranking nodes in a graph in many contexts.,pagerank,useful tool for ranking nodes in a graph in many contexts,no
836,,,,,used-for,"pagerank is used to boost certain nodes' ranking, and it interprets all links between nodes as positive votes for importance even if some links are meant to show distrust.",pagerank,"boost certain nodes' ranking, and it interprets all links between nodes as positive votes for importance even if some links are meant to show distrust",no
837,16136603.0,"the idea of ranking nodes in a graph has a rich history starting from the introduction of pagerank by brin and page [5] . the original pagerank was meant for web search, but many researchers have developed more tailored ranking systems such as personalized pagerank [13, 14] , giving a ranking relative to some specified starting distribution s.",{'pagerank'},1.0,compare,"personalized pagerank is like original pagerank except that it is a more tailored ranking system, giving a ranking relative to some specified starting distribution s.",personalized pagerank,original pagerank,no
838,,,,,is-a,"personalized pagerank is a tailored ranking system, giving a ranking relative to some specified starting distribution s.",personalized pagerank,"tailored ranking system, giving a ranking relative to some specified starting distribution s",no
839,6774439.0,"ese results are even stronger as the backpropagation strategy used to train the cnns was fairly rudimentary (relu units, l2 regularization and nesterov momentum) and these were initial test runs done without re nement of the backpropagation hyperparameters. further, the exact evolutionary strategy is independent of the method used to train the cnns, so they could be further improved by advanced techniques like elastic distortions, pretraining and dropout.",{'cnn'},1.0,is-a,"[elastic distortions, dropout] is an advanced technique that could be used to further improve training of cnns.","elastic distortions, dropout",advanced technique that could be used to further improve training of cnns,no
840,,,,,compare,"[elastic distortions, dropout] is like pretraining in that they are both an advanced technique that could be used to further improve training of cnns.","elastic distortions, dropout",pretraining,no
841,2627903.0,"with regard to the first approach, some authors use machine translation systems, whereas others translate the document word by word consulting a bilingual dictionary. in (lawrence, 2003) , the author presents several experiments for clustering a russian-english multilingual corpus; several of these experiments are based on using a machine translation system.",{'machine translation system'},1.0,used-for,machine translation system is used for clustering a russian-english multilingual corpus.,machine translation system,clustering a russian-english multilingual corpus,no
842,210839104.0,"therefore, we consider the manifold optimization to resolve the optimization problem with unimodular constraints. in addition, by recalling the work in mmwave systems [18] , [19] , the joint power allocation and beamforming design is another important problem.",{'unimodular constraint'},0.0,,,,,
843,2898888.0,"given an image (a), the proposed method improves the results of fcn-8s [12] (c) by exploiting the global context information. our result (d) shows that the algorithm can eliminate the false positives that are not compatible with the scene category (e.g., some sand regions in (c) are predicted as mountain in a beach scene).",{'global context information'},0.0,,,,,
844,2898888.0,"in this paper, we propose an algorithm to embed global contexts into the segmentation network by feature learning and non-parametric prior encoding. different from previous approaches that only consider the contexts within the input image, our method exploits the scene similarities between images without knowing scene categories.",{'segmentation network'},0.0,,,,,
845,2898888.0,"for global context feature encoding, we propagate the learned representations through the segmentation network. for non-parametric prior encoding, we generate both global and spatial priors by retrieving annotated images via global context features and combine them with our segmentation network.",{'segmentation network'},1.0,used-for,global context features are used for retrieving annotated images to generate both global and spatial priors for non-parametric prior encoding.,global context features,retrieving annotated images to generate both global and spatial priors for non-parametric prior encoding,no
846,2898888.0,"a recent study shows that the performance of fcn-based models can be improved by applying dilated convolution [32] . the key insight is that dilated convolution allows the network to ""see"" more, i.e., enlarging the receptive field, and therefore more context information is perceived.",{'dilated convolution'},1.0,used-for,dilated convolution is used to improve performance of fcn-based models.,dilated convolution,improve performance of fcn-based models,no
847,2898888.0,"in this work, we generate the prior information without alignment and pass the priors through convolutional layers. it allows the segmentation network to learn how to combine the prior information with local prediction in an end-to-end fashion.",{'convolutional layer'},1.0,used-for,segmentation network is used to learn how to combine the prior information with local prediction in an end-to-end fashion.,segmentation network,learn how to combine the prior information with local prediction in an end-to-end fashion,no
848,2898888.0,"we first propagate an input image through two networks: segmentation network and global context network. the segmentation network (e.g., fcn [20] or deeplab [3] ) generates the initial parsing results.",{'segmentation network'},1.0,is-a,segmentation network is a network that can be used to propagate an input image.,segmentation network,network that can be used to propagate an input image,no
849,,,,,compare,segmentation network is like global context network in that they are both networks that can be used to propagate an input image.,segmentation network,global context network,no
850,13599081.0,we use the concept of strong information theoretic security to ensure that the non-legitimate node cannot decode the confidential message no matter what its computational resources are. this results in the study of the bidirectional broadcast channel with confidential messages for which we establish the strong secrecy capacity region.,{'confidential message'},0.0,,,,,
851,13599081.0,"this means that even if this criterion holds, one still does not know what a non-legitimate receiver can or cannot do to decode the confidential message. a criterion that can be given an operational meaning is the criterion of strong secrecy introduced by maurer and wolf in [11] : it was established in [12, 13] for the wiretap channel that under the strong secrecy criterion, the average decoding error at a non-legitimate receiver tends to one for any decoder it may use.",{'confidential message'},1.0,is-a,strong secrecy criterion is a criterion that can be given an operational meaning.,strong secrecy criterion,criterion that can be given an operational meaning,no
852,13599081.0,due to the side information at the receivers this differs from the classical broadcast scenario und is therefore known as bidirectional broadcast channel (bbc) with confidential messages. in the following we establish the corresponding secrecy capacity region for the strong secrecy criterion.,"{'confidential message', 'bidirectional broadcast channel'}",0.0,,,,,
853,13599081.0,the set of all achievable rate triples is the strong secrecy capacity region of the bbc with confidential messages and is denoted by c s bbc . theorem 1: the strong secrecy capacity region c s bbc of the bbc with confidential messages is the set of all rate triples,{'confidential message'},0.0,,,,,
854,13599081.0,"in [21] we established the weak secrecy capacity region of the bbc with confidential messages where the condition (1) is replaced by the weaker condition (2) , the weak secrecy capacity region c w bbc establishes immediately the converse for c s bbc . therefore, it remains to show the achievability of (2) for the strong secrecy criterion.",{'confidential message'},0.0,,,,,
855,51926976.0,"the ability to generate natural language sequences from source code snippets has a variety of applications such as code summarization, documentation, and retrieval. sequence-to-sequence (seq2seq) models, adopted from neural machine translation (nmt), have achieved state-of-the-art performance on these tasks by treating source code as a sequence of tokens.",{'code summarization'},1.0,is-a,code summarization is an application of generating natural language sequences from source code snippets.,code summarization,application of generating natural language sequences from source code snippets,no
856,,,,,compare,"code summarization is like [documentation, retrieval] in that they are both applications of generating natural language sequences from source code snippets.",code summarization,"documentation, retrieval",no
857,51926976.0,"specifically, we represent a given code snippet as a set of compositional paths over its abstract syntax tree (ast), where each path is compressed to a fixed-length vector using lstms (hochreiter and schmidhuber, 1997) . during decoding, code2seq attends over a different weighted sum of the path-vectors to produce each output token, much like nmt models attend over token representations in the source sentence.",{'compositional path'},0.0,,,,,
858,11470665.0,"the first one lies in the specification: the more test cases cover a statement, the more difficult it is to synthesize sosies. yet, to our surprise, we are also able to synthesize sosies on highly tested statements (up to 600 test cases), which indicates an intrinsic property of the programs we study.",{'sosie'},0.0,,,,,
859,11470665.0,"yet, to our surprise, we are also able to synthesize sosies on highly tested statements (up to 600 test cases), which indicates an intrinsic property of the programs we study. the second dimension is in the code: we manually explore dozens of sosies and characterize new types of forgiving code regions that are prone to diversification.",{'sosie'},0.0,,,,,
860,11470665.0,"we show that there is a relation between execution signatures and the efficiency of the sosiefication process: the more a statement is tested, the more difficult it is synthesize sosies. however, to our surprise, we are still able to synthesize sosies on highly tested statements (up to 600 test cases).",{'sosie'},0.0,,,,,
861,813729.0,"evaluation has long been a stumbling block in the development of machine translation systems, due to the simple fact that there are many correct translations for a given sentence. human evaluation of system output is costly in both time and money, leading to the rise of automatic evaluation metrics in recent years.",{'machine translation system'},1.0,is-a,"human evaluation is a method which evaluates system output, and which is costly in both time and money.",human evaluation,"method which evaluates system output, and which is costly in both time and money",no
862,813729.0,"human evaluation of system output is costly in both time and money, leading to the rise of automatic evaluation metrics in recent years. the most commonly used automatic evaluation metrics, bleu (papineni et al., 2002) and nist (doddington, 2002) , are based on the assumption that ""the closer a machine translation is to a professional human translation, the better it is"" (papineni et al., 2002) .",{'human evaluation'},1.0,is-a,"bleu is an automatic evaluation metric, that is one of the most commonly used and based on the assumption that ""the closer a machine translation is to a professional human translation, the better it is"".",bleu,automatic evaluation metric,no
863,813729.0,,,,compare,"bleu is like nist in that they are the most commonly used automatic evaluation metrics, based on the assumption that ""the closer a machine translation is to a professional human translation, the better it is"".",bleu,nist,no
864,813729.0,,,,compare,"bleu is an alternative to human evaluation, that is based on the assumption that ""the closer a machine translation is to a professional human translation, the better it is"".",bleu,human evaluation,yes
865,813729.0,"the most commonly used automatic evaluation metrics, bleu (papineni et al., 2002) and nist (doddington, 2002) , are based on the assumption that ""the closer a machine translation is to a professional human translation, the better it is"" (papineni et al., 2002) . for every hypothesis, bleu computes the fraction of n-grams which also appear in the reference sentences, as well as a brevity penalty.",{'bleu'},1.0,is-a,"bleu is an automatic evaluation metric, that is one of the most commonly used, based on the assumption that ""the closer a machine translation is to a professional human translation, the better it is"", and for every hypothesis, it computes the fraction of n-grams which also appear in the reference sentences, as well as a brevity penalty.",bleu,automatic evaluation metric,no
866,813729.0,,,,compare,"bleu is like nist in that they are the most commonly used automatic evaluation metrics, based on the assumption that ""the closer a machine translation is to a professional human translation, the better it is"".",bleu,nist,no
867,813729.0,"for every hypothesis, bleu computes the fraction of n-grams which also appear in the reference sentences, as well as a brevity penalty. nist uses a similar strategy to bleu but further considers that n-grams with different frequency should be treated differently in the evaluation.",{'bleu'},0.0,,,,,
868,17959434.0,the number of frequent subgraphs may still be prohibitive. we develop a mechanism to scale down the number of frequent subgraphs to be indexed.,{'frequent subgraph'},0.0,,,,,
869,17959434.0,"[2002] propose apriori-based algorithms to discover frequent subgraphs. han [2002, 2003] and borgelt and berthold [2002] apply the pattern-growth approach to directly generate frequent subgraphs.",{'frequent subgraph'},0.0,,,,,
870,213176488.0,"in this paper, we propose a real-time high-performance dcnn-based method for robust semantic segmentation of urban street scenes, which achieves a good trade-off between accuracy and speed. specifically, a lightweight baseline network with atrous convolution and attention (lbn-aa) is firstly used as our baseline network to efficiently obtain dense feature maps.",{'urban street scene'},0.0,,,,,
871,213176488.0,extensive experimental results show that the proposed method respectively achieves the accuracy of 73.6% and 68.0% mean intersection over union (miou) with the inference speed of 51.0 fps and 39.3 fps on the challenging cityscapes and camvid test datasets (by only using a single nvidia titan x card). this demonstrates that the proposed method offers excellent performance at the real-time speed for semantic segmentation of urban street scenes.,{'miou'},0.0,,,,,
872,213176488.0,"during the past few years, with the significant development of deep learning [6] , [7] , deep convolutional neural networks (dcnns) [8] have been successfully applied to semantic segmentation.",{'deep convolutional neural network'},1.0,used-for,deep convolutional neural networks are used for semantic segmentation.,deep convolutional neural network,semantic segmentation,yes
873,213176488.0,"[18] , pspnet [11] , duc [19] , refinenet [20] , lrr [21] , dpn [22] , frrn [23] , twocolumn [24] , segnet [25] , sqnet [26] , enet [27] , arxiv:2003.08736v2",{'refinenet'},0.0,,,,,
874,213176488.0,"[23] , twocolumn [24] , segnet [25] , sqnet [26] , enet [27] , arxiv:2003.08736v2 [cs.cv] 3 apr 2020 erfnet [28] , icnet [29] , swiftnetrn","{'segnet', 'enet'}",0.0,,,,,
875,213176488.0,"although several methods [35] , [36] , [37] have been developed to improve the computational efficiency of dcnns, these methods mainly focus on image classification or object detection. recently, due to the increasing demand for real-time inference, fast semantic segmentation begins to attract much attention.","{'image classification', 'object detection'}",0.0,,,,,
876,213176488.0,"recently, due to the increasing demand for real-time inference, fast semantic segmentation begins to attract much attention. among these fast semantic segmentation methods, segnet [25] , sqnet [26] and enet [27] are the representative ones.",{'fast semantic segmentation'},1.0,is-a,enet is a representative fast semantic segmentation method.,enet,representative fast semantic segmentation method,no
877,213176488.0,,,,compare,"enet is a like [segnet, sqnet] in that they are representative fast semantic segmentation methods.",enet,"segnet, sqnet",no
878,213176488.0,"in particular, instead of relying on the complex dcnn models, we adopt a lightweight baseline network (i.e., the modified mobilenetv2 [38] ) with atrous convolution [39] and attention [40] (lbn-aa), which requires little memory and a small amount of parameters to achieve fast inference and comparable accuracy. to effectively deal with the multi-scale problem of semantic segmentation, we develop the distinctive atrous spatial pyramid pooling (daspp) to capture objects and context at multiple scales.",{'atrous convolution'},0.0,,,,,
879,44092587.0,"however, several studies have shown that a common experience is that learning from a formal training program is often not or in a limited way applied on the job (e.g. yamnill & mclean, 2001; saks, 2002) . since baldwin and ford's (1988) highly recognized review of the ""transfer problem"" in training research, an outpouring of conceptual and research-based suggestions have focused on how to lessen the gap between learning and sustained workplace performance (yamnill & mclean, 2001; goldstein & ford, 2002; burke & hutchins, 2007) .",{'mclean'},0.0,,,,,
880,13461521.0,"in this paper, we introduce the notion of an embedded graph grammar which extends the graph grammar model [1] from a purely topological construct to one that includes geometry, continuous dynamics and local conditions on the evolution of those dynamics. we present this model through an example that also highlights a hierarchical and systemsoriented approach to using graph and embedded graph grammars.",{'embed graph grammar'},1.0,is-a,"an embedded graph grammar is a model that extends the graph grammar model from a purely topological construct to one that includes geometry, continuous dynamics and local conditions on the evolution of those dynamics. ",embed graph grammar,model,no
881,4462530.0,"behavior preservation, namely the fact that the behavior of a model is not altered by the transformations, is a crucial property in refactoring. the most common approaches to behavior preservation rely basically on checking given models and their refactored versions.",{'behavior preservation'},1.0,is-a,behavior preservation is a property in refactoring that relies basically on checking given models and their refactored versions.,behavior preservation,property in refactoring,no
882,4462530.0,the most common approaches to behavior preservation rely basically on checking given models and their refactored versions. in this paper we introduce a more general technique for checking behavior preservation of refactorings defined by graph transformation rules.,{'behavior preservation'},0.0,,,,,
883,4462530.0,"in this paper we introduce a more general technique for checking behavior preservation of refactorings defined by graph transformation rules. we use double pushout (dpo) rewriting with borrowed contexts, and, exploiting the fact that observational equivalence is a congruence, we show how to check refactoring rules for behavior preservation without the need of considering specific models.",{'behavior preservation'},0.0,,,,,
884,6837121.0,"dynamic risk measures have been usually studied in stochastic programming settings which we discuss in section 6. recently, dynamic risk measures have been used to formulate risk-averse markov decision processes [21, 13] .",{'dynamic risk measure'},1.0,used-for,dynamic risk measures are used to formulate risk-averse markov decision processes in stochastic programming settings.,dynamic risk measure,formulate risk-averse markov decision processes in stochastic programming settings,no
885,11286860.0,"several researchers have classified and clustered web spam pages. urvoy et al. use html structure to classify web pages, and they develop a clustering method using locality-sensitive hashing to cluster similar spam pages together [27] .",{'web spam page'},0.0,,,,,
886,11286860.0,"distatis is an adaptation of the statis methodology specifically used for the purposes of integrating distance matrices for different input attributes [3] . distatis can be considered a three-way extension of metric multidimensional scaling [15] , which transforms a collection of distance matrices into cross-product matrices used in the crossproduct approach to statis.",{'distatis'},1.0,is-a,"distatis is an adaptation of the statis methodology that is specifically used for the purposes of integrating distance matrices for different input attributes, and can be considered a three-way extension of metric multidimensional scaling, which transforms a collection of distance matrices into cross-product matrices used in the crossproduct approach to statis.",distatis,adaptation of the statis methodology ,no
887,11286860.0,"distatis can be considered a three-way extension of metric multidimensional scaling [15] , which transforms a collection of distance matrices into cross-product matrices used in the crossproduct approach to statis. consensus can be performed between two or more distance matrices by using distatis and then converting the cross-product matrix output into into a (squared) euclidean distance matrix which is the inverse transformation of metric multidimensional scaling [1] .",{'distatis'},1.0,is-a,"distatis is a three-way extension of metric multidimensional scaling, that transforms a collection of distance matrices into cross-product matrices used in the crossproduct approach to statis, and can perform consensus between two or more distance matrices.",distatis,three-way extension of metric multidimensional scaling,no
888,195191782.0,"in our analysis, we find that a popular deep learning-based approach to bioner, known as bidirectional long short-term memory network-conditional random field (bilstm-crf), is correspondingly poor at generalizing. to address this, we evaluate three modifications of bilstm-crf for bioner to improve generalization: improved regularization via variational dropout, transfer learning and multi-task learning.",{'bilstm - crf'},1.0,is-a,"bilstm-crf is the bidirectional long short-term memory network-conditional random field that is a popular deep learning-based approach to bioner, and is correspondingly poor at generalizing.",bilstm - crf,bidirectional long short-term memory network-conditional random field,no
889,195191782.0,,,,is-a,variational dropout is a modification of bilstm-crf for bioner that improves generalization by improved regularization.,variational dropout,modification of bilstm-crf for bioner,no
890,195191782.0,"we found that variational dropout improves out-of-corpus performance by an average of 4.62%, transfer learning by 6.48% and multi-task learning by 8.42%. the maximal increase we identified combines multi-task learning and variational dropout, which boosts out-of-corpus performance by 10.75%.",{'variational dropout'},0.0,,,,,
891,16952206.0,"in the problem of channel resolvability, where a given output probability distribution via a channel is approximated by transforming the uniform random numbers, characterizing the asymptotically minimum rate of the size of the random numbers, called the channel resolvability, has been open. this paper derives formulas for the channel resolvability for a given general source and channel pair.",{'channel resolvability'},1.0,is-a,channel resolvability is the problem that characterizes the asymptotically minimum rate of the size of the uniform random numbers that are transformed to approximate a given output probability distribution via a channel.,channel resolvability,problem,no
892,16952206.0,this paper derives formulas for the channel resolvability for a given general source and channel pair. we also investigate the channel resolvability in an optimistic sense.,{'channel resolvability'},0.0,,,,,
893,16952206.0,"finding the asymptotically minimum rate of the size of the uniform random numbers (channel resolvability) which can approximate a given target output distribution via a channel is called the problem of channel resolvability. when the variational distance between the target output distribution and the approximated distribution is required to be asymptotically not greater than   [0, 1), the problem is called the problem of channel resolvability.",{'channel resolvability'},1.0,is-a,"channel resolvability is a problem that finds the asymptotically minimum rate of the size of the uniform random numbers which can approximate a given target output distribution via a channel, when the variational distance between the target output distribution and the approximated distribution is required to be asymptotically not greater than   [0, 1).",channel resolvability,problem,no
894,16952206.0,"when the variational distance between the target output distribution and the approximated distribution is required to be asymptotically not greater than   [0, 1), the problem is called the problem of channel resolvability. though these problems were introduced by han and verd [3] more than two decades ago, the general formula for the channel resolvability has not been known in general.",{'channel resolvability'},1.0,is-a,"channel resolvability is a problem that requires the variational distance between the target output distribution and the approximated distribution to be asymptotically not greater than   [0, 1).",channel resolvability,problem,no
895,16952206.0,"though these problems were introduced by han and verd [3] more than two decades ago, the general formula for the channel resolvability has not been known in general. a few cases where the channel resolvability has been characterized are the worst input case with  = 0 by hayashi [4] and the case of the stationary memoryless source and channel by watanabe and hayashi [9] .",{'channel resolvability'},0.0,,,,,
896,16952206.0,"a few cases where the channel resolvability has been characterized are the worst input case with  = 0 by hayashi [4] and the case of the stationary memoryless source and channel by watanabe and hayashi [9] . recently, much attention has been paid to the channel resolvability because this technique can be used to guarantee the strong secrecy in physical-layer security systems [1] , [4] .",{'channel resolvability'},1.0,is-a,channel resolvability is a technique that has received much attention because it can be used to guarantee the strong secrecy in physical-layer security systems.,channel resolvability,technique,no
897,16952206.0,"recently, much attention has been paid to the channel resolvability because this technique can be used to guarantee the strong secrecy in physical-layer security systems [1] , [4] . thus, it is desirable to characterize the channel resolvability for a given pair of the input distribution and the general channel.",{'channel resolvability'},1.0,is-a,channel resolvability is a technique that has received much attention because it can be used to guarantee the strong secrecy in physical-layer security systems.,channel resolvability,technique,no
898,55702318.0,"one such rule of thumb is the historically grown custom of increasing the number of features (for convolutions synonymous with kernel or filter) with increasing depth of a convolutional neural network (cnn). perpetuated by perhaps the simplicity and large success of the vgg architecture [1] , more recent work such as residual networks [2] or densely connected networks [3] still follow this design principle.","{'convolutional neural network', 'increase depth'}",0.0,,,,,
899,55702318.0,"one such rule of thumb is the historically grown custom of increasing the number of features (for convolutions synonymous with kernel or filter) with increasing depth of a convolutional neural network (cnn). perpetuated by perhaps the simplicity and large success of the vgg architecture [1] , more recent work such as residual networks [2] or densely connected networks [3] still follow this design principle.","{'convolutional neural network', 'increase depth'}",0.0,,,,,
900,8012279.0,"data from the ucsd network telescope has supported significant research on dos attacks [9] , internet worms and their victims, e.g., code-red, slammer, witty, and the nyxem email virus. data sets curated from telescope observations of these events became a foundation for modeling the top speed of flash worms, the worst-case scenario economic damages from such a worm, the pathways of their spread, and potential means of defense.",{'slammer'},1.0,is-a,slammer is an internet worm.,slammer,internet worm,no
901,,,,,compare,"slammer is like [code-red, witty, the nyxem email virus] in that they are both internet worms. ",slammer,"code-red, witty, the nyxem email virus",no
902,2639559.0,"results: we describe uchime, a new program that detects chimeric sequences with two or more segments. uchime either uses a database of chimera-free sequences or detects chimeras de novo by exploiting abundance data.",{'uchime'},1.0,is-a,uchime is a new program that detects chimeric sequences with two or more segments.,uchime,new program that detects chimeric sequences with two or more segments,no
903,2639559.0,"uchime either uses a database of chimera-free sequences or detects chimeras de novo by exploiting abundance data. uchime has better sensitivity than chimeraslayer (previously the most sensitive database method), especially with short, noisy sequences.",{'uchime'},1.0,compare,"uchime is like chimeraslayer except that it has better sensitivity, especially with short, noisy sequences.",uchime,"chimeraslayer except that it has better sensitivity, especially with short, noisy sequences",no
904,2639559.0,"to improve speed and accuracy of chimera detection, we created a new algorithm, uchime. in our tests, uchime achieved higher sensitivity than the best previous method based on a reference",{'uchime'},1.0,is-a,uchime is an algorithm that achieved higher sensitivity than the best previous method based on a reference.,uchime,algorithm that achieved higher sensitivity than the best previous method based on a reference,no
905,2639559.0,uchime can use a trusted reference database of non-chimeric sequences (like chimeraslayer) and also offers a de novo mode (like perseus). uchime does not require a multiple alignment of the reference database.,{'uchime'},1.0,is-a,"uchime is an alogrithm that does not require a multiple alignment of the reference database, and also offers a de novo mode (like perseus).",uchime,"alogrithm that does not require a multiple alignment of the reference database, and also offers a de novo mode (like perseus)",no
906,2639559.0,"uchime does not require a multiple alignment of the reference database. uchime reports a score for each sequence, allowing the user to trade sensitivity for specificity by adjusting the minimum score threshold used to discriminate chimeras from biological sequences.",{'uchime'},0.0,,,,,
907,7996650.0,"the related graph decomposition (called clique minimal separator decomposition) has given rise to recent interest, see e.g. [7, 9, 11, 17, 22] . this decomposition results in a set of overlapping subgraphs called atoms, characterized as the maximal connected subgraphs containing no clique separator.",{'clique minimal separator decomposition'},1.0,is-a,"clique minimal separator decomposition is a decomposition which results in a set of overlapping subgraphs called atoms, characterized as the maximal connected subgraphs containing no clique separator.",clique minimal separator decomposition,"decomposition which results in a set of overlapping subgraphs called atoms, characterized as the maximal connected subgraphs containing no clique separator",yes
908,174801144.0,"nonetheless, some architectures, such as mobilenet [10, 20] , inception-v1 [23] and densenet [11] still exhibit significant degradation when quantized to 8 bits. mobilenets are of particular interest as they were designed specifically for embedded applications and as such are often deployed in their quantized form.","{'mobilenet', 'densenet'}",1.0,compare,"mobilenet is like [inception-v1, densenet] in that they are both architectures that exhibit significant degradation when quantized to 8 bits.",mobilenet,"inception-v1, densenet",yes
909,,,,,is-a,"[mobilenet, densenet] is an architecture that exhibits significant degradation when quantized to 8 bits.","mobilenet, densenet",architecture that exhibits significant degradation when quantized to 8 bits,no
910,,,,,is-a,mobilenet is an architecture designed specifically for embedded applications and as such are often deployed in their quantized form.,mobilenet,architecture designed specifically for embedded applications and as such are often deployed in their quantized form,no
911,2414783.0,"in this work, we introduce tieredlatency dram (tl-dram), which achieves both low latency and low cost-per-bit. in tl-dram, each long bitline is split into two shorter segments by an isolation transistor, allowing one segment to be accessed with the latency of a short-bitline dram without incurring high cost-per-bit.",{'tl - dram'},1.0,is-a,tl-dram is a method which achieves both low latency and low cost-per-bit.,tl-dram,method which achieves both low latency and low cost-per-bit,no
912,2414783.0,"in our mechanism (tiered-latency dram), each long bitline is split into two shorter segments using an isolation transistor, as shown in fig 2c: the segment that is connected directly to the sense-ampli er is called the near segment, whereas the other is called the far segment. table 1 summarizes the latency and die-size (i.e., costper-bit 2 ) characteristics of tiered-latency dram and other drams (refer to sec 3 for details).",{'tiere - latency dram'},0.0,,,,,
913,2414783.0,"we describe two major ways of leveraging tl-dram: 1) by not exposing the near segment capacity to the os and using it as a hardware-managed cache, and 2) by exposing the near segment capacity to the os and using hardware/software to map frequently accessed pages to the near segment. we propose two new policies to manage the near segment cache that speci cally exploit the asymmetric latency characteristics of tl-dram.",{'tl - dram'},0.0,,,,,
914,2414783.0,"with the same amount of cache capacity, the performance improvement of cached dram (8.3%) is less compared to that of tl-dram (12.8%) for 1-core systems. this is primarily due to the large caching latency incurred by cached dram.","{'tl - dram', 'cached dram'}",1.0,compare,cached dram is like tl-dram except that its performance improvement is less for 1-core systems due to the large caching latency incurred by cached dram.,cached dram,tl-dram,yes
915,2414783.0,"we introduced tiered-latency dram (tl-dram), a dram architecture that provides both low latency (in the common case) and low cost-per-bit. the key idea behind tl-dram is to segment a long bitline using an isolation transistor, creating a segment of rows with low access latency while keeping cost-per-bit on par with commodity dram.","{'tl - dram', 'tiere - latency dram'}",1.0,is-a,tl-dram is a dram architecture that provides both low latency (in the common case) and low cost-per-bit.,tl-dram,dram architecture that provides both low latency (in the common case) and low cost-per-bit,no
916,11279107.0,it takes its origin in the two important papers [3] and [4] where the orthogonal joint diagonalization of matrices and the orthogonal diagonalization of a fourthorder tensor are introduced respectively in link with ica. a generalization to statistics of any order greater than two is done in [5] and the specific case of the orthogonal joint diagonalization of third-order tensors is considered in [6] .,{'orthogonal joint diagonalization'},0.0,,,,,
917,86787580.0,"however, bayesowl does not have query support in sparql format as a query standard in its knowledge base. in addition, bayesowl does not feature a blending process or ""symbiotic mutualism"" between ontologies and bns, so it does not offer ontology enrichment or bn network structural adjustment through structural and parameter learning.",{'bayesowl'},1.0,is-a,bayesowl is a method which does not have query support in sparql format as a query standard in its knowledge base. ,bayesowl,method which does not have query support in sparql format as a query standard in its knowledge base ,no
918,,,,,is-a,"bayesowl is a method which does not feature a blending process or ""symbiotic mutualism"" between ontologies and bns, so it does not offer ontology enrichment or bn network structural adjustment through structural and parameter learning.",bayesowl,"method which does not feature a blending process or ""symbiotic mutualism"" between ontologies and bns",no
919,86787580.0,"ontobayes [16] is the successor of bayesowl, and the two share many similarities. the knowledge structure in ontobayes is simpler than that of bayesowl; ontobayes does not generate additional nodes or control nodes.",{'bayesowl'},1.0,compare,ontobayes is like bayesowl except that the knowledge structure is simpler; ontobayes does not generate additional nodes or control nodes.,ontobayes,bayesowl,yes
920,403182.0,"cogn neurodyn (2012) 6:251-257 doi 10.1007 the two existing models of synaptic consolidation will be presented and compared. finally, the link to behavior will be discussed, followed by a link to reinforcement learning and open computational questions.",{'synaptic consolidation'},0.0,,,,,
921,16517917.0,"furthermore, the split bregman iteration proposed in [30] was shown to be powerful in [30, 45] when it is applied to various pde based image restoration approaches, e.g., rof and nonlocal pde models. the split bregman iteration is further used to develop a fast algorithm for the analysis based approach in frame-based image restoration in [12] .",{'split bregman iteration'},1.0,used-for,"split bregman iteration is used for various pde based image restoration approaches, e.g., rof and nonlocal pde models.",split bregman iteration,"various pde based image restoration approaches, e.g., rof and nonlocal pde models",no
922,,,,,used-for,split bregman is used to develop a fast algorithm for the analysis based approach in frame-based image restoration.,split bregman iteration,develop a fast algorithm for the analysis based approach in frame-based image restoration,yes
923,16517917.0,"the split bregman iteration is further used to develop a fast algorithm for the analysis based approach in frame-based image restoration in [12] . while the balanced approach in frame-based image restoration gives satisfactory simulation results, as shown in [6, 7, 8, 13, 14, 15, 16, 17] , when solved by a variant of the proximal forward-backward splitting algorithm, but the numerical convergence speed achieved is not as fast as the synthesis based approach when solved by the linearized bregman iteration, or the analysis based approach when solved by the split bregman iteration.","{'frame - base image restoration', 'split bregman iteration'}",0.0,,,,,
924,57375797.0,"since their introduction by benczr and karger [stoc'96], cut sparsifiers have proved extremely influential and found various applications. going beyond cut sparsifiers, filtser and krauthgamer [sidma'17] gave a precise classification of which binary boolean csps are sparsifiable.",{'cut sparsifier'},0.0,,,,,
925,13348954.0,"based on the experimental results, the vfh had the best performance to recognize the objects among other global descriptors. ceron and prieto [18] evaluated different combination of three descriptors that are suitable for object recognition and classification: spin images, vfh, and narf (normal aligned radial feature).",{'vfh'},1.0,used-for,vfh is used to recognize the objects among other global descriptors.,vfh,recognize the objects among other global descriptors,no
926,,,,,is-a,"[spin image, vfh] is a descriptor that is suitable for object recognition and classification.","spin image, vfh",descriptor that is suitable for object recognition and classification,no
927,,,,,compare,"spin image is like [vfh, narf] in that they are both descriptors that are suitable for object recognition and classification.",spin image,"vfh, narf",yes
928,13348954.0,"ceron and prieto [18] evaluated different combination of three descriptors that are suitable for object recognition and classification: spin images, vfh, and narf (normal aligned radial feature). the two experiments showed that the vfh outperformed other 3d shape descriptors when used alone.","{'spin image', 'vfh'}",0.0,,,,,
929,13348954.0,"the two experiments showed that the vfh outperformed other 3d shape descriptors when used alone. because vfh has high recognition performance and fast computational properties, it has been widely used for objects recognition and classification [16, [19] [20] [21] .",{'vfh'},1.0,is-a,vfh is a method with high recognition performance and fast computational properties.,vfh,method with high recognition performance and fast computational properties,no
930,13348954.0,"because vfh has high recognition performance and fast computational properties, it has been widely used for objects recognition and classification [16, [19] [20] [21] . in this paper, the vfh of the point cloud data affiliated with waveform features was calculated and employed for concealed cars extraction.",{'vfh'},1.0,used-for,vfh is used for objects recognition and classification.,vfh,objects recognition and classification,no
931,43887.0,"the java anon proxy (also known as jap or web mixes) uses fixed shared routes known as cascades. as with a single-hop proxy, this approach aggregates users into larger anonymity sets, but again an attacker only needs to observe both ends of the cascade to bridge all the system's traffic.",{'web mix'},1.0,is-a,web mixes is an approach which uses fixed shared routes known as cascades.,web mixes,approach which uses fixed shared routes known as cascades,no
932,33599910.0,"this is partially observed through the trust and reputation systems that have being discussed in [3] , [4] , [7] , [9] . in optimis [3] , trust is one of the core component used by sp, along with risk, eco-efficiency and cost for evaluating the ip for their service.",{'trust reputation system'},0.0,,,,,
933,3977229.0,in section 2 we discuss in detail dbscan along with its known optimizations but also its challenges. we then move on to give an overview of advance in section 3 and discuss in more detail the approximate acceleration based on locality sensitive hashing in section 4.2 and the approximation based on representative points in section 5.,{'dbscan'},0.0,,,,,
934,52190751.0,"however, the proposal networks can only detect faces within a small range of sizes. for these faces whose sizes exceed the receptive field, it will fail to capture the global facial characteristics.",{'proposal network'},0.0,,,,,
935,3263491.0,"larank uses gradients as sparingly as svmstruct and yet runs considerably faster. in fact, larank reaches an equivalent accuracy faster than algorithms that use the full gradient information.",{'larank'},1.0,compare,"larank is an alternative to svmstruct, that uses gradients sparingly yet runs considerably faster and reaches an equivalent accuracy faster than algorithms that use the full gradient information.",larank,svmstruct,no
936,3263491.0,"larank generalizes better than perceptron-based algorithms. in fact, larank provides the performance of svmstruct or mcsvm because it solves the same optimization problem.",{'larank'},1.0,compare,"larank is an alternative to perceptron-based algorithms, that generalizes better and provides the performance of svmstruct or mcsvm because it solves the same optimization problem.",larank,perceptron-based algorithm,no
937,3263491.0,"larank achieves nearly optimal test error rates after a single pass over the randomly reordered training set. therefore, larank offers the practicality of an online algorithm.",{'larank'},1.0,compare,larank is like an online algorithm in that it offers the same practicality and achieves nearly optimal test error rates after a single pass over the randomly reordered training set.,larank,online algorithm,no
938,18311759.0,other methods are the transductive support vector machine (tsvm) [3] and semi-supervised svm method (s3vm),{'transductive support vector machine'},0.0,,,,,
939,13401571.0,"previous work (purver et al., 2006; misra et al., 2008; sun et al., 2008; misra et al., 2009; riedl and biemann, 2012) has shown that using topic assignments or topic distributions instead of word frequency can significantly improve segmentation performance. here we consider more advanced topic models that model dependencies between (sub-)sections in a document, such as structured topic models (stms) presented in (du et al., 2010; du et al., 2012b) .","{'topic distribution', 'topic assignment'}",1.0,compare,"[topic distribution, topic assignment] is an alternative to word frequency, that can significantly improve segmentation performance.","topic distribution, topic assignment",word frequency,no
940,13401571.0,,,,is-a,stms is a structured topic model that is an advanced topic model that models dependencies between (sub-)sections in a document.,stms,structured topic model,no
941,13401571.0,"here we consider more advanced topic models that model dependencies between (sub-)sections in a document, such as structured topic models (stms) presented in (du et al., 2010; du et al., 2012b) . stms treat each text as a sequence of segments, each of which is a set of text passages (e.g., a paragraph or sentence).",{'stms'},1.0,is-a,"stms is a structured topic model that is an advanced topic model that models dependencies between (sub-)sections in a document and treats each text as a sequence of segments, each of which is a set of text passages (e.g., a paragraph or sentence).",stms,structured topic model,no
942,13401571.0,we are interested in unsupervised topic segmentation in either written or spoken language. there is a large body of work on unsupervised topic segmentation of text based on lexical cohesion.,{'unsupervised topic segmentation'},0.0,,,,,
943,13401571.0,"in this paper we take a generative approach lying between plda and sits. in contrast to plda, which uses a flat topic model (i.e., lda), we assume each text has a latent topic structure that can reflect the topic coherence pattern, and the model adapts its parameters to the segments to further improve performance.",{'plda'},0.0,,,,,
944,199668887.0,"federated learning produces personalized recommendation models by communicating model building between a central server and mutually disconnected peers holding personal information [10, 22] . thus, federated learning enacts model building centrally on data that is distributed across personal data owners.",{'federated learning'},1.0,used-for,federated learning is used to produce personalized recommendation models by communicating model building between a central server and mutually disconnected peers holding personal information; it enacts model building centrally on data that is distributed across personal data owners.,federated learning,produce personalized recommendation models by communicating model building between a central server and mutually disconnected peers holding personal information; it enacts model building centrally on data that is distributed across personal data owners,no
945,1848384.0,"the attractive properties of printcipher are that all rounds use the same round key and differ only by a round counter and that the linear layer is partially key-dependent. because of these properties, most known cryptanalytic results on printcipher are based on weak keys (see table 1 ).","{'linear layer', 'printcipher'}",0.0,,,,,
946,1848384.0,"because of these properties, most known cryptanalytic results on printcipher are based on weak keys (see table 1 ). the best attack results on printcipher are invariance subspace attacks on the full printcipher-48/96 [8] .",{'printcipher'},0.0,,,,,
947,1848384.0,"in section 2, we describe briefly the structure of printcipher. in section 3, we explain how to construct related-key differential characteristics on printcipher.",{'printcipher'},0.0,,,,,
948,26159004.0,"type-2 fuzzy rough set is a combination of rough sets and type-2 fuzzy sets. as an extension of fuzzy sets, type-2 fuzzy sets [21] are useful in circumstances where it is difficult to determine the exact membership functions of a fuzzy set because the membership degrees are fuzzy themselves.",{'type-2 fuzzy set'},1.0,is-a,"type-2 fuzzy sets are an extension of fuzzy sets, that are useful in circumstances where it is difficult to determine the exact membership functions of a fuzzy set because the membership degrees are fuzzy themselves.",type-2 fuzzy set,extension of fuzzy set,no
949,50787708.0,"in [11] , brafman and domshlak tackle the complexity of determining whether one outcome is preferred to another outcome (dominance testing) which is known for treestructured networks only; moreover, little is known about the consistency of cyclic cp-nets. in this paper they show how the complexity of dominance testing depends on the structure of the cp-net.",{'dominance testing'},1.0,is-a,"dominance testing is a test that is used for determining whether one outcome is preferred to another outcome, which is known for treestructured networks only, and its complexity depends on the structure of the cp-net.",dominance testing,test,no
950,12461081.0,"the state-of-the-art video coding standard h.264/avc [1] was developed by the joint video team of itu-t video coding experts group and iso/iec moving picture experts group. compared to previous the video coding standards, h.264/avc achieves higher coding performance with the use of several advanced coding tools such as variable block sizes for motion estimation (me) and mode decision, multi-reference frames, a motion vector (mv) with quarter-pixel accuracy, a deblocking filter, and context-based adaptive binary arithmetic coding (cabac) [2] .",{'h.264 / avc'},1.0,is-a,"h.264/avc is the state-of-the-art video coding standard, that was developed by the joint video team of itu-t video coding experts group and iso/iec moving picture experts group, and compared to previous the video coding standards, achieves higher coding performance with the use of several advanced coding tools such as variable block sizes for motion estimation (me) and mode decision, multi-reference frames, a motion vector (mv) with quarter-pixel accuracy, a deblocking filter, and context-based adaptive binary arithmetic coding (cabac).",h.264 / avc,state-of-the-art video coding standard,no
951,12461081.0,,,,is-a,deblocking filter is an advanced coding tool that is used by h.264/avc to achieve higher coding performance than previous video coding standards.,deblocking filter,advanced coding tool,no
952,12461081.0,,,,is-a,context-based adaptive binary arithmetic coding (cabac) is an advanced coding tool that is used by h.264/avc to achieve higher coding performance than previous video coding standards.,context-based adaptive binary arithmetic coding,advanced coding tool,no
953,12461081.0,,,,compare,"deblocking filter is like [variable block sizes for motion estimation (me) and mode decision, multi-reference frames, a motion vector (mv) with quarter-pixel accuracy] in that they are advanced coding tools that is used by h.264/avc to achieve higher coding performance than previous video coding standards.",deblocking filter,"variable block sizes for motion estimation (me) and mode decision, multi-reference frames, a motion vector (mv) with quarter-pixel accuracy",no
954,12461081.0,,,,compare,"context-based adaptive binary arithmetic coding (cabac) is like [variable block sizes for motion estimation (me) and mode decision, multi-reference frames, a motion vector (mv) with quarter-pixel accuracy] in that they are advanced coding tools that is used by h.264/avc to achieve higher coding performance than previous video coding standards.",context-based adaptive binary arithmetic coding,"variable block sizes for motion estimation (me) and mode decision, multi-reference frames, a motion vector (mv) with quarter-pixel accuracy",no
955,12461081.0,"[8] employed the sum-of-absolute-transformed-differences to predict the skip mode. in these algorithms [5] [6] [7] [8] , since coding modes excluding the skip mode are considered as a single group, if the skip mode is not determined as the optimal mode, the rdo process is executed for all coding modes.",{'skip mode'},0.0,,,,,
956,1094854.0,"breviz [4] is a tool that locates inter-worksheet smells in spreadsheets, and presents them via data flow diagrams, to improve understanding. ucheck",{'breviz'},1.0,is-a,"breviz is a tool that locates inter-worksheet smells in spreadsheets, and presents them via data flow diagrams, to improve understanding.",breviz,tool,no
957,4718335.0,it is shown that higher orders of minkowski distance and entropy provide accurate quality prediction for the contrast distorted images. the proposed metric performs predictions by extracting only three features from the distorted images followed by a regression analysis.,{'contrast distorted image'},0.0,,,,,
958,4718335.0,"the riqmc was further modified in [21] by computing the phase congruency of the reference and distorted images. in [23] , a more efficient rr-iqa called qmc was proposed that uses entropy and saliency features of the reference and distorted images for quality prediction.",{'phase congruency'},0.0,,,,,
959,4718335.0,"there are limited methods in order to assess quality of the contrast distorted images [25] , [26] . the authors in [25] use a natural scene statistics (nss) induced model to blindly predict the quality of contrast distorted images.",{'distort image'},0.0,,,,,
960,4718335.0,"the authors in [25] use a natural scene statistics (nss) induced model to blindly predict the quality of contrast distorted images. they also use five features based on the nss models of mean, standard deviation, skewness, kurtosis and entropy.","{'natural scene statistic', 'distorted image'}",0.0,,,,,
961,4718335.0,"in this paper, we use higher orders of the minkowski distance along with the power-law transformation and entropy to provide accurate quality predictions for contrast distorted images. in addition, the features of the proposed metric are able to classify type of the contrast distorted images.",{'contrast distorted image'},0.0,,,,,
962,53659094.0,"later, krivelevich and yuster [11] extend the concept of rainbow connection to the vertex version. for more results on rainbow connection and rainbow vertex connection, we refer to the survey [15] .",{'rainbow connection'},0.0,,,,,
963,52920885.0,contemporary techniques in digital print replication of the human iris recreate a more accurate iris image for use in the medical ocular prosthesis industry [11] . paper-based approaches restrict the dynamic pupil membrane observable in the human iris as the paper utilised in these models is a non-stretchable material.,{'human iris'},0.0,,,,,
964,10289085.0,"(2016a) integrate a neural network joint model that has been adapted using native-language-specific learner text as a feature in smt, while chollampatt et al. (2016b) integrate a neural network global lexicon model and a neural network joint model to exploit continuous space representations of words rather than discrete ones, and learn non-linear mappings.",{'neural network joint model'},0.0,,,,,
965,10289085.0,"(2016b) integrate a neural network global lexicon model and a neural network joint model to exploit continuous space representations of words rather than discrete ones, and learn non-linear mappings. present a neural machine translation (nmt) model and propose an approach that tackles the rare-word problem in nmt.",{'neural network joint model'},0.0,,,,,
966,10289085.0,present a neural machine translation (nmt) model and propose an approach that tackles the rare-word problem in nmt. and mizumoto and matsumoto (2016) employ supervised discriminative methods to re-rank the smt decoder's n -best list output based on language model and syntactic features respectively.,{'nmt'},0.0,,,,,
967,3165686.0,"a woban is comprised of a number of segments each containing a wmn at the front end and a pon at the back end. in a woban segment, each onu of the pon is connected to a wireless gateway in the wmn so that users within the coverage area of the wmn are connected to the co via the wmn and the pon.",{'wmn'},0.0,,,,,
968,85459276.0,"the suitability of transfer learning for the task is next studied by applying two existing convnets models (vggnet and resnet) trained on imagenet dataset, through fine-tuning of the last few layers. leave-one-patient-out (lopo) testing, and testing on the holdout dataset are used to evaluate the performance of the convnets.","{'fine - tuning', 'imagenet dataset', 'resnet'}",1.0,type-of,resnet is a type of convnet model.,resnet,convnet,yes
969,16837627.0,"the set of rank-1 games is the smallest extension of zerosum games in the hierarchy, which strictly generalizes zerosum games. for any given constant c, kannan and theobald [8] also construct a rank-1 game, for which the number of connected components of nash equilibria is larger than c.",{'rank-1 game'},1.0,is-a,"rank-1 games is a set of the smallest extension of zerosum games in the hierarchy, that strictly generalizes zerosum games.",rank-1 game,set of the smallest extension of zerosum games in the hierarchy,no
970,16837627.0,"for any given constant c, kannan and theobald [8] also construct a rank-1 game, for which the number of connected components of nash equilibria is larger than c. this shows that the expressive power of rank-1 games is larger than the zero-sum games.",{'rank-1 game'},1.0,compare,"rank-1 games are an alternative to zero-sum games, that have a larger expressive power because for any given constant c, the number of connected components of nash equilibria is larger than c.",rank-1 game,zero-sum game,no
971,16837627.0,"this shows that the expressive power of rank-1 games is larger than the zero-sum games. rank-1 games may also arise in practical situations, in particular the multiplicative games between firms and workers in [1] are rank-1 games.",{'rank-1 game'},1.0,compare,"rank-1 games are an alternative to zero-sum games, that have a larger expressive power.",rank-1 game,zero-sum game,no
972,664362.0,"the gia system [3] improves on gnutella using: topology adaptation, flow control and biased random walks. we do not compare lms and gia, because our model does not allow topology adaptation and, by design, the lms substrate is not responsible for node heterogeneity and node congestion, without which flow control and biased random walks are of no use.",{'gnutella'},0.0,,,,,
973,664362.0,"yappers [6] is a p2p system that, like lms, assumes a ""given topology"" model and combines structured and unstructured designs. in yappers, nodes publish an item by storing it at a node of the 2-hop neighborhood, which is structured as a small dht.",{'yapper'},1.0,is-a,"yappers is a p2p system that, like lms, assumes a ""given topology"" model, combines structured and unstructured designs, and nodes publish an item by storing it at a node of the 2-hop neighborhood, which is structured as a small dht.",yappers,p2p system,no
974,664362.0,,,,compare,"yappers is like lms in that it is a p2p system that assumes a ""given topology"" model and combines structured and unstructured designs.",yappers,lms,no
975,3331242.0,this scheme is inspired by the mceliece scheme but uses another family of codes defined over f 2 128 instead of f2 and is not based on the hamming metric. it allows significantly shorter public keys than the mceliece scheme.,{'mceliece scheme'},0.0,,,,,
976,1924063.0,"alternatively, consider tropos [7] , an agent-oriented software engineering methodology, which uses the i* modelling framework [53] to guide and support the system development process starting from requirements analysis down to implementation. in tropos and i*, goals are explicitly associated with external stakeholders and can be delegated to other actors or the system-to-be.",{'agent - orient software engineering methodology'},1.0,is-a,"tropos is an agent-oriented software engineering methodology, that uses the i* modelling framework to guide and support the system development process starting from requirements analysis down to implementation. ",tropos,agent - orient software engineering methodology,yes
977,1924063.0,,,,compare,"tropos is like i*, in that tropos uses the i* modelling framework to guide and support the system development process starting from requirements analysis down to implementation and their goals are explicitly associated with external stakeholders and can be delegated to other actors or the system-to-be.",tropos,i*,no
978,1924063.0,"thus, requirements in tropos and i* are conceived as goals associated to social actors within a network of social dependencies. in this setting, selecting a set of assignments is more complex than in kaos because delegations can be transitive and iterative. ''",{'tropos'},1.0,compare,"tropos is like i* in that their requirements are conceived as goals associated to social actors within a network of social dependencies, and in this setting, selecting a set of assignments is more complex than in kaos because delegations can be transitive and iterative. ",tropos,i*,
979,1924063.0,,,,compare,"[tropos, i*] is an alternative to kaos, that makes selecting a set of assignments more complex in a network of social dependencies because delegations can be transitive and iterative.","tropos, i*",kaos,yes
980,1924063.0,"pddl (planning domain definition language) is the widely used specification language proposed in [27] . in the implementation of our approach, we use pddl of the version 2.2 [18] , which supports, among others, derived predicates and timed initial literals.",{'pddl'},1.0,is-a,"pddl is the planning domain definition language, that is a widely used specification language and can support, among others, derived predicates and timed initial literals.",pddl,planning domain definition language,no
981,59155690.0,"these attacks require a bigger amount of samples in comparison to the simple power analysis, so it is usually necessary to have a physical control over the device for a certain period of time. when performing a dpa attack, only the knowledge of the used encryption algorithm is usually needed.",{'simple power analysis'},0.0,,,,,
982,3824849.0,"the results indicate that the psnr and ssim of the watermarked image are about 46 db and approximately one, respectively. also, the mean of psnr and ssim of several recovered images which has been destroyed about 90% is reached to 24 db and 0.86, respectively.",{'ssim'},0.0,,,,,
983,210701113.0,"we introduce the code i-flow, a python package that performs high-dimensional numerical integration utilizing normalizing flows. normalizing flows are machine-learned, bijective mappings between two distributions.",{'normalize flow'},1.0,is-a,"normalizing flows are machine-learned, bijective mappings between two distributions.",normalize flow,"machine-learned, bijective mappings between two distributions",no
984,210701113.0,"in section 3, we review the concept of normalizing flows and work done on cl-based flow by [28] [29] [30] [31] . we investigate the minimum number of cls required to capture the correlations between every other input dimension.",{'normalize flow'},0.0,,,,,
985,10472668.0,"recently, there has been one attempt to perform the tranformations on forests without going through binary trees in [ps04] , where the notion of macro forest transducer is considered. compared to our work, macro forest transducers define a restricted class of forest rewrite systems.",{'macro forest transducer'},1.0,is-a,macro forest transducers are a restricted class of forest rewrite systems.,macro forest transducer,restricted class of forest rewrite systems,no
986,204934851.0,"since our first works proposing a crdt for concurrent editing [64, 56] and later laying the theoretical foundations of crdts [65] , crdts have become mainstream and are used in a large number of systems serving millions of users worldwide. currently, an application can use crdts by either using a storage system that offers crdts in its interface,by embedding an existing crdt library or implementing its own support.","{'crdts', 'crdt'}",0.0,,,,,
987,204934851.0,"section 2 discusses the aspects that are important for an application developer that uses crdts to maintain the state of her application. as any abstract data type, a crdt implements some given functionality and important aspects that must be considered include the time complexity for operation execution and the space complexity for storing data and for synchronizing replicas.",{'crdts'},1.0,is-a,"crdt is an abstract data type, that implements some given functionality and important aspects that must be considered include the time complexity for operation execution and the space complexity for storing data and for synchronizing replicas.",crdt,abstract data type,no
988,204934851.0,"as any abstract data type, a crdt implements some given functionality and important aspects that must be considered include the time complexity for operation execution and the space complexity for storing data and for synchronizing replicas. however, as crdts are designed to be replicated and to allow uncoordinated updates, a key aspect of a crdt is its semantics in the presence of concurrency -this section focuses on this aspect.",{'crdt'},1.0,is-a,"crdt is an abstract data type, that implements some given functionality and is designed to be replicated and to allow uncoordinated updates, a key aspect is its semantics in the presence of concurrency.",crdt,abstract data type,no
989,204934851.0,section 3 discusses the aspects that are important for the system developer that needs to create a system that includes crdts. these developers need to focus on another key aspect of crdts: the synchronization model.,{'crdts'},0.0,,,,,
990,43047480.0,"the surf detector is based on the hessian matrix [8] , but uses a very basic approximation, just as dog (difference of gaussians) is a very basic laplacian-based detector. it relies on integral images to reduce the computation time and we therefore call it the 'fast-hessian' detector.",{'surf detector'},1.0,based-on,"the surf detector is based on the hessian matrix, except it uses a very basic approximation, just as dog (difference of gaussians) is a very basic laplacian-based detector, and it relies on integral images to reduce the computation time and is therefore called the 'fast-hessian' detector.",surf detector,the hessian matrix,no
991,8297152.0,"scheduling the execution of multiple concurrent tasks on shared resources such as cpus and network links is essential to ensuring the reliable operation of many autonomic systems. well known techniques such as rate-monotonic scheduling can offer rigorous timing and preemption guarantees, but only under assumptions (i.e., a fixed set of tasks with well-known execution times and invocation rates) that do not hold in many autonomic systems.",{'autonomic system'},1.0,is-a,"rate-monotonic scheduling is a well known technique that can offer rigorous timing and preemption guarantees, but only under assumptions (i.e., a fixed set of tasks with well-known execution times and invocation rates) that do not hold in many autonomic systems.",rate - monotonic scheduling,well known technique,no
992,8297152.0,"well known techniques such as rate-monotonic scheduling can offer rigorous timing and preemption guarantees, but only under assumptions (i.e., a fixed set of tasks with well-known execution times and invocation rates) that do not hold in many autonomic systems. new hierarchical scheduling techniques are better suited to enforce the more flexible execution constraints and enforcement mechanisms that are required for autonomic systems, but a rigorous foundation for verifying and enforcing concurrency and timing guarantees is still needed for these approaches.","{'autonomic system', 'rate - monotonic scheduling'}",1.0,is-a,"rate-monotonic scheduling is a well known technique that can offer rigorous timing and preemption guarantees, but only under assumptions (i.e., a fixed set of tasks with well-known execution times and invocation rates) that do not hold in many autonomic systems.",rate - monotonic scheduling,well known technique,no
993,8297152.0,"new hierarchical scheduling techniques are better suited to enforce the more flexible execution constraints and enforcement mechanisms that are required for autonomic systems, but a rigorous foundation for verifying and enforcing concurrency and timing guarantees is still needed for these approaches. the primary contributions of this paper are: (1) a scheduling policy design technique that can use different decision models across a wide range of systems models, and an example of how a specific (markov decision process) decision model can be applied to a basic multi-threaded system model; (2) novel model checking techniques that can evaluate the behavior of the system model when it is placed under the control of the resulting scheduling policy; and (3) an evaluation of those scheduling policy design and model checking techniques for a simple but representative example of the kinds of execution scenarios that can arise in autonomic systems.",{'autonomic system'},0.0,,,,,
994,38517615.0,"these systems will be described as coalgebras of so-called polynomial functors, built up from constants and identities, using products, coproducts and powersets. the semantical account involves boolean algebras with operators indexed by polynomial functors, called mbaos, for manysorted boolean algebras with operators, combining standard (categorical) models of modal logic and of many-sorted predicate logic.",{'coalgebra'},1.0,part-of,"coalgebras are a part of polynomial functors, that are built up from constants and identities, using products, coproducts and powersets, and the semantical account involves boolean algebras with operators indexed by polynomial functors, called mbaos, for manysorted boolean algebras with operators, combining standard (categorical) models of modal logic and of many-sorted predicate logic.",coalgebra,polynomial functors,yes
995,12423516.0,"for profiling results from different classifiers (i.e., face profiling and full body profiling), dempster's rule [4, 22] is introduced to combine them. and finally, the pignistic transformation is applied to get the probabilities of the subject being male or female.",{'dempster rule'},0.0,,,,,
996,1268851.0,"shape as well as other perceptual properties such as depth, motion, speed and color are important for object detection and recognition. what makes shape a unique perceptual property is its sufficient complexity to make object detection and recognition possible",{'object detection'},0.0,,,,,
997,5514215.0,"in addition, bbus can be removed, added, and upgraded easily in udcsnet. in a 5g udcsnet, data transmission and many network functions such as cooperative interference management and mobility handover management require efficient fronthauling between the bbu pool and the rrhs.",{'bbus'},0.0,,,,,
998,5514215.0,"mmwave spectrum band can be used for fronthaul links and the access links in udcsnet, while optical fiber is used for backhaul links between the core network and the bbu pool. the bbu pool in this paper is enhanced with centralized processor and collaborative functions to support the heterogeneous rrhs (macro rrh, small rrh, wi-fi rrh).",{'bbu pool'},0.0,,,,,
999,58004748.0,"in this paper we propose a bayesian method for estimating architectural parameters of neural networks, namely layer size and network depth. we do this by learning concrete distributions over these parameters.",{'network depth'},0.0,,,,,
1000,58004748.0,"we do this by learning concrete distributions over these parameters. our results show that regular networks with a learnt structure can generalise better on small datasets, while fully stochastic networks can be more robust to parameter initialisation.",{'concrete distribution'},0.0,,,,,
1001,17352526.0,"boehm projected three levels of the model called basic cocomo, intermediate cocomo and detailed cocomo [3, 5] . in the present paper we mainly focus on the intermediate cocomo.",{'intermediate cocomo'},0.0,,,,,
1002,8541831.0,"the 3dmm fitting proposed in the work of blanz and vetter [11, 12] was among the first model-based 3d facial recovery approaches. the method requires the construction of a 3dmm which is a statistical model of facial texture and shape in a space where there are explicit correspondences.",{'3dmm'},1.0,is-a,3dmm is a statistical model of facial texture and shape in a space where there are explicit correspondences.,3dmm,statistical model of facial texture and shape in a space where there are explicit correspondences,no
1003,,,,,used-for,3dmm is used for fitting in model-based 3d facial recovery approaches.,3dmm,fitting in model-based 3d facial recovery approaches,no
1004,8541831.0,the method requires the construction of a 3dmm which is a statistical model of facial texture and shape in a space where there are explicit correspondences. the first 3dmm was built using 200 faces captured in well-controlled conditions displaying only the neutral expression.,{'3dmm'},1.0,is-a,3dmm is a method built using 200 faces captured in well-controlled conditions displaying only the neutral expression.,3dmm,method built using 200 faces captured in well-controlled conditions displaying only the neutral expression,no
1005,5230241.0,"[9] , the authors observe that their algorithm reduces to solving a meta-svm which can be solved using standard off-the-shelf svm tools such as libsvm. however, despite being highly efficient on few examples, libsvm is very inefficient on more than a few thousand examples due to quadratic scaling [6] .",{'libsvm'},1.0,is-a,libsvm is a standard off-the-shelf svm tool.,libsvm,standard off-the-shelf svm tool,no
1006,,,,,used-for,"libsvm is used for solving a meta-svm, but is very inefficient on more than a few thousand examples due to quadratic scaling.",libsvm,solving a meta-svm,no
1007,4461076.0,"realistic face image synthesis has many real-world applications, such as face super-resolution, frontalization, and morphing, among others. with the emergence of deep generative models, such as the generative adversarial networks (gan) [12] and the variational auto-encoder [18] , we have made tremendous progress in building deep networks for synthesizing realistic faces [37, 21, 36, 21] .",{'frontalization'},1.0,compare,"frontalization is like [face super-resolution, morphing] in that they are both real-world applications of realistic face image synthesis.",frontalization,"face super-resolution, morphing",no
1008,,,,,is-a,frontalization is a real-world application of realistic face image synthesis.,frontalization,real-world application of realistic face image synthesis,no
1009,,,,,compare,generative adversarial network (gan) is like variational auto-encoder in that they are both deep generative models used for building deep networks for synthesizing realistic faces.,generative adversarial network,variational auto-encoder,yes
1010,,,,,is-a,generative adversarial network (gan) is a deep generative model used for building deep networks for synthesizing realistic faces.,generative adversarial network,deep generative model used for building deep networks for synthesizing realistic faces,yes
1011,4461076.0,"to this end, we propose a framework based on generative adversarial networks to disentangle identity and attributes given a face image, and recombine different iden-tities and attributes for identity preserving face synthesis. as shown in figure 2 , our framework has five parts: 1) an identity encoder network i to encode the identities of subjects; 2) an attribute encoder network e to extract attributes of any given face image; 3) a generator network g to synthesize a face image from a combined input of identity and attributes; 4) a classification network c to preserve the identity of the generated face; and 5) a discriminate network d to distinguish real and generated examples.",{'generative adversarial network'},0.0,,,,,
1012,4461076.0,"inspired by the cvae-gan [4] , we adopt a new asymmetric loss function. more specifically, we adopt a crossentropy loss when training the discriminative network d, and the classification network c, and use a pairwise feature matching loss when updating the generative network g.",{'cvae - gan'},0.0,,,,,
1013,4461076.0,"many variants of gans have been proposed to improve the stability of training process [34, 3, 5] . meanwhile, there are also many works that have added condition information to the generative network and the discriminative network for conditional image synthesis.",{'gan'},0.0,,,,,
1014,9288623.0,"deep networks benefit from the feed-forward structure and enjoy much faster inference. however, to maintain their competitive performances, deep networks show demands for increased width (numbers of filters) and depth (number of layers), as well as smaller strides, all leading to growing computational costs [16] .",{'deep network'},0.0,,,,,
1015,63895337.0,the need for the efficient use of the scarce spectrum in wireless applications has led to significant interest in the study of cognitive radio system. one possible scheme for the operation of the cognitive radio network is to allow the secondary users to transmit concurrently on the same frequency band as the primary users when the resulting interference power at the receivers is kept below the interference temperature limit [1] .,{'cognitive radio system'},0.0,,,,,
1016,63895337.0,one possible scheme for the operation of the cognitive radio network is to allow the secondary users to transmit concurrently on the same frequency band as the primary users when the resulting interference power at the receivers is kept below the interference temperature limit [1] . the problem of secure transmission in the presence of an eavesdropper was first studied from an information-theoretic perspective in [2] where wyner considered a wiretap channel model.,"{'secondary user', 'primary user', 'interference temperature limit'}",0.0,,,,,
1017,201103910.0,"the reward is then considered as extrinsic (or is a feedback) because the reward function is provided expertly and specifically for the task. with an extrinsic reward, many spectacular results have been obtained on atari game [bellemare et al., 2015] with the deep q-network (dqn)",{'reward function'},0.0,,,,,
1018,201103910.0,"with an extrinsic reward, many spectacular results have been obtained on atari game [bellemare et al., 2015] with the deep q-network (dqn) [mnih et al., 2015] or on the game of go with alphago zero","{'atari game', 'deep q - network ( dqn )'}",0.0,,,,,
1019,201103910.0,"[mnih et al., 2015] or on the game of go with alphago zero [silver et al., 2017] through the integration of deep learning to rl, leading to the name of deep reinforcement learning (drl).",{'alphago'},0.0,,,,,
1020,201103910.0,"table 1 shows the difference between reinforcement learning and the use of intrinsic motivation. reinforcement learning is an active process since the agent learns from its interactions with the environment, unlike classification or regression which are supervised methods.",{'reinforcement learning'},1.0,compare,"reinforcement learning is an alternative to supervised methods like classification or regression, that is an active process since the agent learns from its interactions with the environment.",reinforcement learning,supervised methods like classification or regression,no
1021,201103910.0,"furthermore, they show the interest of this method as a pre-training for hierarchical reinforcement learning and as initialization for learning a task. diayn chooses f ( ) as a state of the trajectory and computes the intrinsic reward at every iteration of the trajectory.",{'hierarchical reinforcement learning'},0.0,,,,,
1022,212633928.0,"in this context, birdnet was introduced in [1] as an object detection framework aimed to provide 3d detections using bev data only. the method proved the adequacy of applying an image-based detector (faster r-cnn [2] ) to the processing of bev structures, although it also had some limitations stemming from its design.","{'3d detection', 'birdnet'}",1.0,is-a,"birdnet is an object detection framework, that aimed to provide 3d detections using bev data only and proved the adequacy of applying an image-based detector (faster r-cnn) to the processing of bev structures, although it also had some limitations stemming from its design.",birdnet,object detection framework,no
1023,212633928.0,,,,is-a,faster r-cnn is an image-based detector.,fast r - cnn,image-based detector,no
1024,212633928.0,"the method proved the adequacy of applying an image-based detector (faster r-cnn [2] ) to the processing of bev structures, although it also had some limitations stemming from its design. hence, despite being intended to work mostly on an end-to-end basis, birdnet still required a hand-crafted post-processing step to obtain the final rotated 3d box representing each obstacle, as shown in fig. 1 .",{'fast r - cnn'},1.0,is-a,faster r-cnn is an image-based detector.,fast r - cnn,image-based detector,no
1025,18730373.0,"the problem of finding a referring expression for an object is treated as finding the cheapest subgraph of the scene graph which uniquely characterizes the intended referent. for the generation of multimodal referring expressions, the scene graph is enriched with edges representing the various kinds of pointing gestures.",{'scene graph'},0.0,,,,,
1026,8125892.0,"the initial 3d map is usually computed from a homography [17] or an essential matrix [33] . however, the model selection between homography and essential matrix is tricky, as discussed in [47, 32] .",{'homography'},0.0,,,,,
1027,8125892.0,"furthermore, during initialization, the selection between homography and essential matrix is also tricky, as discussed in the orb-slam system [32] . therefore, orb-slam evaluates a model confidence and is only able to start reconstruction once the uncertainty is sufficiently small.",{'homography'},1.0,is-a,orb-slam is a system that evaluates a model confidence and is only able to start reconstruction once the uncertainty is sufficiently small.,orb - slam,system,no
1028,8125892.0,"the map optimization is often solved by a nonlinear least square problem, using advanced libraries such as g2o [27] or ceres [1] , which are designed to efficiently minimize the linearized objective function through an iterative approach. since the objective function is non-convex, a good initialization is critical to the nonlinear optimization in pose-graph.",{'g2o'},1.0,type-of,g2o is a type of advanced library that is used to solve the map optimization by a nonlinear least square problem and is designed to efficiently minimize the linearized objective function through an iterative approach.,g2o,advanced library,no
1029,8125892.0,"since the objective function is non-convex, a good initialization is critical to the nonlinear optimization in pose-graph. direct initialization by visual odometry alone usually produces poor results due to drifting errors, so loop closures [52] are used to reduce the drifting.",{'pose - graph'},1.0,used-for,loop closures are used to reduce the drifting errors from direct initialization by visual odometry in pose-graph.,loop closure,reduce the drifting errors from direct initialization by visual odometry in pose-graph,no
1030,291143.0,"differences in apparent rate computations between pepa and the law of mass action can be easily adapted either way. a main difference between our cgf and pepa, however, is our ability to represent chemical reactions of the form a  r b + c: these reactions require a process to ""split"" in two.",{'pepa'},0.0,,,,,
1031,291143.0,"a main difference between our cgf and pepa, however, is our ability to represent chemical reactions of the form a  r b + c: these reactions require a process to ""split"" in two. pepa, instead, is intentionally restricted to the composition of purely sequential processes, to enable markov chain analysis by linear algebra.",{'pepa'},0.0,,,,,
1032,52945022.0,"by incorporating the salient motion detection and the object proposal, a pixel-wise fusion strategy is developed to effectively remove detection noises, such as dynamic background and stationary objects. furthermore, by leveraging the obtained segmentation from immediately preceding frames, a forward propagation algorithm is employed to deal with unreliable motion detection and object proposals.",{'object proposal'},0.0,,,,,
1033,44826358.0,"visual tracking is an active research topic in the field of computer vision with robotic applications ranging from visual servoing, automatic navigation and robot-human interaction. given the initial state (e.g., position and scale) of a specific target in the first frame of a video or an image sequence, a visual tracker seeks to estimate the states of the target in the subsequent frames.","{'visual tracking', 'visual servoing'}",1.0,is-a,"visual tracking is an active research topic in the field of computer vision that has robotic applications ranging from visual servoing, automatic navigation and robot-human interaction, and seeks to estimate the states of the target in the subsequent frames.",visual tracking,active research topic in the field of computer vision,no
1034,44826358.0,,,,is-a,visual servoing is a robotic application of visual tracking that is an active research topic in the field of computer vision.,visual servoing,robotic application of visual tracking,no
1035,44826358.0,,,,compare,"visual servoing is like [automatic navigation, robot-human interaction] in that they are robotic applications of visual tracking that are active research topics in the field of computer vision.",visual servoing,"automatic navigation, robot-human interaction",no
1036,44826358.0,"given the initial state (e.g., position and scale) of a specific target in the first frame of a video or an image sequence, a visual tracker seeks to estimate the states of the target in the subsequent frames. some state-of-the-art tracking algorithms including tracking-learning-detection (tld), 1 multiple instance learning (mil), 2 structured output tracking with kernels (stuck) 3 and l1 tracker using accelerated proximal gradient (l1apg) 4 have been proposed in recent years.",{'visual tracker'},1.0,used-for,"a visual tracker is used to estimate the states of the target in the subsequent frames given the initial state (e.g., position and scale) of a specific target in the first frame of a video or an image sequence.",visual tracker,"estimate the states of the target in the subsequent frames given the initial state (e.g., position and scale) of a specific target in the first frame of a video or an image sequence",no
1037,44826358.0,,,,is-a,l1 tracker using accelerated proximal gradient (l1apg) is a state-of-the-art tracking algorithm.,accelerate proximal gradient,state-of-the-art tracking algorithm,no
1038,44826358.0,,,,compare,"l1 tracker using accelerated proximal gradient (l1apg) is like [tracking-learning-detection (tld), multiple instance learning (mil), structured output tracking with kernels (stuck)] in that they are state-of-the-art tracking algorithms.",accelerate proximal gradient,"tracking-learning-detection (tld), multiple instance learning (mil), structured output tracking with kernels (stuck)",no
1039,13929398.0,"the local efficiency describes how fault tolerant the system is, which means in case when node i is removed from the graph, how efficient the communication between the first neighbors of i remains. higher values of global and local efficiency suggest a model which is nearer to a small-world model.",{'local efficiency'},1.0,is-a,"local efficiency is a metric that describes how fault tolerant the system is, which means in case when node i is removed from the graph, how efficient the communication between the first neighbors of i remains.",local efficiency,metric that describes how fault tolerant the system is,no
1040,10113401.0,"a partial differential equation (pde) relates the evolution of level set function with the positions of the curve as the curve starts evolving. active contour based models are also used for curve evolution [5, 6] .",{'level set function'},0.0,,,,,
1041,10113401.0,"active contour based models are also used for curve evolution [5, 6] . for active contour models an energy function is minimized to evolve an initial curve.",{'curve evolution'},1.0,used-for,active contour models are used for curve evolution.,active contour models,curve evolution,no
1042,10113401.0,"the speed is evaluated from the position of initial and final contour, change of curvature of initial contour to that of final contour and the optic flow vectors of image sequence as discussed in the next section. note that this curve evolution deforms level set function but does not process contour pixels individually as in active contour [6, 8] .",{'initial contour'},0.0,,,,,
1043,1490304.0,"in recent years, many studies have focused on sentiment classification in the context of machine learning, e.g. to identify that a sentiment is positive or negative. in particular, the bag-of-words method has been popularly used to transform textual data into structured data, in order to enable the direct use of machine learning algorithms for sentiment classification.",{'sentiment classification'},1.0,used-for,"sentiment classification is used for the context of machine learning, e.g. to identify that a sentiment is positive or negative.",sentiment classification,"the context of machine learning, e.g. to identify that a sentiment is positive or negative",no
1044,1490304.0,"in particular, concepts on fuzzy logic, rule based systems and sentiment classification are described. section iii proposes the use of fuzzy rule based systems towards advances in interpretability of computational models for sentiment classification.",{'sentiment classification'},0.0,,,,,
1045,1490304.0,section iii proposes the use of fuzzy rule based systems towards advances in interpretability of computational models for sentiment classification. section iv reports an experimental study to show that fuzzy rule based systems can demonstrate similar or even better accuracy of sentiment classification.,{'sentiment classification'},0.0,,,,,
1046,5883271.0,"in this paper, we revisit the enumeration of directed animals using gas models. we show that there exists a natural construction of random directed animals on any directed graph together with a particles system -a gas model with nearest exclusion -that explains combinatorialy the formal link known between the density of the gas model and the generating function of directed animals counted according to the area.",{'gas model'},1.0,used-for,gas models are used for the enumeration of directed animals.,gas models,the enumeration of directed animals,no
1047,14276533.0,"[4] propose the lrr-graph, which seeks a low-rank representation of the data. by jointly obtaining the representation of all the data under the low-rankness assumption, lrr-graph effectively impose global constraints on the data structure (e.g., multiple subspaces).",{'low - rank representation'},1.0,used-for,"lrr-graph is used to impose global constraints on the data structure (e.g., multiple subspaces).",lrr-graph,"impose global constraints on the data structure (e.g., multiple subspaces)",no
1048,14276533.0,"in this paper, we demonstrate how the label information can be integrated into the construction of lrr-graph, resulting in significantly improvement on the performance of existing ssl methods. further, our framework can be readily applied to other self-representation methods such as 1 -graph, least squares representation [39] , correlation adaptive subspace segmentation [40] , correntropy induced 2 -graph [41] , and the smooth representation [42] .",{'lrr'},1.0,compare,"correlation adaptive subspace segmentation is like [1 -graph, least squares representation, correntropy induced 2 -graph, smooth representation] in that they are both self-representation methods.",correlation adaptive subspace segmentation,"1 -graph, least squares representation, correntropy induced 2 -graph, smooth representation",no
1049,,,,,is-a,correlation adaptive subspace segmentation is a self-representation method.,correlation adaptive subspace segmentation,self-representation method,no
1050,18173800.0,"more recently, reduction rules based on matching theory [28] or on bidimensionality theory [15] have been proposed. in this paper, we develop and push further a kernelization technique used for a few parameterized problems [9, 30] , called conflict packing, which also uses matching arguments.",{'bidimensionality theory'},,,,,,
1051,4012597.0,"a detailed discussion on the diversity order of relay selection for several practical channel estimation techniques is presented in section vi-c, and corresponding numerical examples are given in section vii. these results are based on the exact outage analysis conducted in section iv for rayleigh fading and certain channel estimation techniques, and are extended to nakagami-m fading in section v. prior to the outage analysis, the unified model that incorporates the effects of noisy and outdated channel estimates is presented in section iii.",{'diversity order'},,,,,,
1052,53230629.0,"therefore, in this article, we provide an overview of the current literature on publishing and consuming data on the web by conducting a systematic mapping study. systematic mapping is a protocol-driven methodology for reviewing and synthesizing a research data area [67] .",{'systematic mapping study'},,,,,,
1053,53230629.0,systematic mapping is a protocol-driven methodology for reviewing and synthesizing a research data area [67] . a systematic mapping study typically provides an overview of the research reported in the field and identifies possible issues arising from examining the existing literature.,{'systematic mapping'},,,,,,
1054,16314115.0,"it is known that by restricting the class of formulae it is possible to guarantee that a certain class of proofs, known as uniform proofs, are complete with respect to provability in intuitionistic logic. in this paper we explore the relationship between uniform proofs and classes of formulae more deeply.",{'uniform proof'},,,,,,
1055,16314115.0,in this paper we explore the relationship between uniform proofs and classes of formulae more deeply. firstly we show that uniform proofs arise naturally as a normal form for proofs in rst-order intuitionistic sequent calculus.,{'uniform proof'},1.0,type-of,uniform proofs are a type of normal form for proofs in rst-order intuitionistic sequent calculus.,uniform proof,normal form for proofs in rst-order intuitionistic sequent calculus,no
1056,16314115.0,"firstly we show that uniform proofs arise naturally as a normal form for proofs in rst-order intuitionistic sequent calculus. next we show that the class of formulae known as hereditary harrop formulae are intimately related to uniform proofs, and that we may extract such formulae from uniform proofs in two di erent ways.",{'uniform proof'},1.0,type-of,uniform proofs are a type of normal form for proofs in rst-order intuitionistic sequent calculus.,uniform proof,normal form for proofs in rst-order intuitionistic sequent calculus,no
1057,16314115.0,"next we show that the class of formulae known as hereditary harrop formulae are intimately related to uniform proofs, and that we may extract such formulae from uniform proofs in two di erent ways. we also give results which may be interpreted as showing that hereditary harrop formulae are the largest class of formulae for which uniform proofs are guaranteed to be complete, along the lines of an interpolation theorem.",{'uniform proof'},0.0,,,,,
1058,16314115.0,"a uniform proof is one in which the principal connective of the formula is introduced in the last step of the proof; in other words, when searching for a proof of a given formula, we need only consider the immediate subformulae of the desired conclusion. hence we may think of uniform proofs as goal-directed, in that when searching for a uniform proof of a given goal, we may use the structure of the goal to determine the structure of the proof.",{'uniform proof'},1.0,is-a,"a uniform proof is a proof that introduces the principal connective of the formula in the last step of the proof; in other words, when searching for a proof of a given formula, we need only consider the immediate subformulae of the desired conclusion. ",uniform proof,proof,no
1059,16314115.0,,,,is-a,"uniform proofs are goal-directed proofs, in that when searching for a uniform proof of a given goal, we may use the structure of the goal to determine the structure of the proof.",uniform proof,goal-directed proof,no
1060,16314115.0,"in this paper we examine the relationship between uniform proofs and hereditary harrop formulae, and we give several results which may be interpreted as establishing the maximality of this class of formulae. as uniformity is a property of proofs rather than formulae, it is not strictly possible to establish that a given class of formulae is the largest one for which uniform proofs are complete.",{'uniform proof'},0.0,,,,,
1061,16314115.0,"however, as we shall see, there is a natural relationship between uniform proofs and hereditary harrop formulae. essentially this is that whilst f 1 ; f`u f 2 , there is a hereditary harrop formula d such that d`u f 2 , and d is related to f and f 1 in such a way that d is the formula \doing the work"" in the uniform proof.",{'uniform proof'},1.0,compare,"uniform proofs are like hereditary harrop formulae, in that whilst f 1 ; f`u f 2 , there is a hereditary harrop formula d such that d`u f 2 , and d is related to f and f 1 in such a way that d is the formula \doing the work"" in the uniform proof.",uniform proof,hereditary harrop formula,yes
1062,16314115.0,this occurs by determining when it is possible to permute certain combinations of inference rules so that an arbitrary proof may be converted into a uniform proof. thus we may identify hereditary harrop formulae as a logic programming language purely from the notion of a uniform proof and the proof theory of intuitionistic logic; no prior knowledge of logic programming languages per se is needed.,{'uniform proof'},0.0,,,,,
1063,16314115.0,thus we may identify hereditary harrop formulae as a logic programming language purely from the notion of a uniform proof and the proof theory of intuitionistic logic; no prior knowledge of logic programming languages per se is needed. this suggests that the strategy of studying permutation rules in order to investigate the completeness of goal-directed provability may be used to identify logic programming languages independently of the logic in use; such a strategy has been used to identify logic programming languages in linear logic 8;9),{'uniform proof'},0.0,,,,,
1064,30147060.0,"hitag2 is an encryption algorithm designed by nxp semiconductors that is used in electronic vehicle immobilizers and anti-theft devices. hitag2 uses 48-bit keys for authentication and confidentiality, and due to that feature it is considered an insecure cipher.",{'hitag2'},1.0,is-a,"hitag2 is an encryption algorithm that is designed by nxp semiconductors, used in electronic vehicle immobilizers and anti-theft devices, and uses 48-bit keys for authentication and confidentiality.",hitag2,encryption algorithm,no
1065,30147060.0,,,,type-of,hitag2 is a type of insecure cipher in that it uses 48-bit keys for authentication and confidentiality.,hitag2,insecure cipher,no
1066,30147060.0,"in this contribution, we have focused on the usage of hitag2 as a pke system in a publicly known protocol (verdult et al., 2012) . given the short length of hitag2's keys, this stream cipher has been considered insecure for some years, and as such it can be attacked by using expensive devices such as copacobana (guneysu et al., 2008) .",{'hitag2'},1.0,is-a,hitag2 is an insecure stream cipher in that is has short key lengths and can be attacked by using expensive devices such as copacobana.,hitag2,insecure stream cipher,no
1067,30147060.0,"given the short length of hitag2's keys, this stream cipher has been considered insecure for some years, and as such it can be attacked by using expensive devices such as copacobana (guneysu et al., 2008) . in addition to that, hitag2 suffers from more elaborated cryptographic attacks (courtois et al., 2009; courtois et al., 2011; stembera and novotny, 2011;",{'copacobana'},1.0,is-a,hitag2 is an insecure stream cipher in that is has short key lengths and can be attacked by using expensive devices such as copacobana.,hitag2,insecure stream cipher,no
1068,29159423.0,"[18] presented a novel scheme for combining different modalities of information for egocentric action recognition. from the egocentric video, they extracted dense trajectories and a set of local descriptors across the trajectories.",{'egocentric action recognition'},0.0,,,,,
1069,6783800.0,"to handle with high and more uncertainty in the evaluation and selection processes, the problem is solved by using multi-criteria decision making technique with interval type-2 fuzzy sets. the study contributes the facility location selection literature by introducing the application of fuzzy topsis method with interval type-2 fuzzy sets.",{'type-2 fuzzy set'},0.0,,,,,
1070,6783800.0,"different from the location selection literature, the study employed multicriteria decision making technique with type-2 fuzzy sets during the analysis to handle the uncertainties. the literature has suggested type-2 fuzzy sets in the case of availability of more and high uncertainty.",{'type-2 fuzzy set'},0.0,,,,,
1071,6783800.0,"although this kind of problem has inherently more uncertainty, to the best of the authors' knowledge, there is no study applying type-2 fuzzy sets (t2fss) for a facility location selection problem. on the other hand, researchers 9 have highlighted that there have been a limited number of studies involving industrial applications of t2fss and there has been a need to resolve the problems that were solved by using type-1 fuzzy sets.",{'type-2 fuzzy set'},0.0,,,,,
1072,6783800.0,"on the other hand, researchers 9 have highlighted that there have been a limited number of studies involving industrial applications of t2fss and there has been a need to resolve the problems that were solved by using type-1 fuzzy sets. so, the motivation for conducting the study comes from the literature review indicating the availability and criticality high uncertainties on the location selection decision making process as well as the lack of studies using type-2 fuzzy sets to handle uncertainties and vagueness for solving the problems in the multiple industrial environments.",{'type-1 fuzzy set'},0.0,,,,,
1073,6783800.0,"briefly, the paper aims to solve multi-stage location selection problem by applying fuzzy multi-criteria decision making approach by using type-2 fuzzy sets. in this pursuit, fuzzy topsis (technique for order preference by similarity to ideal solution) approach with type-2 fuzzy sets, developed by chen and lee 10 is employed for a location selection problem.",{'type-2 fuzzy set'},0.0,,,,,
1074,39715157.0,"in [12] , safa et al. proposed a hierarchical routing algorithm which is called cbtrp. for the cbtrp, neighbor nodes self-organize into a cluster structure according to the corresponding trust value.",{'cbtrp'},1.0,type-of,"cbtrp is a type of hierarchical routing algorithm, where neighbor nodes self-organize into a cluster structure according to the corresponding trust value.",cbtrp,hierarchical routing algorithm,no
1075,39715157.0,"for the cbtrp, neighbor nodes self-organize into a cluster structure according to the corresponding trust value. to ensure the safety of data transmission, the cbtrp would send data to trust cluster head directly and apply directed diffusion.",{'cbtrp'},0.0,,,,,
1076,1231017.0,"in this paper we present a nave approach to tackle the problem of cross-lingual wsd and cross-lingual lexical substitution which correspond to the task #2 and #3 of the semeval-2 competition. we used a bilingual statistical dictionary, which is calculated with giza\+\+ by using the eu-roparl parallel corpus, in order to calculate the probability of a source word to be translated to a target word (which is assumed to be the correct sense of the source word but in a different language).",{'cross - lingual lexical substitution'},0.0,,,,,
1077,1231017.0,"it is claimed that wsd is essential for those applications that require of language comprehension modules such as search engines, machine translation systems, automatic answer machines, second life agents, etc. moreover, with the huge amounts of information in internet and the fact that this information is continuosly growing in different languages, we are encourage to deal with crosslingual scenarios where wsd systems are also needed.",{'machine translation system'},1.0,used-for,"wsd systems are used for applications that require language comprehension modules such as search engines, machine translation systems, automatic answer machines, second life agents, etc.",wsd system,"applications that require language comprehension modules such as search engines, machine translation systems, automatic answer machines, second life agents, etc",no
1078,1231017.0,,,,compare,"machine translation systems are like [search engines, automatic answer machines, second life agents] in that they require language comprehension modules.",machine translation system,"search engines, automatic answer machines, second life agents",no
1079,1231017.0,"moreover, with the huge amounts of information in internet and the fact that this information is continuosly growing in different languages, we are encourage to deal with crosslingual scenarios where wsd systems are also needed. despite the wsd task has been studied for a long time, the expected feeling is that wsd should be integrated into real applications such as mono and multi-lingual search engines, machine translation systems, automatic answer machines, etc (agirre and edmonds, 2006) .",{'wsd system'},0.0,,,,,
1080,1231017.0,"despite the wsd task has been studied for a long time, the expected feeling is that wsd should be integrated into real applications such as mono and multi-lingual search engines, machine translation systems, automatic answer machines, etc (agirre and edmonds, 2006) . different studies on this issue have demonstrated that those applications benefit from wsd, such as in the case of machine translation (chan et al., 2007; carpuat and wu., 2007) .","{'wsd task', 'machine translation system'}",1.0,is-a,machine translation is a real application that benefits from wsd.,machine translation,real application,no
1081,1231017.0,"on the other hand, lexical substitution (ls) refers to the process of finding a substitute word for a source word in a given sentence. the ls task needs to be approached by firstly disambiguating the source word, therefore, these two tasks (wsd and ls) are somehow related.",{'source word'},0.0,,,,,
1082,9723691.0,"the resource sharing hypothesis proposes a dynamic distribution of resources over a time span of up to 600 msec during the attentional blink. in contrast, the st 2 model argues that working memory encoding is serial during the attentional blink and that, due to joint consolidation, lag 1 is the only case where resources are shared.",{'attentional blink'},0.0,,,,,
1083,6162778.0,"deep generative models (dgms) characterize the distribution of observations with a multilayered structure of hidden variables under nonlinear transformations. among various deep learning methods, dgms are natural choice for those tasks that require probabilistic reasoning and uncertainty estimation, such as image generation [1] , multimodal learning [30] , and missing data imputation.",{'deep generative model'},1.0,is-a,"deep generative models (dgms) are a deep learning method that characterize the distribution of observations with a multilayered structure of hidden variables under nonlinear transformationsm and are a natural choice for those tasks that require probabilistic reasoning and uncertainty estimation, such as image generation, multimodal learning, and missing data imputation.",deep generative model,deep learning method,no
1084,6162778.0,,,,is-a,image generation is a task that requires probabilistic reasoning and uncertainty estimation.,image generation,task,no
1085,6162778.0,,,,compare,"image generation is like [multimodal learning, missing data imputation] in that they are tasks that require probabilistic reasoning and uncertainty estimation.",image generation,"multimodal learning, missing data imputation",no
1086,6162778.0,"for the arguably more challenging unsupervised learning, [5] presents a generative adversarial network (gan), which adopts a game-theoretical min-max optimization formalism. gan has been extended with success in various tasks [1, 21] .",{'generative adversarial network'},0.0,,,,,
1087,119105191.0,"bow-cnn (johnson and zhang, 2014) learns powerful embedding of small text regions by applying cnn to high-dimensional text data. the embedding of all regions are sent to one or multiple convolutional layers, a pooling layer and the output layer at the end.",{'cnn'},0.0,,,,,
1088,119105191.0,"bow-cnn (johnson and zhang, 2014) learns powerful embedding of small text regions by applying cnn to high-dimensional text data. the embedding of all regions are sent to one or multiple convolutional layers, a pooling layer and the output layer at the end.",{'cnn'},0.0,,,,,
1089,210157149.0,"in this article, we present an overview of the sparse vector transmission (svt), a scheme to transmit a short-sized information after the sparse transformation. we discuss basics of svt, two distinct svt strategies, viz., frequency-domain sparse transmission and sparse vector coding with detailed operations, and also demonstrate the effectiveness in realistic wireless environments.",{'svt'},1.0,is-a,"svt is the sparse vector transmission, that is a scheme that transmits a short-sized information after the sparse transformation. ",svt,sparse vector transmission,no
1090,210157149.0,our intent in this article is to introduce new type of short packet transmission scheme referred to as sparse vector transmission (svt). key idea of svt is to transmit the short-sized information after the sparse vector transformation.,{'svt'},1.0,type-of,svt is a type of short packet transmission scheme that transmits the short-sized information after the sparse vector transformation.,svt,short packet transmission scheme,no
1091,210157149.0,"further, svt can inherently improve the user identification quality and security. in a nutshell, svt is a viable solution for massive machine-type communication (mmtc) and urllc scenarios having many advantages over the conventional packet transmission mechanism.",{'svt'},1.0,type-of,svt is a type of solution that is used for massive machine-type communication (mmtc) and urllc scenarios having many advantages over the conventional packet transmission mechanism and it can inherently improve the user identification quality and security.,svt,solution,no
1092,496982.0,"in this paper, we propose a novel feature extraction algorithm called membership-degree preserving discriminant analysis (mpda) based on the fisher criterion and fuzzy set theory for face recognition. in the proposed algorithm, the membership degree of each sample to particular classes is firstly calculated by the fuzzy k-nearest neighbor (fknn) algorithm to characterize the similarity between each sample and class centers, and then the membership degree is incorporated into the definition of the between-class scatter and the within-class scatter.",{'fuzzy set theory'},0.0,,,,,
1093,496982.0,lpp is a linear algorithm and is able to generate effective maps for both training and test data points. some experiments have shown that lpp can be successfully applied in face recognition.,{'lpp'},1.0,is-a,lpp is a linear algorithm that is able to generate effective maps for both training and test data points and has been shown to be successfully applied in face recognition.,lpp,linear algorithm,no
1094,496982.0,,,,used-for,lpp can be used for face recognition.,lpp,face recognition,no
1095,496982.0,"owing to the success of lpp in face recognition, some improvements have been developed to overcome the limitations of lpp, such as unsupervised discriminant projection (udp) [9] , classcorrelation locality preserving projection [10] , supervised lpp [11] , marginal fisher analysis (mfa)","{'lpp', 'unsupervised discriminant projection'}",1.0,used-for,lpp is used for face recognition.,lpp,face recognition,no
1096,496982.0,,,,compare,unsupervised discriminant projection is like marginal fisher analysis in that they are used to overcome the limitations of lpp.,unsupervised discriminant projection,marginal fisher analysis,yes
1097,496982.0,"[9] , classcorrelation locality preserving projection [10] , supervised lpp [11] , marginal fisher analysis (mfa) [12] , discriminant locality preserving projection (dlpp)",{'marginal fisher analysis'},0.0,,,,,
1098,496982.0,"[12] , discriminant locality preserving projection (dlpp) [13] , local fisher linear discriminant analysis (lfda)",{'dlpp'},0.0,,,,,
1099,8798193.0,"although the pooled features can be directly used for classification, it has two drawbacks: (1) caused from the over-completeness and compositionality of rois in hrd, it tends to be highly correlated and redundant between the variables of pooled features; (2) for a hrd with large number of rois, it produces a huge number of variables in this raw feature representation and may obstruct large-scale image classification. motivated by the success of partial least squares (pls) in computer vision literature [17, 18] , we further employ the pls analysis for dimensionality reduction on the pooled features.","{'pool feature', 'large - scale image classification'}",0.0,,,,,
1100,8798193.0,"motivated by the success of partial least squares (pls) in computer vision literature [17, 18] , we further employ the pls analysis for dimensionality reduction on the pooled features. it can capture the statistical relationship between pooled features and class labels for different visual words, and learn a more compact and discriminative feature representation for classification.",{'pool feature'},0.0,,,,,
1101,52948198.0,"on one hand, the cooperative communication via relaying has been extensively investigated in wireless communication systems to increase the communication rate and improve the communication reliability [20] , [21] , and applied in various other setups such as the wireless powered communication [22] and the wireless powered mec systems [24] . on the other hand, cooperative computation has emerged as a viable technique in mec systems, which enables end users to exploit computation resources at nearby wireless devices (instead of aps or bss).",{'relaying'},1.0,type-of,"relaying is a type of cooperative communication that has been extensively investigated in wireless communication systems to increase the communication rate and improve the communication reliability, and applied in various other setups such as the wireless powered communication and the wireless powered mec systems. ",relaying,cooperative communication,no
1102,2098957.0,this provisional unused segment in the licensed spectrum are known as spectrum holes [3] . spectrum hole is define as the frequency band that has been allocated to a licensed user but it is unutilized at a particular time or location.,{'spectrum hole'},1.0,is-a,spectrum hole is the frequency band that has been allocated to a licensed user but it is unutilized at a particular time or location.,spectrum hole,frequency band,no
1103,2098957.0,"most of the work in the field of crahn has focused on channel scarcity problem at the lower layer (phy, mac), while routing in crahn is largely unexplored. routing in crahn is a very important task having a great effect on the overall performance of the network.",{'crahn'},1.0,is-a,"crahn is a network that has focused on channel scarcity problem at the lower layer (phy, mac), but routing is largely unexplored and is a very important task having a great effect on the overall performance.",crahn,network,no
1104,2098957.0,routing in crahn is a very important task having a great effect on the overall performance of the network. routing in crahn differs from routing in traditional ad hoc networks as it has to adapt to dynamic changes of spectrum due to stochastic behavior of pu and su.,{'crahn'},0.0,,,,,
1105,2098957.0,"routing in crahn differs from routing in traditional ad hoc networks as it has to adapt to dynamic changes of spectrum due to stochastic behavior of pu and su. moreover, routing protocols in crahn must deal with heterogeneity of resources (available channels and available energy).",{'crahn'},0.0,,,,,
1106,2098957.0,"a modified version of leach protocol for cognitive radio sensor network named as cognitive leach (cogleach) is presented in [7] . unlike leach, cogleach considers number of vacant channels to measure the weight for each node.","{'cogleach', 'cognitive radio sensor network'}",1.0,is-a,cogleach is a modified version of leach protocol for cognitive radio sensor network that is named as cognitive leach and considers number of vacant channels to measure the weight for each node.,cogleach,modified version of leach protocol for cognitive radio sensor network,no
1107,2098957.0,,,,compare,cogleach is an alternative to leach that considers number of vacant channels to measure the weight for each node.,cogleach,leach,yes
1108,10682115.0,"(fabian et al., 2015) use attributebased encryption (abe) to protect medical data stored in multi-cloud environments and shared among different cooperative organizations. abe produces encrypted data in a way that only users with specific ""attributes"" can decrypt.",{'abe'},1.0,is-a,"abe is an attributebased encryption, that is used to protect medical data stored in multi-cloud environments and shared among different cooperative organizations, and produces encrypted data in a way that only users with specific ""attributes"" can decrypt.",abe,attributebased encryption,no
1109,10682115.0,"abe produces encrypted data in a way that only users with specific ""attributes"" can decrypt. in essence, abe incorporates access control policies into ciphertexts.",{'abe'},0.0,,,,,
1110,10682115.0,"in essence, abe incorporates access control policies into ciphertexts. the disadvantage of using abe for this purpose is that the loss of a private key that corresponds to an attribute requires the generation of a new key, the distribution of this key to all users that have this attribute, and the appropriate encryption of all files protected by this attribute.",{'abe'},0.0,,,,,
1111,55958889.0,"since baraniuk [5] and others first introduced compressed sensing into high resolution radar in 2007 in rice university, the application of cs theory in radar imaging has attracted more and more attention, and the corresponding basic research has been carried out gradually. in 2009, herman [6] and others research high resolution radar based on cs theory by numerical simulation, the effect of modeling scene of transmitting signals to a generalized linear operator, the proposed method overcomes the shortcomings of the traditional radar ambiguity function and time-frequency uncertainty principle of target range and velocity resolution limit, and makes possible that obtains both target distance and doppler super-resolution at the same time with mono-pulse radar.",{'cs theory'},0.0,,,,,
1112,60619880.0,"in [15] , zhang et al. investigated collaborative task execution between md and cloud clone for mobile applications under the stochastic wireless channel. in [16] , zhang et al. proposed an energy-optimal execution strategy for the mcc under the stochastic wireless channel.",{'stochastic wireless channel'},0.0,,,,,
1113,202728518.0,"third combination includes orb, brute force (knn) and ransac. fourth combination contains orb, brute force (knn) and prosac.",{'ransac'},0.0,,,,,
1114,32735963.0,"a rigorous definition of the differential resultant res(p), of a set p of n sparse generic ordinary laurent differential polynomials in n  1 differential variables, has been recently presented in [21] (and in [15] , for the non sparse nonhomogeneous polynomial case), together with a single exponential algorithm in terms of bounds for degree and order of derivation. a matrix representation of the sparse differential resultant does not exist even for the simplest cases and, as noted in [21] , having macaulay style formulas in the differential case would improve the existing bounds for degree and order.",{'differential resultant'},0.0,,,,,
1115,23559790.0,by far the most popular solution to the constrained point-cloud registration problem is the iterative closest point icp algorithm [2] . icp works directly on the point-clouds by alternating between performing point matching using point-to-point nearest neighbour matching and recomputing the relative transform between the two frames such that it minimizes the l2-norm of the matches.,{'icp'},1.0,is-a,"icp is the iterative closest point algorithm, that is the most popular solution to the constrained point-cloud registration problem and works directly on the point-clouds by alternating between performing point matching using point-to-point nearest neighbor matching and recomputing the relative transform between the two frames such that it minimizes the l2-norm of the matches.",icp,iterative closest point algorithm,no
1116,23559790.0,"we will refer to the first step of icp, where nearest neighbour matching between the point-clouds is performed, as the matching step. the second step of the icp algorithm where eq.",{'icp'},0.0,,,,,
1117,23559790.0,irls is performed using eq. (3) where k indicates the iteration of the irls and the superscripts indicate the t that the residuals were computed with.,{'irl'},0.0,,,,,
1118,366803.0,"this paper compares kernel-based probabilistic neural networks for speaker verification based on 138 speakers of the yoho corpus. experimental evaluations using probabilistic decision-based neural networks (pdbnns), gaussian mixture models (gmms) and elliptical basis function networks (ebfns) as speaker models were conducted.",{'speaker verification'},0.0,,,,,
1119,366803.0,"experimental evaluations using probabilistic decision-based neural networks (pdbnns), gaussian mixture models (gmms) and elliptical basis function networks (ebfns) as speaker models were conducted. the original training algorithm of pdbnns was also modified to make pdbnns appropriate for speaker verification.","{'speaker model', 'probabilistic decision - base neural network'}",0.0,,,,,
1120,366803.0,"early work that based on these approaches typically use data from the target speakers only to train the speaker models. as a result, discriminative information from non-target speakers (also known as anti-speakers or background speakers) will not be embedded in the speaker models.",{'speaker model'},0.0,,,,,
1121,366803.0,speaker models trained by using clean speech signals are usually subject to performance degradation in noisy environments. the present study compares the speaker verification performance of three kernel-based speaker models under clean and noisy environments.,{'speaker model'},0.0,,,,,
1122,11770599.0,"[7] using ccalc, while [5] extends the planning domain description language pddl [6] to support external predicates/functions (called semantic attachments) and modifies the planner ff [11] accordingly.",{'ccalc'},1.0,is-a,semantic attachments are external predicates/functions that are supported by the planning domain description language pddl extended in ccalc.,semantic attachment,external predicates/functions,no
1123,65323843.0,"sisr concerns the problem of estimating an underlying hr image, given a single lr image of the scene, under the assumption that the original imaging set up is not available. being an ill-posed problem, since several hr may correspond to the input lr image, sisr can be likened to ordinary ""analytical"" interpolation -like linear, bicubic, and cubic splines.",{'sisr'},1.0,is-a,"sisr is a problem that estimates an underlying hr image, given a single lr image of the scene, under the assumption that the original imaging set up is not available.",sisr,problem,no
1124,65323843.0,,,,compare,"sisr is like ordinary ""analytical"" interpolation -like linear, bicubic, and cubic splines- in that several hr may correspond to the input lr image, making it an ill-posed problem.",sisr,"ordinary ""analytical"" interpolation -like linear, bicubic, and cubic splines",no
1125,65323843.0,"note that most ""of the recent sisr methods fall into the example based methods which try to learn prior knowledge from lr and hr pairs, thus alleviating the ill-posedness of sisr. representative methods include neighbor embedding regression [45] - [47] , random forest [48] , [49] and deep convolutional neural network(cnn)",{'sisr'},0.0,,,,,
1126,8035897.0,"they achieved a classification accuracy of 94.8% with svm, while cnn had an accuracy of 83%. as they have mentioned in their paper, the main reason of not having better results with cnn is the insufficient number of images in their training set.",{'cnn'},0.0,,,,,
1127,8491656.0,the idea is that we transfer the question of algebraic conservativity to that of operational conservativity rather than to perform a term rewriting analysis. the only thing that remains to be done in order to prove the operational conservativity is to check our simple conditions for the operational rules.,{'operational conservativity'},0.0,,,,,
1128,15066114.0,"most geographic routing protocols use greedy forwarding as their basic mode of operation, where the next forwarding hop is the closest node to the destination among its neighbors. greedy forwarding, however, fails in the presence of a void or an obstacle [1, 2] .",{'greedy forwarding'},1.0,is-a,"greedy forwarding is a mode of operation that is used for most geographic routing protocols, where the next forwarding hop is the closest node to the destination among its neighbors, however, it fails in the presence of a void or an obstacle.",greedy forwarding,mode of operation,no
1129,15066114.0,"the proposed protocol inherits the group motion support of landmark routing (lanmar). as in lanmar, a landmark node is elected within each group; the election procedure is dynamic and is described in detail in [8, 20] .",{'landmark routing'},1.0,is-a,"lanmar is the landmark routing protocol, that elects a landmark node within each group in a dynamic election procedure.",lanmar,landmark routing,yes
1130,15066114.0,"as in lanmar, the link state routing scheme is applied locally with a scope up to k hops. as a departure from lanmar, geo-lanmar uses geo-routing instead of dsdv to route packets to remote nodes.",{'lanmar'},0.0,,,,,
1131,15066114.0,"the geo-lanmar protocol has been compared with gpsr [2] , aodv [14] and lanmar via extensive simulation experiments.",{'gpsr'},0.0,,,,,
1132,67870191.0,"it is much less known, however, whether or not there are good lattice rules for function spaces consisting of non-periodic smooth functions. in [22] , it was proven that the shift-averaged worst-case error of randomly shifted lattice rules in weighted non-periodic sobolev spaces of first order smoothness, i.e., function spaces which consist of non-periodic functions such that the mixed first partial derivatives are square-integrable, coincides with the worst-case error of (deterministic) lattice rules in korobov spaces with modified weights.",{'good lattice rule'},0.0,,,,,
1133,2554264.0,"we present shapenet: a richly-annotated, large-scale repository of shapes represented by 3d cad models of objects. shapenet contains 3d models from a multitude of semantic categories and organizes them under the wordnet taxonomy.",{'shapenet'},1.0,is-a,"shapenet is a richly-annotated, large-scale repository of shapes that is represented by 3d cad models of objects from a multitude of semantic categories and organizes them under the wordnet taxonomy.",shapenet,"richly-annotated, large-scale repository of shapes",no
1134,2554264.0,"[2] , correspondences [13, 12] , hierarchies [19] , symmetries [11] , salient features [3] , semantic segmentations and labels [36] , alignments of 3d models with images [35] , semantic ontologies [5] , and other functional annotations -but again only for small size datasets. for example, the benchmark for 3d mesh segmentation contains just 380 models in 19 object classes [2] .",{'semantic segmentation'},0.0,,,,,
1135,2554264.0,"[2] , correspondences [13, 12] , hierarchies [19] , symmetries [11] , salient features [3] , semantic segmentations and labels [36] , alignments of 3d models with images [35] , semantic ontologies [5] , and other functional annotations -but again only for small size datasets. for example, the benchmark for 3d mesh segmentation contains just 380 models in 19 object classes [2] .",{'semantic segmentation'},0.0,,,,,
1136,15446155.0,"we adapted wixom and todd's (2005) model to explain a conceptual gap between system characteristics (specifically, information quality) and system use, which mclean's (1992, 2003 ) milestone models of system success have not addressed in full. wixom and todd (2005) filled the gap by reasoning that users' evaluation of system characteristics (""object-based beliefs"") impacts their affective feeling toward those characteristics (""object-based attitudes""), which, in turn, exerts influence on two tam predictors of use -perceived usefulness and perceived ease of use (""behavioral beliefs"").",{'mclean'},0.0,,,,,
1137,10342474.0,"applying tree assignments to component trees for obtaining cosegmentations is a novel contribution in this work. in fact, cosegmentations promise to be useful in other bioimaging (and eventually image processing) applications beyond cell tracking.",{'cosegmentation'},1.0,used-for,cosegmentation is used for bioimaging (and eventually image processing) applications beyond cell tracking.,cosegmentation,bioimaging (and eventually image processing) applications beyond cell tracking,no
1138,10342474.0,"in fact, cosegmentations promise to be useful in other bioimaging (and eventually image processing) applications beyond cell tracking. one straightforward application where cosegmentation is of high relevance are protein colocalization studies.",{'cosegmentation'},1.0,used-for,cosegmentation is used for bioimaging (and eventually image processing) applications beyond cell tracking.,cosegmentation,bioimaging (and eventually image processing) applications beyond cell tracking,no
1139,10342474.0,,,,part-of,cosegmentation is a part of protein colocalization studies.,cosegmentation,protein colocalization studies,no
1140,52040261.0,"in this paper, a novel, dual-mode model predictive control framework is introduced that combines the dynamic window approach to navigation with reference tracking controllers. this adds a deliberative component to the obstacle avoidance guarantees present in the dynamic window approach as well as allow for the inclusion of complex robot models.",{'dynamic window approach'},1.0,used-for,the dynamic window approach is used for navigation with an obstacle avoidance guarantee.,dynamic window approach,navigation with an obstacle avoidance guarantee,no
1141,15434500.0,"in [8] proposed a novel technique called growth codes to increase data persistence in wireless sensor networks, i.e. increasing the amount of information that can be recover at the sink. growth codes is a linear technique that information is encoded in an online distributed way with increasing degree.",{'growth code'},1.0,is-a,"growth codes are a novel technique, that increase data persistence in wireless sensor networks, i.e. increasing the amount of information that can be recover at the sink.",growth code,novel technique,no
1142,15434500.0,,,,is-a,growth codes is a linear technique that information is encoded in an online distributed way with increasing degree.,growth code,linear technique,no
1143,15434500.0,"they showed that growth codes can increase the amount of information that can be recovered at any storage node at any time period whenever there is a failure in some other nodes. they do not use robust or soliton distributions, however, they propose a new distribution depending on the network condition to determine degrees of the storage nodes.",{'growth code'},0.0,,,,,
1144,16982644.0,"several proposals have recently appeared in the literature focused on the formalisation of compensable processes using process calculi. they can be roughly divided into two types: (i) compensable flow composition [6, 5, 7] closer to the spirit of orchestration languages like bpel4ws, where suitable process algebras are designed from the scratch to describe the possible flow of control among services; and (ii) interaction based compensations [1, 4, 9, 11] , as suitable extensions of well-known name passing calculi, like the -calculus and join-calculus, for describing transactional choreographies, where each service describes its possible interactions, and the actual composition takes place dynamically, i.e. when services interact.",{'compensable process'},0.0,,,,,
1145,14727794.0,"alamouti introduced a simple but effective diversity scheme in [12] for two transmit antennas and achieved maximum diversity gain but no coding gain with minimum decoding complexity. using two transmit antenna system and one receive antenna, the scheme provides the same diversity order as maximal ratio receiver combining (mrrc)",{'alamouti'},0.0,,,,,
1146,5645590.0,"for the discussion search task, we compare two methods for incorporating thread evidence into the language models of email messages. for the expert finding task, we create implicit expert representations as mixtures of language models from associated documents.",{'language model'},0.0,,,,,
1147,2948298.0,"in the same vein, proposed a simple baseline for the task of vqa. this baseline simply concatenates the bag of words (bow) features from the question and convolutional neural networks (cnn) features from the image to predict the answer.",{'vqa'},0.0,,,,,
1148,2065400.0,"we introduce the brat rapid annotation tool (brat), an intuitive web-based tool for text annotation supported by natural language processing (nlp) technology. brat has been developed for rich structured annotation for a variety of nlp tasks and aims to support manual curation efforts and increase annotator productivity using nlp techniques.",{'brat'},1.0,is-a,"brat is an intuitive web-based tool for text annotation that stands for brat rapid annotation tool, is supported by natural language processing (nlp) technology, has been developed for rich structured annotation for a variety of nlp tasks and aims to support manual curation efforts and increase annotator productivity using nlp techniques.",brat,intuitive web-based tool for text annotation,no
1149,2065400.0,,,,used-for,brat is used for a nlp tasks.,brat,nlp task,yes
1150,2065400.0,"brat has been developed for rich structured annotation for a variety of nlp tasks and aims to support manual curation efforts and increase annotator productivity using nlp techniques. we discuss several case studies of real-world annotation projects using pre-release versions of brat and present an evaluation of annotation assisted by semantic class disambiguation on a multicategory entity mention annotation task, showing a 15% decrease in total annotation time.","{'brat', 'nlp task'}",1.0,used-for,brat is used for a nlp tasks.,brat,nlp task,yes
1151,2065400.0,,,,used-for,brat is used for rich structured annotation for a variety of nlp tasks and aims to support manual curation efforts and increase annotator productivity using nlp techniques.,brat,rich structured annotation for a variety of nlp tasks and aims to support manual curation efforts and increase annotator productivity using nlp techniques,no
1152,2065400.0,"we discuss several case studies of real-world annotation projects using pre-release versions of brat and present an evaluation of annotation assisted by semantic class disambiguation on a multicategory entity mention annotation task, showing a 15% decrease in total annotation time. brat is available under an opensource license from: http://brat.nlplab.org",{'brat'},0.0,,,,,
1153,2065400.0,"we have introduced brat, an intuitive and userfriendly web-based annotation tool that aims to enhance annotator productivity by closely integrating nlp technology into the annotation process. brat has been and is being used for several ongoing annotation efforts at a number of academic institutions and has so far been used for the creation of well-over 50,000 annotations.",{'brat'},1.0,is-a,brat is an intuitive and userfriendly web-based annotation tool that aims to enhance annotator productivity by closely integrating nlp technology into the annotation process. ,brat,intuitive and userfriendly web-based annotation tool,no
1154,2065400.0,,,,used-for,"brat is used for several ongoing annotation efforts at a number of academic institutions and has so far been used for the creation of well-over 50,000 annotations.",brat,"several ongoing annotation efforts at a number of academic institutions and has so far been used for the creation of well-over 50,000 annotations",no
1155,2065400.0,"the design and implementation of brat was informed by experience from several annotation tasks and research efforts spanning more than a decade. a variety of previously introduced annotation tools and approaches also served to guide our design decisions, including the fast annotation mode of knowtator (ogren, 2006) , the search capabilities of the xconc tool (kim et al., 2008) , and the design of web-based systems such as myminer (salgado et al., 2010) , and gate teamware (cunningham et al., 2011) .",{'brat'},1.0,is-a,"myminer is a web-based system that served to guide the design decisions for the annotation tool, brat.",myminer,web-based system,no
1156,2065400.0,,,,is-a,"brat is an annotation tool that was guided by previously introduced annotation tools and approaches, including the fast annotation mode of knowtator, the search capabilities of the xconc tool, and the design of web-based systems such as myminer, and gate teamware.",brat,annotation tool,no
1157,22689427.0,"using datasets of stimuli inspired by the original cognitive psychology experiments, we find that state-of-the-art one shot learning models trained on imagenet exhibit a similar bias to that observed in humans: they prefer to categorize objects according to shape rather than color. the magnitude of this shape bias varies greatly among architecturally identical, but differently seeded models, and even fluctuates within seeds throughout training, despite nearly equivalent classification performance.",{'imagenet'},1.0,compare,shape bias is like human bias in that objects are categorized according to shape rather than color.,shape bias,human bias,no
1158,22689427.0,,,,used-for,"imagenet is used for training state-of-the-art one shot learning models, and they exhibit a similar bias to that observed in humans: they prefer to categorize objects according to shape rather than color.",imagenet,"training state-of-the-art one shot learning models, and they exhibit a similar bias to that observed in humans: they prefer to categorize objects according to shape rather than color.",no
1159,22689427.0,"there is high variance in the bias between inception networks initialized with different random seeds, demonstrating that otherwise identical networks converge to qualitatively different solutions. 3) mns also have a strong shape bias, and this bias closely mimics the bias of the inception model that provides input to the mn.",{'inception network'},1.0,compare,"the inception model is like mns in that mns have a strong shape bias, and this bias closely mimics the bias of the inception model that provides input to the mn.",inception model,mns,no
1160,10075105.0,"this catalogue of reconciliation patterns is based on the core modeling elements of web modeling languages, which have been jointly developed in the mdwenet initiative [14, 18] . for demonstrating the proposed approach, we use webml as selected mdwe protagonist.",{'web modeling language'},0.0,,,,,
1161,7605892.0,"moreover, in general, one cannot simply restrict the inputs to be gaussian in the limiting expression to characterize the capacity region of the gaussian interference channel [6] , [7] . a single-letter capacity expression 1 for the discrete memoryless interference channel is unknown, except for the strong interference regime [8] .",{'gaussian interference channel'},0.0,,,,,
1162,8812543.0,"the company wants to target key potential customers s of the social network and persuade them into adopting the new product by handing out free samples. we assume that individuals in s will be convinced to adopt the new product after they receive a free sample, and the friends of customers in s would be persuaded into buying the new product, which in turn will recommend the product to other friends.",{'free sample'},0.0,,,,,
1163,8812543.0,"on the other hand, honeycomb networks have been suggested as an attractive architecture for interconnected networks which have been widely investigated in parallel and distributed applications (see [3, 30] and references therein). in this paper, we study target set selection problem under strict majority thresholds on different kinds of honeycomb networks such as honeycomb mesh hm t , honeycomb torus ht t , honeycomb rectangular torus hret(m, n), honeycomb rhombic torus hrot(m, n), generalized honeycomb rectangular torus ght(m, n), planar hexagonal grid phg(m, n), cylindrical hexagonal grid chg(m, n), and toroidal hexagonal grid thg(m, n) (all terms will be defined in later sections).",{'honeycomb network'},1.0,is-a,honeycomb networks are an architecture that can be used for interconnected networks.,honeycomb network,architecture,no
1164,8812543.0,,,,type-of,honeycomb meshhm t is type of honeycomb network that can be used for the target set selection problem under strict majority thresholds.,honeycomb mesh,honeycomb network,yes
1165,8812543.0,,,,compare,"honeycomb meshhm t is like [honeycomb torus ht t, honeycomb rectangular torus hret(m, n), honeycomb rhombic torus hrot(m, n), generalized honeycomb rectangular torus ght(m, n), planar hexagonal grid phg(m, n), cylindrical hexagonal grid chg(m, n), and toroidal hexagonal grid thg(m, n)] in that they are types of honeycomb networks that can be used for the target set selection problem under strict majority thresholds.",honeycomb mesh,"honeycomb torus ht t, honeycomb rectangular torus hret(m, n), honeycomb rhombic torus hrot(m, n), generalized honeycomb rectangular torus ght(m, n), planar hexagonal grid phg(m, n), cylindrical hexagonal grid chg(m, n), and toroidal hexagonal grid thg(m, n)",no
1166,8812543.0,"in section 3 we determine the exact value of min-seed(g,  > ) for any honeycomb mesh g. in section 4, by computing the optimal target set for a generalized honeycomb rectangular torus, we determine the exact values of min-seed(g,  > ) when g is a honeycomb torus or a honeycomb rectangular torus or a honeycomb rhombic torus.",{'honeycomb mesh'},0.0,,,,,
1167,5679369.0,"the second such example is principal direction divisive partitioning (pddp), which is based on repeated divisions of instances according to the sign of their projection on the first principal component [14] . pddp outperforms the bisecting k-means algorithm in quality and stability [15] and will thus be used here as a benchmark for a state-of-the-art td algorithm.","{'principal direction divisive partitioning', 'pddp'}",1.0,based-on,principal direction divisive partitioning (pddp) is based on repeated divisions of instances according to the sign of their projection on the first principal component.,principal direction divisive partitioning,repeated divisions of instances according to the sign of their projection on the first principal component,no
1168,5679369.0,,,,compare,"pddp is an alternative to the bisecting k-means algorithm, that outperforms it in quality and stability and is thus used as a benchmark for a state-of-the-art td algorithm.",pddp,bisecting k-means algorithm,no
1169,51923422.0,"note that this step still has the low computation workload, since deep features are densely estimated. in addition, semantic content can be depicted more precisely with deep features [5, 7] which differs from the local feature content (relevent to the goal of our work).",{'deep feature'},0.0,,,,,
1170,51923422.0,[7] compute deep features from different fragments of images and aggregate them with the vlad descriptor [13] . netvlad [8] is a trainable generalization of vlad to recognize the geo-location of images.,"{'deep feature', 'vlad descriptor'}",1.0,is-a,vlad is a descriptor that aggregates deep features from different fragments of images.,vlad,descriptor,no
1171,51923422.0,,,,is-a,netvlad is a trainable generalization of vlad that recognizes the geo-location of images.,netvlad,trainable generalization of vlad,no
1172,48360932.0,"the processing and distribution of light fields is complicated by the recorded data quantities, limited bandwidths, lacking format standards, and the use of intermediate data such as depthmaps. the presentation of light fields is also affected by the bandwidth requirements and the variety of image rendering methods and devices.",{'light field'},0.0,,,,,
1173,48360932.0,"the required data can be recorded by plenoptic cameras [4] and multi-camera systems [5, 6] . plenoptic cameras produce a scene sampling that closely matches the four-dimensional parametrization of light field [3] .",{'plenoptic camera'},1.0,is-a,plenoptic cameras are cameras that produce a scene sampling that closely matches the four-dimensional parametrization of light field.,plenoptic camera,camera,no
1174,48360932.0,"plenoptic cameras produce a scene sampling that closely matches the four-dimensional parametrization of light field [3] . however, plenoptic cameras are seldom used in end-to-end systems, due to the spatial-angular resolution tradeoff and high data bandwidth [1] .","{'light field', 'plenoptic camera'}",1.0,is-a,"plenoptic cameras are cameras that produce a scene sampling that closely matches the four-dimensional parametrization of light field and are seldom used in end-to-end systems, due to the spatial-angular resolution tradeoff and high data bandwidth.",plenoptic camera,camera,no
1175,48360932.0,"however, plenoptic cameras are seldom used in end-to-end systems, due to the spatial-angular resolution tradeoff and high data bandwidth [1] . multi-camera systems avoid the bandwidth limits of plenoptic cameras, and therefore are used in end-to-end systems.",{'plenoptic camera'},0.0,,,,,
1176,202661161.0,"the classifiers and feature extractors are co-learned in an adversarial manner based on the prediction discrepancy on unlabeled data. meanwhile, a multinomial multi-domain adversarial discriminator is deployed to enhance the effective extraction of domain-invariant features, while separating them from the domain-specific features.",{'feature extractor'},0.0,,,,,
1177,2924377.0,bayes rule is also used to reformulate the translation probability of phrase pairs. experiment results showed that proposed system can improve translation quality by applying morphological analysis on myanmar language.,"{'phrase pair', 'translation probability'}",0.0,,,,,
1178,2924377.0,machine translation (mt) is the task of automatically translating a text from one natural language into another. there exist different approaches to address the problem of machine translation.,{'machine translation'},1.0,is-a,"machine translation (mt) is a task that automatically translates a text from one natural language into another, and there exist different approaches to address this problem.",machine translation,task,no
1179,2924377.0,there exist different approaches to address the problem of machine translation. this paper presents translation model of myanmar phrases for statistical myanmar to english machine translation system.,{'machine translation'},0.0,,,,,
1180,2924377.0,this paper presents translation model of myanmar phrases for statistical myanmar to english machine translation system. target and source language model based on n-gram (trigram) and translation model based on bayes' rule to reformulate translation probability p (f| e).,{'translation model'},0.0,,,,,
1181,2924377.0,"therefore, translation model used some rules for syntactic structure and morphological analysis of myanmar language to improve in translation direction and to reduce the number of unknown words in translation. the rest of this paper is organized as follows: in section 2, previous works in statistical machine translation is presented.",{'translation model'},0.0,,,,,
1182,2924377.0,"in this section, previous works in statistical machine translation on different languages are reviewed. various researchers have improved the quality of statistical machine translation system by using different methods on different language.",{'statistical machine translation'},0.0,,,,,
1183,2924377.0,"in 2002, och and ney first introduced the log-linear model into smt. in 2004 koehn suggested using features of lexical weighting.","{'och', 'ney'}",0.0,,,,,
1184,2924377.0,"in 2004 koehn suggested using features of lexical weighting. in this year, the famous phrase-based decoder, pharaoh, was released to be a free smt toolkit by philipp koehn and further updated to moses by koehn et al., 2007.",{'lexical weighting'},1.0,is-a,pharaoh is a phrase-based decoder that was released to be a free smt toolkit.,pharaoh,phrase-based decoder,no
1185,2924377.0,"in this year, the famous phrase-based decoder, pharaoh, was released to be a free smt toolkit by philipp koehn and further updated to moses by koehn et al., 2007. in 2003 koehn, och and marcu, used noisy channel based translation model and beam search decoder.",{'pharaoh'},1.0,is-a,pharaoh is a phrase-based decoder that was released to be a free smt toolkit.,pharaoh,phrase-based decoder,no
1186,199466287.0,"optimal transport (ot), a powerful distance for comparing probability distributions, has recently attracted great attention in machine learning area [rubner et al., 2000; pele and werman, 2009; ni et al., 2009; courty et al., 2017; arjovsky et al., 2017; wang et al., 2018; li et al., 2019] . in contrast to other popular distances of distributions, e.g., kl-divergence, (1) ot is more effective to describe the geometry of distributions by considering the spatial location of the distribution modes [villani, 2003] ; (2) it has also gained the superior performance in real applications, such as image retrieval [pele and werman, 2009 ], image segmentation [ni et al., 2009] and generative adversarial network [arjovsky et al., 2017] etc.",{'optimal transport'},1.0,is-a,optimal transport is a powerful distance for comparing probability distributions that has attracted great attention in machine learning.,optimal transport,a powerful distance for comparing probability distributions,no
1187,199466287.0,,,,compare,optimal transport is an alternative to other popular distances of distributions that is more effective to describe the geometry of distributions by considering the spatial location of the distribution modes.,optimal transport,other popular distances of distributions,no
1188,199466287.0,,,,used-for,optimal transport is used in generative adversarial networks.,optimal transport,generative adversarial network,yes
1189,207242665.0,"the depth of convolutional neural networks is a crucial ingredient for reduction in test errors on benchmarks like im-agenet and coco. however, training a neural network becomes difficult with increasing depth.","{'convolutional neural network', 'coco'}",0.0,,,,,
1190,207242665.0,"however, training a neural network becomes difficult with increasing depth. problems like vanishing gradient and diminishing feature reuse are quite trivial in very deep convolutional neural networks.",{'increase depth'},1.0,is-a,vanishing gradient is a problem that is quite trivial in very deep convolutional neural networks.,vanish gradient,problem,no
1191,207242665.0,,,,compare,vanishing gradient is like diminishing feature reuse in that they are problems that are quite trivial in very deep convolutional neural networks.,vanish gradient,diminishing feature reuse,no
1192,207242665.0,"in this paper, we propose to replace the combination of relu and batch normalization with exponential linear unit (elu) in residual networks. our experiments show that this not only speeds up the learning behavior in residual networks, but also improves the classification performance as the depth increases.","{'batch normalization', 'elu', 'residual network', 'relu', 'exponential linear unit'}",0.0,,,,,
1193,207242665.0,"convolutional neural networks (cnn), a type of dnn, have been a preferred model in many areas of computer vision [12, 14, 15, 16, 17] . cnns have demonstrated state-of-the-art results in computer vision problems like object recognition [1, 12, 15, 17] and detection [28, 29, 30] .","{'convolutional neural network', 'cnn'}",1.0,type-of,convolutional neural networks (cnn) are a type of dnn that have been a preferred model in many areas of computer vision and have demonstrated state-of-the-art results in computer vision problems like object recognition and detection.,convolutional neural network,dnn,no
1194,207242665.0,"while alexnet had 5 convolutional layers [10] , the vgg network and googlenet in 2014 had 19 and 22 layers respectively [15, 17] . these models pushed the state-of-the-art, but new problems were introduced with increasing depth.",{'googlenet'},0.0,,,,,
1195,207242665.0,"these models pushed the state-of-the-art, but new problems were introduced with increasing depth. problems like vanishing/exploding gradients [3] and diminishing feature reuse [7] affected the classification performance of these deeper models.",{'increase depth'},0.0,,,,,
1196,207242665.0,elus push the mean activations towards zero using negative values. this helps them curb the bias shift and speeds up the learning process.,{'elus'},0.0,,,,,
1197,207242665.0,this helps them curb the bias shift and speeds up the learning process. this allows elus to give a relatively better accuracy and learning speed than a combination of relu [8] and batch normalization [4] .,{'bias shift'},0.0,,,,,
1198,207242665.0,the accuracy is affected in such very deep models [1] due to diminishing feature reuse problem. highway neworks [7] and residual networks [1] are the latest methods to tackle this problem.,{'deep model'},1.0,is-a,residual networks are a method that are used to tackle the diminishing feature reuse problem,residual network,method,no
1199,207242665.0,,,,compare,residual networks are like highway networks in that they are methods that are used to tackle the diminishing feature reuse problem,residual network,highway network,no
1200,207242665.0,"highway neworks [7] and residual networks [1] are the latest methods to tackle this problem. these network architectures introduce skip connections, which allow flow of information to later layers, empowering deeper networks with better accuracy.",{'residual network'},1.0,compare,"residual networks are like highway neworks in that they are network architectures that introduce skip connections, which allow flow of information to later layers, empowering deeper networks with better accuracy.",residual network,highway network,no
1201,207242665.0,,,,is-a,"residual networks are network architectures that introduce skip connections, which allow flow of information to later layers, empowering deeper networks with better accuracy.",residual network,network architecture,no
1202,207242665.0,"in our paper, we propose to replace the relu and batch normalization combination with the exponential linear unit. the exponential linear units (elus) give a better classification performance compared to a combination of relu and batch normalization and also speed up learning in very deep networks.","{'exponential linear unit', 'relu'}",1.0,compare,"exponential linear units are an alternative to [relu, batch normalization] that give a better classification performance and also speed up learning in very deep networks.",exponential linear unit,"relu, batch normalization",yes
1203,207242665.0,batch normalization is a noteworthy recent contribution towards paring down the vanishing gradient problem [4] . batch normalization makes normalization a part of the model and achieves it for each mini-batch rather than normalized initialization and a lower learning rate.,{'batch normalization'},1.0,used-for,batch normalization is used for pairing down the vanishing gradient problem and it makes normalization a part of the model and achieves it for each mini-batch rather than normalized initialization and a lower learning rate.,batch normalization,pairing down the vanishing gradient problem and it makes normalization a part of the model and achieves it for each mini-batch rather than normalized initialization and a lower learning rate,no
1204,207242665.0,residual networks (resnets) [1] use identity transformation to utilize shortcut connections.,"{'resnet', 'residual network'}",0.0,,,,,
1205,207242665.0,"this increases the classification accuracy of deeper networks. the resnets gain more parameters with growing depth, and hence are able to give improved function approximation capabilities.",{'deep network'},0.0,,,,,
1206,207242665.0,"in residual networks, the gradients and features learned in earlier layers are passed back and forth between the layers via the identity transformations id(). exponential linear unit (elu)",{'residual network'},0.0,,,,,
1207,207242665.0,"if these units do not cancel each other, then the learning causes a bias shift for units in the next layer. therefore, elus decrease the bias shift as the mean activations are closer to zero.",{'bias shift'},0.0,,,,,
1208,207242665.0,"therefore, elus decrease the bias shift as the mean activations are closer to zero. less bias shift also speeds up learning by bringing standard gradient closer towards the unit natural gradient.",{'bias shift'},0.0,,,,,
1209,683784.0,"orthodisease (9) and phenomicdb (8, 26) are two other resources that allow researchers to look simultaneously at all available phenotypes for an orthologous gene group. the phenomicdb and orthodisease are useful resources integrating the phenotypes with the homologous genes from a variety of species.",{'phenomicdb'},1.0,compare,phenomicdb is like orthodisease in that they are two resources that allow researchers to look simultaneously at all available phenotypes for an orthologous gene group and are useful resources integrating the phenotypes with the homologous genes from a variety of species.,phenomicdb,orthodisease,no
1210,683784.0,,,,is-a,phenomicdb is a resource that allow researchers to look simultaneously at all available phenotypes for an orthologous gene group and it is a useful resource integrating the phenotypes with the homologous genes from a variety of species.,phenomicdb,resource,no
1211,683784.0,"the phenomicdb and orthodisease are useful resources integrating the phenotypes with the homologous genes from a variety of species. however, unlike our phenohm server, phenomicdb or orthodisease do not indicate the likelihood a phenotype is shared by the orthologous genes.",{'phenomicdb'},1.0,compare,"the phenomicdb is like orthodisease in that they are useful resources integrating the phenotypes with the homologous genes from a variety of species, and they do not indicate the likelihood a phenotype is shared by the orthologous genes.",phenomicdb,orthodisease,no
1212,683784.0,,,,compare,"the phenomicdb is an alternative to the phenohm server, in that it does not indicate the likelihood a phenotype is shared by the orthologous genes.",phenomicdb,phenohm server,no
0,57943122.0,the hybrid recommender systems combine the collaborative filtering and content-based filtering or some features of both filtering techniques. the combination of any other information such as user demographic or social information with the content or collaborative filtering is also utilized in the hybrid approach.,{'hybrid recommender system'},1.0,is-a,"hybrid recommender systems are an approach that combine collaborative filtering, content-based filtering, some features of both filtering technique, and the combination of any other information such as user demographic or social information with the content or collaborative filtering.",hybrid recommender system,approach,no
1,16084553.0,"a more elegant yet efficient approach is based on sequential suboptimal search methods [9, 10] ; the sequential forward floating selection (sffs) and sequential backward floating selection (sbfs) [10] are among the most popular methods.",{'sequential forward float selection'},1.0,type-of,sequential forward float selection is a type of sequential suboptimal search method.,sequential forward float selection,sequential suboptimal search method,no
2,10029628.0,"examples of real-world graph-structured data include the web graph, social, biological, telecommunication, utility, road and transportation networks, as well as relational data. the digital universe is producing an avalanche of these and many other occurrences of graph-structured data.",{'graph - structure datum'},0.0,,,,,
3,10290908.0,"this article reviews algorithms and methods for detecting and classifying action potentials, a problem commonly referred to as spike sorting. the article first discusses the challenges of measuring neural activity and the basic issues of signal detection and classification.",{'spike sorting'},1.0,is-a,spike sorting is a problem that detects and classifies action potentials and includes the challenges of measuring neural activity and the basic issues of signal detection and classification.,spike sorting,problem,no
4,10290908.0,it reviews and illustrates algorithms and techniques that have been applied to many of the problems in spike sorting and discusses the advantages and limitations of each and the applicability of these methods for different types of experimental demands. the article is written both for the physiologist wanting to use simple methods that will improve experimental yield and minimize the selection biases of traditional techniques and for those who want to apply or extend more sophisticated algorithms to meet new experimental challenges.,{'spike sorting'},0.0,,,,,
5,10290908.0,"one use of spike sorting is to aid the study of neural populations. in some cases, it is possible to measure population activity by using multiple electrodes that are spaced far enough apart so that each can function as a single independent electrode.",{'spike sorting'},1.0,used-for,"spike sorting is used to aid the study of neural populations and in some cases, it is possible to measure population activity by using multiple electrodes that are spaced far enough apart so that each can function as a single independent electrode.",spike sorting,aid the study of neural populations,no
6,1244007.0,"in engineering. today, many works have heen reported in the cooperative control of telerobot over the internet.",{'cooperative control'},0.0,,,,,
7,859921.0,"many automatic systems were built to address this challenge including generating aspect-based sentiment summarization of reviews [1, 8, 19] and comparing and ranking products with regard to their aspects [13] . in this study we focus on the problem of review summarization, which takes as input a set of user reviews for a specific product or service entity and produces a set of representative text excerpts from the reviews.",{'aspect - base sentiment summarization'},1.0,is-a,aspect-based sentiment summarization is an automatic system that summarizes reviews by taking as input a set of user reviews for a specific product or service entity and producing a set of representative text excerpts from the reviews.,aspect - base sentiment summarization,automatic system,no
8,859921.0,"[17] , which generates a word either from a topic or one of the two additional subtopics -sentiments, but it fails to account for the intimate interplay between a topic/aspect and a sentiment. tsm is based on plsi whereas more recent work ( [9, 11, 20] ) uses or extends latent dirichlet allocation (lda)","{'latent dirichlet allocation', 'plsi'}",0.0,,,,,
9,9798825.0,"lopez et al. discussed the relationship of program transformation with respect to aspectj [12] . in a different context [7] , we applied program transformation technology to construct an aspect weaver for object pascal.",{'aspectj'},0.0,,,,,
10,9798825.0,this paper extends that work to c\+\+ templates in order to address the challenges of transforming complex template code. aspectj provides support for generics and parameterized types in pointcuts and intertype declarations.,"{'pointcut', 'aspectj'}",1.0,is-a,aspectj is a c\+\+ template that provides support for generics and parameterized types in pointcuts and intertype declarations.,aspectj,c\+\+ template,no
11,195799050.0,"using the encoder-decoder structure, crack characteristics with multiple contexts are automatically learned, and end-to-end crack detection is achieved. specifically, we first propose the multi-dilation (md) module, which can synthesize the crack features of multiple context sizes via dilated convolution with multiple rates.",{'dilated convolution'},0.0,,,,,
12,195799050.0,"with the rapid advancement in sensors and information technology (it), millions of road images have been collected by many transportation agencies for crack detection. various manually designed features, such as grayscale [1] - [4] , edge [5] - [7] , gabor filters [8] , [9] , wavelet [10] , [11] , and histogram of oriented gradients (hog)","{'hog', 'orient gradient'}",1.0,is-a,hog is a manually designed feature for crack detection that stands for the histogram of oriented gradients.,hog,manually designed feature for crack detection,no
13,195799050.0,"pixel-level prediction is achieved in these methods, but these methods are time consuming and do not involve end-to-end aspects. some studies [19] , [20] applied a fully convolutional network (fcn) [21] to crack detection to solve the above problems with high precision and speed.",{'fully convolutional network'},1.0,is-a,fully convolutional networks are methods that have been applied to crack detection.,fully convolutional network,method,no
14,59929451.0,"in this paper, a mutual-backup architecture of sip-servers is proposed for wireless backbone based networks. a message format for synchronization and information exchange between sip servers is also proposed in the paper.",{'sip server'},1.0,part-of,sip-servers are a part of a mutual-backup architecture for wireless backbone based networks.,sip server,mutual-backup architecture for wireless backbone based networks,no
15,9200896.0,"this is achieved in the h.264/avc (advanced video coding) codec [5] by setting the quantization parameter (qp) in such a way that lower-priority texture data that can be replaced more easily at the decoder through error concealment occupies a larger part of a frame's data. consequently, when packetized in a wimax mac service data unit (msdu) within a mac protocol data unit (mpdu)",{'quantization parameter'},0.0,,,,,
16,7976495.0,"their model describes institutions as being composed of a set of registration rules which deal with the entry and exit of agents from institutions, a set of interaction rules which govern how commitments are created and dispensed between agents, a set of authorisations which describe agents innate abilities to perform certain actions and an internal ontology which describes a model for the interpretation of terms relevant to the institution. a number of aspects of this approach correspond with our model for describing institutions as outlined in section 4, in particular interaction rules correspond to our social rules, authorisations with our treatment of institutionalised power and the internal ontology with our domain specific rules.",{'institutionalised power'},0.0,,,,,
17,7976495.0,in their work specifications of social systems are formalised in both the event calculus [22] and using a subset of the action language c+ [12] .,{'event calculus'},0.0,,,,,
18,18602084.0,it puts a multifaceted agent used in analysis 'into the shoes' of the user and turns the design and implementation into one we call people-oriented programming (pop). pop calls on users to gather ethnographic data about themselves using cultural probes and on end-user innovation via software toolkits.,{'cultural probe'},0.0,,,,,
19,18602084.0,"pop calls upon the user in three capacities: as the focus of customised software, which von hippel and katz describe as 'markets of one' [24] ; as a self-ethnographer using cultural probes [7] to gather data; and as an end-user developer via software toolkits [24] designed to make the user central to innovation in new product development, the way that end-users are doing in the games genre [18] and in mashups of internet services [2] . the technology used here to pursue people oriented programming is the digitalfriend, v1 of which instantiates the shadowboard agent architecture [9] .",{'cultural probe'},1.0,used-for,cultural probes are used to gather data by self-ethnographers.,cultural probe,gather data by self-ethnographers,no
20,5736403.0,"in [6] , a self-organizing traffic light uses a threshold to control a time-based integration of the count of arriving vehicles within a given horizon during the red light, so that large enough ""platoons"" can move without unnecessary stopping. more recently, a self-control method was proposed based on the notion of an ""anticipated queue"", which contains not only those vehicles already queued at the intersection, but also those predicted to reach the intersection before the last queued vehicle is cleared [8] .",{'self - organize traffic light'},1.0,is-a,"a self-organizing traffic light is a self-control method that uses a threshold to control a time-based integration of the count of arriving vehicles within a given horizon during the red light, so that large enough ""platoons"" can move without unnecessary stopping. ",self - organize traffic light,self-control method,no
21,5987723.0,"the early models were criticized for the limited correspondence to the real structure of the brain. to respond to this critique, computational neuroscience tried to avoid mathematical modeling that had no empirical correspondence (dayan and williams, 2006) .",{'dayan'},0.0,,,,,
22,19361520.0,"at a high level, we can also adopt the offloading approach. however, instead of offloading computation to the remote cloud, we instantiate the edge computing concept [39] by offloading dl tasks to a nearby mobile device (e.g., a smartphone or a tablet) that has local connectivity with the wearable.",{'nearby mobile device'},0.0,,,,,
23,19361520.0,a challenge here is that enumerating all split-point candidates (for partial offloading) on a general graph takes exponential execution time w.r.t. the graph size.,{'partial offloading'},0.0,,,,,
24,19361520.0,"for example, google combines the deep neural networks and graph-based machine learning to build an entirely ""on-device"" ml technology for powering smart messaging on android wear 2.0, enabling technologies like smart reply to be used for any application [6] . in academia, there are several directions to scale down the deep-learning workloads for wearables and mobile devices.",{'smart reply'},1.0,type-of,"smart reply is a type of technology that is enabled by ""on-device"" ml technology that powers smart messaging on android 2.0, built by google combining the deep neural networks and graph-based machine learning, and can be used for any application.",smart reply,technology,no
25,19361520.0,"some efforts [53] [26] [68] [42] have proposed deep models that are much smaller than normal without sacrificing too much accuracy, so they can run directly on mobile cpu or even dsp. some other efforts such as [27] [41] is another popular approach of accelerating deep learning and reducing the energy consumption.",{'deep model'},0.0,,,,,
26,40221698.0,"this additional information may come, for instance, in the form of a small portion of revealed community memberships, or in the form of node features, or both. in this paper, we aim to address the above concerns by answering the following questions:",{'node feature'},0.0,,,,,
27,26701595.0,"the approach can also be engineered to produce computable programs from conceptual and abstract algorithms as an inverse function. in this paper, we introduce the core idea behind the mindreader online assessment system that is able to understand a wide variety of elementary algorithms students learn in their entry level programming classes such as java, c++ and python.",{'mindreader'},1.0,is-a,"mindreader is an online assessment system that is able to understand a wide variety of elementary algorithms students learn in their entry level programming classes such as java, c++ and python.",mindreader,online assessment system,no
28,10471853.0,"moving shadow detection is critical for accurate object detection in video streams since shadow points are often misclassified as object points, causing errors in segmentation and tracking. many algorithms have been proposed in the literature that deal with shadows.",{'accurate object detection'},0.0,,,,,
29,39588889.0,"the workload analyzer monitors and classifies the consumption of data, both at the infrastructure and platform layers. it combines all the data from different nodes of the cloud-tm platform, then filters and correlates them.",{'cloud - tm platform'},0.0,,,,,
30,53256742.0,"deep learning approaches have intensively been used in different studies to produce an effective smartphone-based har. however, there are several deep learning models available in the literature, including convolutional neural networks (cnns)",{'convolutional neural network'},1.0,type-of,convolutional neural networks are a type of deep learning model.,convolutional neural network,deep learning model,no
31,5319354.0,"it demonstrated the computational feasibility of symbolic timing simulation on a number of reasonable-sized benchmarks. however, sirsim suffers from a major bottleneck which we term the event multiplication problem.",{'symbolic timing simulation'},0.0,,,,,
32,59553801.0,"[16] , using the icub humanoid robot [17] , developed a model capable of number comparison and parity judgement that took into account the snarc (spatial-numerical association of response codes) effect. in another work [18] they constructed a recurrent neural network that is first taught to recite the numbers in the counting order and then to count the presented objects with or without proprioceptive gesture input from icub robot.",{'icub humanoid robot'},0.0,,,,,
33,1318906.0,crosscutting concerns are encapsulated in specific entities called aspects where are typical elements described in aop like pointcuts and advice. aodm involve both static and dynamic views (class diagrams and collaboration diagrams).,{'pointcut'},0.0,,,,,
34,1318906.0,in this sense the ejbs deployment descriptor is extended to define aspects and pointcuts. the aspects are implemented like templates (called parametrized aspects) which can be instantiated by specific components (bean components).,{'pointcut'},0.0,,,,,
35,17660790.0,topic models have emerged as fundamental tools in unsupervised machine learning. most modern topic modeling algorithms take a probabilistic view and derive inference algorithms based on latent dirichlet allocation (lda) or its variants.,{'latent dirichlet allocation'},0.0,,,,,
36,17660790.0,"topic modeling has long been fundamental to unsupervised learning on large document collections. though the roots of topic modeling date back to latent semantic indexing [12] and probabilistic latent semantic indexing [16] , the arrival of latent dirichlet allocation (lda)","{'latent dirichlet allocation', 'probabilistic latent semantic indexing'}",0.0,,,,,
37,17660790.0,"we answer this question in the affirmative. in particular, we propose a combinatorial optimization formulation for topic modeling, derived using small-variance asymptotics (sva) on the lda model.","{'lda model', 'small - variance asymptotic'}",1.0,part-of,small-variance asymptotics are a part of the lda model that are used to derive a combinatorial optimization formulation for topic modeling.,small - variance asymptotic,lda model,yes
38,17660790.0,"applications include clustering [21] , feature learning [10] , evolutionary clustering [11] , infinite hidden markov models [26] , markov jump processes [17] , infinite svms [32] , and hierarchical clustering methods [22] . a related thread of research considers how to apply sva methods when the data likelihood is not gaussian, which is precisely the scenario under which lda falls.","{'evolutionary clustering', 'infinite hidden markov model'}",0.0,,,,,
39,51864369.0,"this threat intelligence based taxonomy providing a stage-by-stage operational understanding of a cyber-attack, can be highly beneficial to security practitioners and the design of evolutionary computational intelligence on trojans detection and mitigation strategy. the proposed taxonomy is validated by using a real-world dataset of 127 banking trojans",{'trojan detection'},0.0,,,,,
40,51864369.0,"using threat model like ckc and aligning patterns of threat attacks to it, will allow researchers and security experts to speak in one language i.e. ckc. and in this language, we will be highlighting what to look for at each stage of the kill chain to support an intelligent-derived defensive and investigative tactics for analysts and experts in organisations to perform their day-to-day tasks against apt.",{'kill chain'},0.0,,,,,
41,51864369.0,"karim et al., proposed a taxonomy for mobile botnets [41] . with emergence of mobile malwares, a taxonomy for mobile malware behavioural detection was proposed [42] followed by an android malware attack vectors taxonomy based on attackers modus-operandi [43] .",{'mobile malware'},0.0,,,,,
42,1338543.0,"boyd et al. (2001) have used simulation to demonstrate this spiral-down effect, which is known to some practitioners.",{'spiral - effect'},0.0,,,,,
43,408998.0,"in this paper we present a generalization of probabilistic matrix factorization that replaces scalar latent features with functions whose inputs are the side information. by placing gaussian process priors on these latent functions, we achieve a flexible nonparametric bayesian model that incorporates side information by introducing dependencies between pmf problems.",{'probabilistic matrix factorization'},0.0,,,,,
44,62191625.0,this paper evaluates the performance of the array processing and compares it to the large bandwidth technique in terms of snr and resolution of ncf. it is shown that the large bandwidth technique gives better snr and resolution compared to the array processing technique under certain conditions.,{'ncf'},0.0,,,,,
45,62191625.0,"delay and sum (ds) beam-forming technique described in [1] is applied in the array processing of this paper, which leads to the derivation of the snr and resolution of the ncf in array processing. a relationship between the two techniques is shown in this paper in which the resources required to achieve a desired snr and resolution are defined.",{'ncf'},0.0,,,,,
46,10051669.0,"both symbol recognition and structural analysis have been extensively studied for decades. mathematical expression recognition, which features both of them as the two major stages of the process, is a good subject for studying the integration of the two areas.",{'mathematical expression recognition'},1.0,is-a,mathematical expression recognition is a subject that studies the integration of symbol recognition and structural analysis.,mathematical expression recognition,subject,no
47,10051669.0,"afterwards, we will discuss some existing schemes and propose some new schemes for evaluating the performance of mathematical expression recognition systems. finally, we will provide and discuss some experimental results which will then be followed by some concluding remarks.",{'mathematical expression recognition system'},0.0,,,,,
48,59567054.0,"after the experiment, the collected data are analyzed with three types of analyses: generalized linear model (glm), dd scores, and random forests. through the analysis, the followings are observed: (i) korean also has island phenomena, (ii) scrambling increases the dd scores in all of four types of island constraints, and (iii) the increases of the dd scores are not due to the violation of island constraints but can be explained by a processing-based account.",{'random forest'},0.0,,,,,
49,59567054.0,"after the experiment, all of the data for 100 participants are extracted and they are statistically analyzed with r. for these data, three types of analysis methods are adopted: glm, dd scores, and random forests. this paper is organized as follows.",{'random forest'},0.0,,,,,
50,2715947.0,"our previous work proposed a social recommender system used two social media knowledge sources: online product reviews and purchase preferences. as a result, recommendation was improved by the combination of aspect based sentiment analysis with preference knowledge [2] .",{'aspect base sentiment analysis'},0.0,,,,,
51,865945.0,"abstract-in multiple input multiple output (mimo) systems, multiuser enhancement is in the implementation phase. block diagonalization (bd) is known as the safest technique for the multiuser mimo downlink since it suppresses the inter-user interference (lui) perfectly.",{'block diagonalization'},1.0,is-a,block diagonalization is a technique that is known as the safest for the multiuser mimo downlink since it suppresses the inter-user interference (lui) perfectly.,block diagonalization,technique,no
52,865945.0,"the partial nulling has been previously proposed by the authors to exploit the receiver's capability of spatial filtering for lui cancellation and thus to enable the increase in degrees of freedom at the trans mitter [9] . the idea minimizing signal-to-ieakage-plus-noise ratio (slnr) also eases the perfect nulling condition [10] , [11] .",{'slnr'},0.0,,,,,
53,10705817.0,"it is based on the study of structural matrices. properties of structural matrices regarding detectability, discriminability and diagnosability are established in order to be used by sensor placement methods.",{'diagnosability'},0.0,,,,,
54,10705817.0,"recently, a bridge approach between fdi and dx was proposed (cordier, dague, lvy, dumas, montmain, staroswiecki and trav-massuys, 2000; nyberg and krysander, 2003; ploix, touaf and flaus, 2003) .",{'dague'},0.0,,,,,
55,10705817.0,the sensor placement algorithm should compute solutions that satisfy detectability and diagnosability properties where detectability is the possibility of detecting a fault on a component and diagnosability is the possibility of isolating a fault on a component without ambiguities with any other faulty components. few methods have focused on this problem.,{'diagnosability'},1.0,is-a,diagnosability is a property that computes the possibility of isolating a fault on a component without ambiguities with any other faulty components and that should be satisfied by the sensor placement algorithm.,diagnosability,property,no
56,10705817.0,,,,compare,diagnosability is like detectability in that the sensor placement algorithm should compute solutions that satisfy them both.,diagnosability,detectability,no
57,1243904.0,"it gives a measurable benefit at a low cost (each result could simply be stored as a complete html page in a few kb), though the benefit is limited by the degree of repetition in the input stream. at a lower level, list caching is used to keep inverted lists corresponding to frequently used search terms in main memory, resulting in additional benefits for engines with disk-based index structures.",{'list caching'},1.0,used-for,list caching is used for engines with disk-based index structures to keep inverted lists corresponding to frequently used search terms in main memory.,list caching,engines with disk-based index structures,no
58,9579373.0,"in [15] , a gpu extension of the nonlocal means algorithm is proposed to denoise ultrasound images. in this approach, the maximum patch size is limited by the amount of shared memory of the gpu.",{'nonlocal mean'},0.0,,,,,
59,4532262.0,"given this hypothesis, it makes sense to concentrate the effort on young objects which are most likely to be unreachable. generational collectors segregate objects according to their age into two or more groups called generations, and run frequent collections of the young generation.",{'young object'},0.0,,,,,
60,4532262.0,"these are pointers that point from the old generation to the young generation. if the young generation is collected while the old generation is not, these pointers must be accounted for: they may be the only evidence that a young object is reachable.",{'young object'},0.0,,,,,
61,18126954.0,"in this paper, we use a new method to decrease the parameterized complexity bound for finding the minimum vertex cover of connected max-degree-3 undirected graphs. the key operation of this method is reduction of the size of a particular subset of edges which we introduce in this paper and is called as ""real-cycle"" subset.",{'parameterized complexity'},0.0,,,,,
62,54628704.0,"both tao and hossam assume that the deadline of every flow is fixed at 250 ms. compared with their model, our method, which randomly generates deadlines based on utilization, can be adapted to the system, whose flow deadlines change dynamically.",{'flow deadline'},0.0,,,,,
63,852996.0,this command language corresponds directly to concurrent kleene algebra (cka) [14] .,{'concurrent kleene algebra'},0.0,,,,,
64,852996.0,"the command language in this paper is based on that introduced in the ""views"" paper [10] , which describes how a range of approaches to reasoning about shared-variable concurrency can be mapped down onto cka, and the command language. approaches covered in [10] include various separation logics [8] , type-theories, owicki-gries [20] , and rely-guarantee [17] , among others.",{'separation logic'},0.0,,,,,
65,213274317.0,"it is however known that rf-wpt also introduces interference to wireless communications, leading to poor data throughput. the joint routing and charging remains a challenging job in rf energy harvesting networks.",{'rf energy harvesting network'},0.0,,,,,
66,213274317.0,"this feature gives rf chargers better mobility yet also introduces higher degree of interferences to wireless communications. in particular, the study from showed that rf energy transfer would cause data loss and largely reduce wireless throughput.",{'rf energy transfer'},1.0,type-of,rf energy transfer is a type of rf charger that has been shown to cause data loss and largely reduce wireless throughput.,rf energy transfer,rf charger,no
67,213274317.0,"without special treatments, data transmissions will be heavily interfered after an rf-wpt charger is introduced in wsns. for example, through experimental studies, showed that the rf energy transfer would cause data loss and largely reduce the wireless throughput.",{'rf energy transfer'},1.0,type-of,rf energy transfer is a type of rf-wpt charger that has been shown to cause data loss and largely reduce the wireless throughput in wsns.,rf energy transfer,rf-wpt charger,no
68,17654474.0,"however, the above techniques have a couple of limitations: firstly, tarantula and cbi do not distinguish the number of times that a particular program element (statement or predicate) has been executed in a run. liu et al.",{'tarantula'},1.0,is-a,tarantula is a technique that does not distinguish the number of times that a particular program element (statement or predicate) has been executed in a run.,tarantula,technique,no
69,17654474.0,,,,compare,tarantula is like cbi in that they are techniques that do not distinguish the number of times that a particular program element (statement or predicate) has been executed in a run.,tarantula,cbi,no
70,17654474.0,"in the implementation provided in the authors' website, it implicitly assumes that (p) is normally distributed. our empirical study on the siemens suite [5] shows that most predicates are far from having any known distribution.",{'siemens suite'},0.0,,,,,
71,17654474.0,the main contributions of the paper are two-fold: (i) it gives the first case study on the statistical nature of the execution spectra over the siemens suite.,{'siemens suite'},0.0,,,,,
72,17654474.0,"harrold et al. [7] list nine classes of program spectra, such as path count, data-dependency count, and execution trace.",{'program spectra'},0.0,,,,,
73,17654474.0,"[8, 10] , in their work tarantula, rank each statement according to suspiciousness, which is a function of the percentages of failed and successful test cases that execute the statement. renieres and reiss [17] , in their work nearestneighbor, find that the execution trace difference between a failed run and its nearest successful neighbor run is more effective for debugging.",{'suspiciousness'},1.0,is-a,suspiciousness is a function that ranks statements in tarantula by the percentages of failed and successful test cases that execute the statement. ,suspiciousness,function,no
74,11109631.0,"link breaks could occur from varying channel conditions or nodes travelling away from each other until they are out-of-range. mwsns also suffer from the same problems as static wsns, such as energy constraints, cost, bandwidth limitations and required self-configuration.",{'link break'},0.0,,,,,
75,16101355.0,"we explore whether the global landscape structure of the number partitioning problem changes with the phase transition. using the local optima network model, we analyse a number of instances before, during, and after the phase transition.",{'local optima network model'},0.0,,,,,
76,16101355.0,"in particular, the local optima network (lon) model [9, 10] . local optima networks compress the whole search space into a graph, where nodes are local optima and edges are transitions among them with a given search operator.",{'local optima network'},1.0,is-a,"local optima network is a model that compresses the whole search space into a graph, where nodes are local optima and edges are transitions among them with a given search operator.",local optima network,model,no
77,16101355.0,"local optima are key features of fitness landscapes as they can be seen as obstacles for reaching high quality solutions. the local optima networks model emphasises the number, distribution and most importantly, the connectivity pattern of local optima in the underlying search space.",{'local optima network model'},1.0,is-a,"the local optima networks model is a model that emphasises the number, distribution and most importantly, the connectivity pattern of local optima in the underlying search space, which are key features of fitness landscapes as they can be seen as obstacles for reaching high quality solutions.",local optima network model,model,no
78,16101355.0,section 3 presents relevant definitions and algorithms related to local optima networks. section 4 presents our fitness landscape analysis and visualisation.,{'local optima network'},0.0,,,,,
79,9763456.0,"melacci et al. [melacci and belkin, 2011] propose a method they call lapsvm, which builds an svm classifier using the graphical structure of the data.",{'lapsvm'},1.0,is-a,lapsvm is a method that builds an svm classifier using the graphical structure of the data.,lapsvm,method,no
80,9763456.0,"zhang et al. [zhang et al., 2009] describe the prototype vector machine which solves a similar objective as above, by approximating it using ""prototype"" vectors which are representative points in the data.",{'prototype vector machine'},0.0,,,,,
81,9763456.0,"[ma et al., 2015] describe new algorithms which are related to the multi-armed bandit problem to perform active search on graphs. their algorithms are based on the -optimality selection criterion, which queries the point that minimizes the sum of the elements in the predictive covariance as described in [ma et al., 2013] .",{'multi - armed bandit problem'},0.0,,,,,
82,15904751.0,"in this paper, a simple and efficient method based on random forests is proposed for human action recognition. first, we extract the 3d skeletal joint locations from depth images.",{'random forest'},0.0,,,,,
83,15904751.0,"by employing the improved fourier temporal pyramid, we recognize actions using random forests. the proposed method is evaluated by using a public video dataset, namely utkinect-action dataset.",{'random forest'},0.0,,,,,
84,15904751.0,"inspired by natural language processing and information retrieval, bag-of-words approaches are also applied to recognize actions as a form of descriptive action unites. in these approaches, actions are represented as a collection of visual words, which is the codebook of spatio-temporal features.",{'visual word'},1.0,part-of,visual words are a part of the codebook of spatio-temporal features in bag-of-words approaches.,visual word,the codebook of spatio-temporal features in bag-of-words approaches,no
85,15904751.0,"the collection of apj3d vectors from training sequences are first extracted using the joint position estimation and then clustered into k-means [11] algorithm. by employing the improved fourier temporal pyramid, we recognize actions using random forests.",{'random forest'},0.0,,,,,
86,15904751.0,section 3 describes our apj3d as human posture representation. section 4 addresses action recognition technique using random forests.,{'random forest'},0.0,,,,,
87,6271257.0,we adapt existing image features (such as shape contexts or sift) to sbir and also introduce new local shape features. these features are used in a bag-of-features approach for sbir.,{'shape context'},1.0,is-a,shape context is an image feature that can be adapted to a bag-of-features approach for sbir.,shape context,image feature,no
88,6271257.0,,,,compare,shape context is like sift in that they are image features that can be adapted to a bag-of-features approach for sbir.,shape context,sift,no
89,53581874.0,"we establish asymptotic optimality of sequential tests generalising the track-and-stop method to problems beyond best arm identification. we further derive sharper stopping thresholds, where the number of arms is replaced by the newly introduced pure exploration problem rank.",{'good arm identification'},0.0,,,,,
90,53581874.0,"in the fixed-confidence setting, the minimal number of samples needed to identify the best arm with accuracy larger than 1   when arms belong to a one-dimensional family has been identified by , in a regime of small values of . their track-and-stop algorithm is shown to asymptotically attain this optimal sample complexity.",{'good arm'},0.0,,,,,
91,18972100.0,"the sentiwordnet resource (esuli and sebastiani, 2006) derived from wordnet which has been used in various opinion mining works (devitt and ahmad, 2007) ; other lines of research include the derivation of word-lists (semi) automatically for opinion classification (turney, 2002) . to the best of our knowledge, little research has been carried out on natural language processing for discourse interpretation in psychology.",{'turney'},0.0,,,,,
92,146009276.0,"this paper presents the archimob corpus, a freely available general-purpose corpus of spoken swiss german based on oral history interviews. the corpus is a result of a long design process, intensive manual work and specially adapted computational processing.",{'archimob corpus'},1.0,is-a,"the archimob corpus is a freely available general-purpose corpus of spoken swiss german that is based on oral history interviews and is a result of a long design process, intensive manual work and specially adapted computational processing.",archimob corpus,freely available general-purpose corpus of spoken swiss german,no
93,146009276.0,"samardi et al. 2015) have shown that even a small amount of data in swiss varieties is more useful for training language processing tools than much larger data sets in standard german. this paper presents an annotated corpus of spoken swiss german, the archimob corpus.",{'archimob corpus'},1.0,is-a,the archimob corpus is an annotated corpus of spoken swiss german.,archimob corpus,annotated corpus of spoken swiss german,no
94,208100060.0,the performance showed for the system in all the sub-collections of the bioscope corpus is high. the authors (2009b) extended their research to include speculation detection showing that the same scope finding approach can be applied to both negation and speculation.,{'bioscope corpus'},0.0,,,,,
95,17942996.0,"in [1] the authors proposed a study concerning the design of explicit state observer for a class of nonlinear descriptor systems described by takagi-sugeno (t-s) model with measurable premise variables. in this paper, the aim is to extend this result to a class of t-s descriptor systems when the premise variables are not measurables.",{'premise variable'},0.0,,,,,
96,1292253.0,"we also investigate algorithms for non-projective parsing that account for nonlocal information, and present several hardness results. this suggests that it is unlikely that exact non-projective dependency parsing is tractable for any model richer than the edge-factored model.",{'non - projective parsing'},0.0,,,,,
97,1292253.0,"figure 1 gives an example dependency graph for the sentence mr. tomash will remain as a director emeritus, which has been extracted from the penn treebank (marcus et al., 1993) . each edge in this graph represents a single syntactic dependency directed from a word to its modifier.",{'penn treebank'},0.0,,,,,
98,1292253.0,"in this representation all edges are labeled with the specific syntactic function of the dependency, e.g., sbj for subject and nmod for modifier of a noun. to simplify computation and some important definitions, an artificial token is inserted into the sentence as the left most word and will always represent the root of the dependency graph.",{'artificial token'},1.0,used-for,an artificial token can be used to represent the root of the dependency graph when inserted into the sentence as the left most word.,artificial token,represent the root of the dependency graph,no
99,1292253.0,figure 2 gives an example of a nonprojective graph for a sentence that has also been extracted from the penn treebank. non-projectivity arises due to long distance dependencies or in languages with flexible word order.,{'penn treebank'},0.0,,,,,
100,201810241.0,ahandani and alavi-rad [9] proposed a sfla based on the opposition-based learning (obl) and obl was used to initialize the population to improve the quality of the candidate solutions and the obl strategy was also used to diversify search moves of sfla and accelerated sfla without premature convergence in the search process. liu et al.,{'opposition - base learning'},0.0,,,,,
101,201810241.0,"[19] proposed an improved sfla for solving the local backlight dimming problem and preserving the image quality perception with a certain low backlight power consumption. through unremitting efforts made by a lot of experts and scholars in the past years, the optimization performance of sfla has been improved largely.",{'local backlight'},0.0,,,,,
102,9506814.0,"many multi-view performance capture methods [22] deform a static full-body shape template obtained with a full-body scanner [4, 5, 23, 24] , or through fitting against the visual hull [25] [26] [27] [28] to match scene motion.",{'visual hull'},0.0,,,,,
103,9506814.0,"this approach forms piecewise-smooth and differentiable model contours which are optimized to maximize overlap with image gradients. the work of sminchisescu and triggs [59] is closely related, an actor model consisting of superquadric ellipsoids is used for monocular 3d pose tracking and is initialized by optimizing bone-length and ellipsoid deformation parameters with respect to image edge cues.",{'actor model'},1.0,used-for,"an actor model is used for monocular 3d pose tracking and consists of superquadric ellipsoids, initialized by optimizing bone-length and ellipsoid deformation parameters with respect to image edge cues.",actor model,monocular 3d pose tracking,no
104,6567832.0,"[kur94] ), in particular when studying language inclusion problems of -regular languages. in addition to this, complementation is useful to check the correctness of other translation techniques [var07, tct + 08].",{'language inclusion problem'},0.0,,,,,
105,20727977.0,"this paper utilizes click data, which can be collected in abundance, to address the cold-start problem. we propose a probabilistic item embedding model that learns item representations from click data, and a model named emb-mf, that connects it with a probabilistic matrix factorization for rating prediction.","{'rating prediction', 'probabilistic matrix factorization'}",1.0,used-for,probabilistic matrix factorization is used for rating prediction.,probabilistic matrix factorization,rating prediction,yes
106,20727977.0,"an mf-based algorithm finds the vector representations (latent feature vectors) of users and items, and uses these vectors to predict the unseen ratings. however, an mf-based algorithm suffers from the cold-start problem: it cannot find the latent feature vectors for items that do not have any prior ratings; thus cannot recommend them.",{'vector representation'},1.0,is-a,vector representations are latent feature vectors that are found by an mf-based algorithm and used to predict the unseen ratings when they have prior ratings.,vector representation,latent feature vector,no
107,20727977.0,"-the proposed model (emb-mf) can automatically control the contributions of prior ratings and clicks in rating predictions. for items that have few or no prior ratings, the predictions mainly rely on click data.",{'rating prediction'},0.0,,,,,
108,20727977.0,"however, using these vectors directly for rating prediction is not appropriate because click data does not exactly reflect preferences of users. instead, we combine item embedding with mf in a way that allows rating data to contribute to item representations.",{'rating prediction'},0.0,,,,,
109,5945410.0,this work presents a new approach to automatic facial ageing which involves the development of a person specific facial ageing system. a color based active appearance model (aam) is used to extract facial features.,{'active appearance model'},1.0,used-for,an active appearance model is used to extract facial features for an approach to automatic facial ageing.,active appearance model,extract facial features for an approach to automatic facial ageing,no
110,5945410.0,"then, regression is used to model an age estimator. age synthesis is achieved by computing a solution that minimises the distance from the original face with the use of constrained regression.",{'age synthesis'},1.0,is-a,age synthesis is a model that is achieved by computing a solution that minimises the distance from the original face with the use of constrained regression.,age synthesis,model,no
111,5945410.0,"by carefully choosing a regression function, the ages were estimated, additionally age synthesis was realised by computing a new set of c values. a number of aam vectors were generated for each age in the training data and stored in a lookup table.",{'age synthesis'},0.0,,,,,
112,16491025.0,"they can talk, chat, build and design objects, program and compile their own developed programs, or move (flying, teleporting, walking or running) to different parts of the world. although these environments provide an interesting working place for students and educators, vw platforms (such as opencobalt or opensim amongst others) rarely provide mechanisms to facilitate the automatic (or semi-automatic) behaviour analysis of users interactions.",{'opensim'},1.0,is-a,opensim is a vw platform that provides an interesting working place for students and educators but rarely provides mechanisms to facilitate the automatic (or semi-automatic) behaviour analysis of users interactions.,opensim,vw platform,no
113,16491025.0,,,,compare,opensim is like opencobalt in that they are vw platforms that provide an interesting working place for students and educators but rarely provide mechanisms to facilitate the automatic (or semi-automatic) behaviour analysis of users interactions.,opensim,opencobalt,no
114,9578519.0,"although feature-based methods for 3d model retrieval usually are efficient, robust, and easy to implement (see for example, bustos et al. [10] ), these descriptors typically only capture an approximation of the original 3d models.",{'3d model retrieval'},0.0,,,,,
115,9578519.0,"unfortunately, none of these approaches is directly applicable to 3d model retrieval, because the computation of 3d salient points is still an open problem [3] . this paper proposes a generic scheme to optimize the retrieval effectiveness of given global 3d object descriptors, by combining them with descriptors of the same descriptor type obtained for a simple partitioning of the objects.",{'3d model retrieval'},0.0,,,,,
116,9578519.0,our approach to use local descriptors is a heuristic. the method in nature is similar to the histogram of oriented gradients (hog) approach for 2d image analysis described in dalal and triggs [14] .,"{'hog', 'orient gradient'}",1.0,is-a,hog is a histogram of oriented gradients that is used for 2d image analysis.,hog,histogram of oriented gradients,no
117,8412888.0,"for time-bounded reachability objectives, e.g., timed schedulers are optimal [3] . for simpler criteria such as unbounded reachability or average reward, time-abstract (ta) schedulers will do.",{'average reward'},0.0,,,,,
118,281928.0,the smv model has been extended to a finite set of jointly sparse vectors having their nonzeros occurring in a common location set. the sensing vectors are applied to each of the sparse vectors resulting in multiple measurement vectors (mmv).,"{'multiple measurement vector', 'mmv'}",0.0,,,,,
119,281928.0,"the imv model is broader than mmv and naturally arises in recovery problems involving analog signals, such as our earlier work on multiband signals [15] . other potential applications involving analog signals are: i) compressed sensing radar, where an imv model can replace the discretization of the plane used in [16] and ii) underwater acoustic sensing, in which the discrete snapshots of the sampled delay doppler spread function can be replaced by a continuous estimate [17] .","{'multiband signal', 'mmv'}",0.0,,,,,
120,281928.0,"we formulate a generic algorithm, referred to as rembo, for the reduction of mmv and boosting. the performance of rembo depends on the embedded smv technique.",{'mmv'},0.0,,,,,
121,281928.0,"the imv model is introduced in section ii, where we also discuss conditions for a unique solution. the deterministic reduction method of imv to mmv and the random reduction of mmv to smv are developed in sections iii and iv, respectively.",{'mmv'},0.0,,,,,
122,11168781.0,simulation result shows that the proposed protocol significantly improves the effective capacity of a sensor network in terms of reliability and quickness. moreover the protocol is highly responsive to the various error conditions experienced and adaptive to large-scale dynamic sensor networks.,{'effective capacity'},0.0,,,,,
123,11168781.0,"in the reliability domain, the protocol takes a different approach and supports a simple, robust and scalable transport that supports error recovery in the hop level itself rather cumulating it still the end. this simple approach with minimum requirements on the signaling reduces the communication cost for data reliability, and finally, responsive to high error rates allowing successful operation even under highly error-prone conditions.",{'reliability domain'},0.0,,,,,
124,6530408.0,for scenes with complex non-rigid deformation multiple-view reconstruction is commonly performed independently at each frame resulting in an unstructured sequence of meshes with each mesh having different vertex positions and connectivity. recent advances in active depth measurement have also introduced low-cost structured light and time-of-flight sensors allowing video-rate 2.5d acquisition of unstructured mesh sequences for the partial non-rigid surface visible from a single viewpoint.,{'unstructured mesh sequence'},1.0,part-of,"unstructured mesh sequences are a part of multiple-view reconstruction for scenes with complex non-rigid deformation that are performed independently at each frame, with each mesh having different vertex positions and connectivity.",unstructured mesh sequence,multiple-view reconstruction for scenes with complex non-rigid deformation,no
125,8033424.0,"however, recent work has provided various approaches for dealing with distributional data in a nonparametric fashion. for example, regression from distributional covariates to real or distributional responses is possible via kernel smoothing (pczos et al. 2012a; oliva, pczos, and schneider 2013) , and many learning tasks can be solved with rkhs approaches (muandet et al. 2012; pczos et al. 2012b) .",{'oliva'},0.0,,,,,
126,16102392.0,"we show that specific personality traits have a distinct direct or moderating effect. we, e.g., found that two personality traits moderate the relationship between perceived ease of use and intention to use.",{'perceive ease'},0.0,,,,,
127,16102392.0,the most used and tested model for technology acceptance is the technology acceptance model tam [1] . within this model two beliefs have causal effects on the intention to use technology: perceived ease of use (peou) and perceived usefulness (pu).,{'perceive ease'},1.0,is-a,perceived ease of use is a belief that has causal effects on the intention to use technology within the technology acceptance model tam.,perceive ease,belief,no
128,16102392.0,,,,compare,perceived ease of use is like perceived usefulness in that they are beliefs that have causal effects on the intention to use technology within the technology acceptance model tam.,perceive ease,perceived usefulness,no
129,195844644.0,"the oil and water in crude oil samples were separated by centrifugation, distillation or electric dehydration, and a water-oil layered mixture was formed according to the unequal densities. then the volume ratio of water and oil was analyzed by digital image processing, and the water content and oil content was able to be calculated.",{'distillation'},1.0,used-for,distillation is used to separate oil and water in crude oil samples.,distillation,separate oil and water in crude oil samples,no
130,195844644.0,,,,compare,distillation is like centrifugation in that they are used to separate oil and water in crude oil samples.,distillation,centrifugation,no
131,195844644.0,,,,compare,distillation is like electric dehydration in that they are used to separate oil and water in crude oil samples.,distillation,electric dehydration,no
132,195844644.0,"the main principle of distillation is to separate this paper is organized as follows. in section 2, the proposed method for the water content of crude oil using computer vision is discussed.",{'distillation'},0.0,,,,,
133,10081036.0,in section 5 we discuss our framework in the context of alternative approaches in the literature. we furthermore point at its compatibility with various generalizations of quantifier elimination by virtual substitution.,{'virtual substitution'},0.0,,,,,
134,11326355.0,"thus, our work differs both in the state representation and the task generalization. in [5] , generation of task models based on multiple human demonstrations is presented.",{'state representation'},0.0,,,,,
135,11326355.0,"thus, our work differs both in the state representation and the task generalization. in [5] , generation of task models based on multiple human demonstrations is presented.",{'state representation'},0.0,,,,,
136,14237137.0,"the tool is built particularly with image support in mind and features a user-friendly interface support for image display and ontology-driven annotation capabilities. recently, independently and concurrently, protg has released five publicly accessible plugins that provide capabilities for ontology visualization: ezowl, jambalaya, ontoviz, owlviz, and tgviz.",{'jambalaya'},1.0,is-a,jambalaya is a publicly accessible plugin that provide capabilities for ontology visualization.,jambalaya,publicly accessible plugin,no
137,14237137.0,,,,compare,jambalaya is like ezowl in that they are publicly accessible plugins that provide capabilities for ontology visualization.,jambalaya,ezowl,no
138,14237137.0,,,,compare,jambalaya is like ontoviz in that they are publicly accessible plugins that provide capabilities for ontology visualization.,jambalaya,ontoviz,no
139,14237137.0,,,,compare,jambalaya is like owlviz in that they are publicly accessible plugins that provide capabilities for ontology visualization.,jambalaya,owlviz,no
140,14237137.0,,,,compare,jambalaya is like tgviz in that they are publicly accessible plugins that provide capabilities for ontology visualization.,jambalaya,tgviz,no
141,14237137.0,"jambalaya [10] provides nested interchangeable views and nicely implements three zooming approaches: geometric, semantic and fisheye zooming. owlviz, and tgviz have graph-like views of ontologies.",{'jambalaya'},1.0,is-a,"jambalaya is a tool that provides nested interchangeable views and nicely implements three zooming approaches: geometric, semantic and fisheye zooming. ",jambalaya,tool,no
142,2018066.0,"for instance, citeseer is a scientific literature digital library that provides academic publications indexed with their citations [9] . different types of hyperlink topology and fitting models are examined extensively for different purposes [15, 26, 48] .",{'citeseer'},1.0,is-a,citeseer is a scientific literature digital library that provides academic publications indexed with their citations.,citeseer,scientific literature digital library,no
143,49325539.0,"predictive process monitoring is concerned with the analysis of events produced during the execution of a process in order to predict the future state of ongoing cases thereof. existing techniques in this field are able to predict, at each step of a case, the likelihood that the case will end up in an undesired outcome.",{'predictive process monitoring'},1.0,is-a,"predictive process monitoring is a technique that is concerned with the analysis of events produced during the execution of a process in order to predict the future state of ongoing cases thereof, with existing techniques in this field able to predict, at each step of a case, the likelihood that the case will end up in an undesired outcome.",predictive process monitoring,technique,no
144,49325539.0,"a set of possible outcomes. this paper is concerned with the latter type of predictive process monitoring, which we call outcome-oriented [3] .",{'predictive process monitoring'},0.0,,,,,
145,49325539.0,"for example, elkan [5] analyzes the notion of misclassification cost and defines conditions under which a misclassification cost matrix is reasonable. turney [13] examines a broader range of costs in the context of inductive concept learning.",{'turney'},0.0,,,,,
146,16764244.0,"with regard to non-optimal decoding, several researchers including the authors of this paper have investigated how much information would be lost if neural correlation is ignored in decoding (nirenberg et al., 2001; wu et al., 2001; golledge et al., 2003; averbeck and lee, 2006; oizumi et al., 2010) . this type of decoding is called mismatched decoding (merhav et al., 1994; oizumi et al., 2010) because the decoding does not match the actual neural activities, i.e., the actual neural activities are correlated but the correlations are ignored in decoding.",{'mismatch decoding'},1.0,type-of,"mismatched decoding is a type of non-optimal decoding that ignores neural correlation in decoding in that the decoding does not match the actual neural activities, i.e., the actual neural activities are correlated but the correlations are ignored in decoding.",mismatched decoding,non-optimal decoding that ignores neural correlation in decoding,no
147,209500502.0,"mdvalse inherits the advantages of valse such as automatically estimating the model order, noise variance and providing uncertain degrees of frequency estimates. compared to valse, the multidimensional frequencies of a single component is treated as a whole, and the probability density function is projected as independent univariate von mises distribution to perform tractable inference.",{'valse'},1.0,compare,"valse is like mdvalse in that it automatically estimates the model order, noise variance and provides uncertain degrees of frequency estimates. ",valse,mdvalse,no
148,209500502.0,"numerical results demonstrate the effectiveness of the mdvalse, compared to state-of-art methods. keywords: variational bayesian inference, line spectral estimation, von mises distribution, multidimensional frequency estimation i. introduction",{'line spectral estimation'},0.0,,,,,
149,192624053.0,such a phenomenon is called scene luminance inversion (sli). raman and chaudhuri 8 used bilateral filtering to calculate the fusion weight of which the value is larger in detail regions.,{'bilateral filtering'},0.0,,,,,
150,192624053.0,"13 calculated the fusion weight by multiplying the well-exposedness, contrast, and saturation, subsequent to which input images were decomposed as a laplacian pyramid to fuse with corresponding weight map. inspired by the approach followed by mertens et al., 13 li et al.",{'laplacian pyramid'},0.0,,,,,
151,39823524.0,"a pattern generator is constructed by connecting oscillators composed of mutually inhibited neurons. the rhythmic signal of the pattern generator drives a proportional derivative controller that determines the joint angles of a virtual character, and the signal of the controller is fed back to the oscillator by which the physical parameters of the controller are utilized for stably and smoothly controlling the signals.",{'mutually inhibit neuron'},0.0,,,,,
152,16148494.0,"in section 2 we describe a probabilistic approach to inference of sparse components and learning of a representation dictionary, and in section 3 we show some applications to music transcription, for both synthesized harpsichord music and real piano music. finally, in section 4 we mention the application of sparse representations to source separation, before concluding.",{'sparse component'},0.0,,,,,
153,800699.0,"the concept of the taut-string algorithm which provides adequate approximations with a small number of local extrema is generalised for analysing two-and higher dimensional data, using delaunay triangulation and diffusion filtering. results are based on equivalence relations in one dimension between the taut string algorithm and the method of solving the discrete total variation flow equation.",{'taut string algorithm'},1.0,is-a,"the taut-string algorithm is a concept that provides adequate approximations with a small number of local extrema and can be generalised for analysing two-and higher dimensional data, using delaunay triangulation and diffusion filtering.",taut string algorithm,concept,no
154,80628341.0,"an accurate representation of the value functional is also crucial for the control design in reinforcement learning (see [4] ). however, we face several difficulties in approximating the d-dimensional value function v d .",{'reinforcement learning'},0.0,,,,,
155,5265174.0,"the analysis of concurrent stochastic games can be classified into: quantitative analysis, analyzing the optimum value of the game and -optimal strategies that ensure values within  of the optimum value; and qualitative analysis, analyzing the set of states with optimum value 1 and -optimal strategies for the states with optimum value 1. we consider concurrent games with tail objectives, i.e., objectives that are independent of the finite-prefix of traces, and show that the class of tail objectives are strictly richer than the -regular objectives.",{'concurrent stochastic game'},0.0,,,,,
156,22210733.0,"acromioclavicular joint (acj) dissociation is one of the common injuries affecting adults. the stability of acj largely depends on the integrity of acromioclavicular ligament, coracoclavicular ligament, capsule, trapezius muscle and deltoid muscle.",{'capsule'},1.0,compare,capsule is like acromioclavicular ligament in that the stability of acromioclavicular joint largely depends on its integrity.,capsule,acromioclavicular ligament,no
157,22210733.0,,,,compare,capsule is like coracoclavicular ligament in that the stability of acromioclavicular joint largely depends on its integrity.,capsule,coracoclavicular ligament,no
158,22210733.0,,,,compare,capsule is like trapezius muscle in that the stability of acromioclavicular joint largely depends on its integrity.,capsule,trapezius muscle,no
159,22210733.0,,,,compare,capsule is like deltoid muscle in that the stability of acromioclavicular joint largely depends on its integrity.,capsule,deltoid muscle,no
160,12511905.0,mahoui and cunningham [10] specified the importance of understanding the information of dl users in creating useful and stable search systems. they analyzed transaction logs to study usage patterns of citeseer in terms of query and search patterns.,{'citeseer'},0.0,,,,,
161,12511905.0,"carevic and mayr [13] proposed bibliometric-enhanced search facilities such as ""journal run"" or ""citation search"" and their possible integration in dls. in their position paper, they argue that bibliometric-enhanced stratagems can facilitate domain specific search activities by applying bibliometric measures for re-ranking and/or rearranging dl-entities like documents, journals or authors.",{'bibliometric - enhance stratagem'},1.0,part-of,"bibliometric-enhanced stratagems are a part of search facilities that can facilitate domain specific search activities by applying bibliometric measures for re-ranking and/or rearranging dl-entities like documents, journals or authors.",bibliometric - enhance stratagem,search facilities,no
162,53670097.0,"the fm-index, which is a compressed subsequence index based on burrows wheeler transform (bwt), is the primary data structure majority of short read aligners -including bowtie [19] , bwa [13] and soap2 [21] .","{'bwa', 'soap2'}",1.0,is-a,"bwa is a short read aligner that has the primary data structure majority of the fm-index, which is a compressed subsequence index based on burrows wheeler transform.",bwa,short read aligner,no
163,53670097.0,,,,is-a,"soap2 is a short read aligner that has the primary data structure majority of the fm-index, which is a compressed subsequence index based on burrows wheeler transform.",soap2,short read aligner,no
164,53670097.0,,,,compare,"bwa is like soap2 in that they are short read aligners that have the primary data structure majority of the fm-index, which is a compressed subsequence index based on burrows wheeler transform.",bwa,soap2,no
165,17786441.0,"there are already a number of studies concerning altmetrics. an overview of these studies can be found in bar-ilan, shema, and thelwall (2014) , haustein (2014), and priem (2014) .",{'shema'},0.0,,,,,
166,80628285.0,we employ uppaal as a verification tool to ensure that predicted function behaviors of the models in east-adl satisfy functional and real-time requirements. the criteria for this architecture-based verification is presented and the transformation rules which comply with this criteria are derived.,{'uppaal'},1.0,is-a,uppaal is an architecture-based verification that is used to ensure that predicted function behaviors of the models in east-adl satisfy functional and real-time requirements.,uppaal,architecture-based verification,no
167,80628285.0,"section 2 introduces technology and background, east-adl and uppaal toolkit as used in our approach. section 3 presents our approach and methodology to improve formal analysis and verification capability of east-adl.",{'uppaal'},0.0,,,,,
168,80628285.0,"[21] language is used as the formal underpinning. we take a similar approach by transforming east-adl constructs to timed automata, especially uppaal ta, in order to allow tool-supported automated simulation and verification of east-adl specification by using uppaal model checker.",{'time automata'},0.0,,,,,
169,11686521.0,"besides cost-based abduction, several efficient mechanisms have also been developed for other kinds of propositional reasoning, such as satisfiability problems (sat) or constraint satisfaction problems (csp). in the sat case, starting from gsat [9] , a set of powerful new local search heuristics has been developed [10] [11] [12] .",{'gsat'},0.0,,,,,
170,35045639.0,"this methodology is based on a representation of surfaces termed square-root normal fields (srnfs), which enables invariance to all shape preserving transformations including translation, scale, rotation, and re-parameterization. we extend this framework by computing parametrization-invariant statistical summaries of endometrial tissue shapes, and random sampling from learned generative models.",{'learn generative model'},0.0,,,,,
171,937579.0,appscope [42] models power consumption by monitoring the changes at the kernel. appscope monitors ne-grained utilization at the android binder level and at the system call level.,{'appscope'},1.0,is-a,appscope is a power consumption model that monitors the changes at the kernel and the ne-grained utilization at the android binder level and at the system call level.,appscope,power consumption model,no
172,5687133.0,"group testing: studies of group testing problems began several decades ago [10], [11] , and have recently regained significant attention [2], [12] , with applications including medical testing, database systems, computational biology, and fault detection. the goal is to determine a small number of ""defective"" items within a larger subset of items.",{'group testing problem'},1.0,part-of,"group testing problems are a part of studies with the goal of determining a small number of ""defective"" items within a larger subset of items and with applications including medical testing, database systems, computational biology, and fault detection.",group testing problem,studies,no
173,210842484.0,"some have allocated curator effort to write summaries, whereas others compute them from data within the database. manually written gene summaries are present in the saccharomyces genome database (sgd) (1) and uniprotkb (2) and were initially available in wormbase, the database for c. elegans and related nematodes (3), before they shifted to computationally derived summaries.",{'sgd'},1.0,is-a,sgd is the saccharomyces genome database that contains manually written gene summaries.,sgd,saccharomyces genome database,no
174,210842484.0,,,,compare,sgd is like uniprotkb in that they are databases that contain manually written gene summaries.,sgd,uniprotkb,no
175,10359409.0,"we present our implementation of a vision system on a mobile robot platform that uses a camera image as the primary sensory input. having to perform all processing, including segmentation and object detection, in real-time on-board the robot, eliminates the possibility of using some state-of-the-art methods that otherwise might apply.",{'object detection'},0.0,,,,,
176,31273121.0,"the client entity is included in the cloudsim, a framework for modelling and simulation of cloud computing. experimental results show the influence of the client behavior on the performance of the services executed in a cloud computing system.",{'cloudsim'},1.0,is-a,cloudsim is a framework that models and simulates cloud computing.,cloudsim,framework,no
177,31273121.0,"all tasks (called cloudlets in cloudsim) are sent at the beginning of the experiment and ordered in the broker, from most urgent to least urgent. the authors claim to have performance gains in reducing the number of nodes allocated to the workload and preservation of the execution time required by tasks deadlines.",{'cloudsim'},0.0,,,,,
178,31273121.0,kathiravelu and veiga [11] present an extension to cloudsim called cloud2sim. they propose to transform the cloudsim in a parallel and distributed simulator using a computer cluster infrastructure to run the simulations.,{'cloudsim'},0.0,,,,,
179,31273121.0,"the proposed implementation called ram broker decides, in a proactive manner, in which cloud resource the workload should be allocated. the proposed approach in this work makes use of cloudsim and considers fault tolerance in their implementation.",{'cloudsim'},0.0,,,,,
180,31273121.0,"[15] report on an experience to provide a perspective of the client in the simulations, introducing enhancements in cloudsim. it is possible to compare different cloud computing providers and select the best features for the client requirements.",{'cloudsim'},0.0,,,,,
181,15654537.0,"but neither heuristic absolutely preserves connectivity, even if it is achievable in principle. cone-based topology control (cbtc), proposed by li et al.",{'cone - base topology control'},0.0,,,,,
182,15654537.0,rodoplu and meng [9] addressed a work targeting significant reductions in energy consumption. they introduced the notion of relay region based on a specific power model.,{'relay region'},0.0,,,,,
183,14231877.0,"we obtain an n-letter capacity expression and prove that the capacity is achieved by an encoding scheme that depends only on the current battery state. moreover, the capacity is invariant to the non-causal knowledge of energy arrivals.",{'energy arrival'},0.0,,,,,
184,14231877.0,"we follow previous work in [4]- [7] and model the energy arrivals as multiples of a fixed quanta. consequently, we obtain a physical layer which has a discrete alphabet based on this quanta.",{'energy arrival'},0.0,,,,,
185,14231877.0,"unlike the case of battery state information at the receiver side [4], resulting channel is not a markov channel when energy arrival side information is available at the receiver. in addition, the state information of this nonmarkov channel is available at both the transmitter and the receiver.",{'energy arrival information'},0.0,,,,,
186,14231877.0,the energy harvesting channel is a state-dependent channel where state process has memory and is input dependent. we follow previous work in [4] - [7] and model the energy arrivals as multiples of a fixed quanta.,{'energy arrival'},0.0,,,,,
187,14231877.0,"consequently, we obtain a physical layer which has a discrete alphabet based on this quanta. unlike the case of battery state information at the receiver side [4] , resulting channel is not a markov channel when energy arrival side information is available at the receiver.",{'energy arrival information'},0.0,,,,,
188,9804296.0,"one of the most used is the spherical camera model [10] , [3] , which has been integrated in a monocular slam by rituerto et al. in [19] .",{'monocular slam'},0.0,,,,,
189,7173250.0,"in this paper, we focus on the point (ii). the main challenge to overcome when re-exploiting some parts of the already licensed spectrum lies in the fact that secondary users should insert their communication without causing harmful interference to the incumbent legacy users.",{'secondary user'},0.0,,,,,
190,7173250.0,"this spectrum mask is usually specified by the standard followed by the incumbent users. cp-ofdm, suffering from poor spectral containment, can hardly fit efficiently in these spectrum masks and is therefore not efficiently applicable to secondary users [2] , [3] , [5] , [6] .",{'secondary user'},0.0,,,,,
191,7173250.0,"building on this, a number of papers have investigated the benefits of using fb based waveforms for the insertion of secondary users [9] - [12] . some real-world demonstrations of coexistence between fb waveforms and cp-ofdm have also been undertaken by both industrials and academics [13] - [15] .",{'secondary user'},0.0,,,,,
192,7173250.0,"the advantages of using fb waveforms instead of cp-ofdm for secondary users are then rated in terms of the maximum performances that each waveform can achieve under the same spectral mask. however, psd only accounts for the properties of the transmit signal, and totally neglects the effects of the cp-ofdm incumbent reception.",{'secondary user'},0.0,,,,,
193,7173250.0,"we further showed that, considering evm measurements, the interference caused by secondary users is not drastically reduced if the latter use fb waveforms instead of cp-ofdm [16] . as these previous results are contradictory with many results published in the literature, it is important to justify them clearly and revise some previously published results with regards to these new findings.",{'secondary user'},0.0,,,,,
194,16958418.0,"this cost is significant -as an example, tolerating 10 faults in an ensemble of 1000 cores (a 1% error rate) requires 11,000 processes! yet other systems such as mapreduce use the concept of deterministic replay.",{'mapreduce'},1.0,is-a,mapreduce is a system that uses the concept of deterministic replay.,mapreduce,system,no
195,16958418.0,"they model the faults by encapsulating all fault prone operations as an unreliable preconditioning operator and then build the fault-tolerant linear solver within the framework of flexible krylov subspace methods, like flexible gmres [11] . the flexible outer iteration is required to be completely reliable.",{'flexible gmre'},1.0,type-of,flexible gmres are a type of flexible krylov subspace method.,flexible gmre,flexible krylov subspace method,no
196,16958418.0,"for inexact krylov subspace methods, the magnitude of perturbations need to be controlled to maintain the convergence, although the perturbations can happen anywhere in the result of a numerical operation. in contrast, our erasure-coded approach does not presume any bound on the perturbations; but it does require the perturbations to be sparse in the affected components.",{'inexact krylov subspace method'},1.0,is-a,"inexact krylov subspace methods are methods where the magnitude of perturbations need to be controlled to maintain the convergence, although the perturbations can happen anywhere in the result of a numerical operation.",inexact krylov subspace method,method,no
197,16958418.0,,,,compare,"inexact krylov subspace methods are an alternative to erasure-coded approaches, where the magnitude of perturbations need to be controlled to maintain the convergence, although the perturbations can happen anywhere in the result of a numerical operation.",inexact krylov subspace method,erasure-coded approach,no
198,32271588.0,"because (2) provides one constraint in two unknowns it is common to combine constraints at neighboring pixels, assuming that the optical flow field is locally constant or affine [1, 2] . this produces a system of linear equations that can be solved using standard (weighted) least squares [14] , or total least squares (tls)",{'optical flow field'},0.0,,,,,
199,32271588.0,"one disadvantage of the approach is that the basis set must be computed from the target, under varying illumination, prior to the tracking. also, the resulting parameters specify a location in the eigenspace of training images, rather than a physical model of the brightness variation.",{'training image'},0.0,,,,,
200,10336544.0,"wu huan proposed an improved algorithm iaa, which adopts a new count-based method to prune candidate itemsets and uses generation record to reduce total data scan amount [11] . wang yuan proposes an improved item constrain association rules mining algorithm, which improves traditional algorithm in two aspects: trimming frequent itemsets and calculating candidate itemsets [12] .",{'candidate itemset'},0.0,,,,,
201,13106128.0,this paper present an approach for content based image retrieval applied to art paintings using the concept of bag of keypoints and surf detector. a descriptor for dominant color is also used and weighted for a best visual retrieval.,{'surf detector'},0.0,,,,,
202,13106128.0,"each one with pictures of landscapes and portraits. as the surf algorithm only evaluates images in grayscale, a dominant color descriptor was used to describe colors.",{'surf'},1.0,is-a,surf is an algorithm that only evaluates images in grayscale.,surf,algorithm,no
203,44090545.0,"in a final step, spectrum-based fault localization (sfl) is used to compute the suspiciousness of each cell. cells that are often involved in calculation chains of smelly cells and less often in calculation chains of non-smelly cells are more suspicious of being faulty.","{'spectrum - base fault localization', 'suspiciousness'}",1.0,used-for,"spectrum-based fault localization is used to compute suspiciousness, where cells that are often involved in calculation chains of smelly cells and less often in calculation chains of non-smelly cells are more suspicious of being faulty.",spectrum - base fault localization,suspiciousness,yes
204,207930584.0,"typical approaches involve neural networks [5] - [7] , support vector machines [8] , fuzzy cognitive maps [9] or the extraction and analysis of a priori defined features [10] . while many of these algorithms achieve detection fig. 1 .",{'fuzzy cognitive map'},0.0,,,,,
205,212633930.0,"twitter is a well-structured streaming source of sociotechnical data allowing for the study of dynamical linguistics and cultural phenomena [1, 2] . of course, like many other social platforms, twitter represents only a subsample of the publicly declared views of utterances, and interactions of millions of individuals, organizations, and automated accounts (twitter social bots) around the world [3] [4] [5] [6] .",{'automate account'},0.0,,,,,
206,212633930.0,"researchers have, nevertheless, shown that twitter's collective conversation mirrors the dynamics of local and global events [7] including earthquakes [8] , flu and influenza [9, 10] , crowdsourcing and disaster relief [11, 12] , major political affairs [13, 14] , and fame dynamics for political figures and celebrities [15] . moreover, analyses of social media data and digital text corpora over the last decade have advanced natural language processing (nlp) research [16] [17] [18] , sentiment detection [19] [20] [21] , word representation [22] [23]",{'word representation'},0.0,,,,,
207,14377089.0,"they are: (1) robustness to data noise; (2) sparsity; (3) datum-adaptive neighborhood. their experimental results also prove that l 1 graph has significant performance improvement in many machine learning applications such as spectral clustering, subspace learning and semi-supervised learning [4] .",{'spectral clustering'},1.0,type-of,spectral clustering is a type of machine learning application.,spectral clustering,machine learning application,no
208,14377089.0,"by these operations, the dimension of the dataset is reduced and the computational time is reduced. l 1 graph has strong theory connection with sparse subspace clustering [9] .",{'sparse subspace clustering'},0.0,,,,,
209,3042738.0,"secondly, instead of segmenting the roi directly, convolutional neural network is employed to predict the vector field of the dynamical system. finally, the boundary of the roi is identified using the poincar map and the flow integration.",{'convolutional neural network'},0.0,,,,,
210,15711455.0,"the latter methods seem to render good estimates, although they typically require rather large data sets to do so. the reassignment method will yield perfect localization of the if for each chirp component, given enough noise-free observations.",{'reassignment method'},0.0,,,,,
211,57373764.0,"recently, a tensor dictionary learning (tdl) [20] method was proposed for spectral ct reconstruction by accommodating sparsity in both spatial and spectral dimensions.",{'spectral ct reconstruction'},0.0,,,,,
212,57373764.0,"recently, a generalized analysis dictionary model called sparsifying transform (st) model was investigated in [22] , [23] , where sparse coefficients are efficiently obtained in the transform domain by thresholding-type operations. learned sparsifying transforms have recently shown promise for ldct image reconstruction compared to nonadaptive methods [24] , [25] .",{'sparse coefficient'},1.0,part-of,sparse coefficients are a part of sparsifying transform models that are efficiently obtained in the transform domain by thresholding-type operations.,sparse coefficient,sparsifying transform model,no
213,28857399.0,", yn. the effects of rounding errors in this plot are negligible because we used the high precision arithmetic provided by the mpfr library [16] , with a mantissa of 640 bits.",{'mpfr library'},0.0,,,,,
214,8549315.0,"the sns classification model use negative selection and pso algorithms to form a set of memory artificial lymphocytes (alcs) that have the ability to distinguish between normal and epileptic eeg patterns. thus, adapted negative selection is employed to create a set of self-tolerant alcs.","{'negative selection', 'pso algorithm'}",1.0,part-of,pso algorithms are a part of the sns classification model that are used to form a set of memory artificial lymphocytes (alcs) that have the ability to distinguish between normal and epileptic eeg patterns. ,pso algorithm,sns classification model,no
215,8549315.0,,,,used-for,negative selection is used to create a set of self-tolerant alcs in the sns classification model.,negative selection,create a set of self-tolerant alcs in the sns classification model,no
216,40298889.0,"most importantly, we point out that we can achieve both security and energy efficiency in most cases simply by categorizing data based on their sensitivity and user security policies along with user perception about the security offered by the cloud. thinkair architecture (kosta et al., 2011) develops on maui and clonecloud by exploiting parallelizability of method execution using multiple vm images.",{'maui'},0.0,,,,,
217,198339983.0,"some other generalizations fs are proposed by some scholars such as pythagorean fuzzy sets [3] , hesitant pythagorean fuzzy sets [4] . however, these are rather different from real magdm problems.",{'pythagorean fuzzy set'},1.0,compare,pythagorean fuzzy set is like hesitant pythagorean fuzzy set in that they are both generalizations fs.,pythagorean fuzzy set ,hesitant pythagorean fuzzy set,yes
218,198339983.0,,,,type-of,pythagorean fuzzy set is a type of generalizations fs.,pythagorean fuzzy set ,generalizations fs,no
219,198339983.0,"in order to deal with this case, smarandache [5] , [6] initially developed the concept of neutrosophic set (ns), which has the capacity of dealing inconsistent and indeterminate information. in the ns, its degree of membership tr a (a)",{'neutrosophic set'},1.0,is-a,neutrosophic set is a method which has the capacity of dealing inconsistent and indeterminate information.,neutrosophic set,method,no
220,198339983.0,"to utilize ns easily in real application wang et al. [7] proposed the concept of single valued neutrosophic set (svns) by changing the non-standard unit interval into the standard unit interval [0, 1] .",{'single value neutrosophic set'},1.0,compare,"single valued neutrosophic set is like ns except that the non-standard unit interval is changed to the standard unit interval [0, 1].",single valued neutrosophic set,ns,no
221,198339983.0,"further, wang et al. [8] proposed the concept of interval neutrosophic set (ins).",{'interval neutrosophic set'},0.0,,,,,
222,198339983.0,"to overcome these limitations, zhang et al. [34] developed the concept of 2-tuple linguistic neutrosophic set (2-tlns) based on the svns and 2-tuple linguistic information model, which is the generalization of several concepts such as 2-tuple linguistic set, 2-tuple linguistic fuzzy set and 2-tuple linguistic intuitionistic fuzzy set [35] .",{'svns'},0.0,,,,,
223,10250610.0,"ict has evolved from a supporting role to the core business of many organisations. this transition to e-business (i.e., doing business using ict) requires a multidisciplinary approach that combines elements of business process reengineering (bpr), supply chain integration, marketing, and software engineering [5] .",{'bpr'},1.0,part-of,bpr is part of the e-business approach.,bpr,the e-business approach,no
224,10250610.0,,,,compare,bpr is like supply chain integration in that they are both part of the e-business approach.,bpr,supply chain integration,no
225,10250610.0,,,,compare,bpr is like marketing in that they are both part of the e-business approach.,bpr,marketing,no
226,10250610.0,,,,compare,bpr is like software engineering in that they are both part of the e-business approach.,bpr,software engineering,no
227,2999978.0,"in [3] , the same authors considered the problem of jointly routing the flows and scheduling transmissions to achieve a given rate vector using the protocol model of interference. they developed necessary and sufficient conditions for the achievable rate vector.",{'protocol model'},0.0,,,,,
228,2999978.0,they formulated the problem as a linear programming problem and implemented primal-dual algorithms for solving the problem. the scheduling problem is solved as a graph edge-coloring problem using existing greedy algorithms.,{'primal - dual algorithm'},0.0,,,,,
229,2999978.0,"alicherry et al. [1] mathematically formulated the joint channel assignment and routing problem in multiradio mesh networks, and established necessary and sufficient conditions under which interference-free link communication schedule can be obtained and designed an simple greedy algorithm to compute such a schedule.",{'joint channel assignment'},0.0,,,,,
230,202788207.0,"these three types of singularities have been studied for numerous types of robots. husty and zsombor-murray (1994) reported a special type of singular stewart-gough platform, in which the six leg axes remain in a specific linear complex, congruence or hyperbolical ruled surface under the singular configuration, which they called constraint singularity.",{'constraint singularity'},1.0,type-of,"constraint singularity is a special type of singular stewart-gough platform, in which the six leg axes remain in a specific linear complex, congruence or hyperbolical ruled surface under the singular configuration.",constraint singularity,singular stewart-gough platform,no
231,202788207.0,"(2002) studied the constraint singularity for a pkm with less than six dofs, where both the mechanism as a whole and the mobile platform (mp) have at least one increased dof. liu et al.",{'constraint singularity'},0.0,,,,,
232,195190932.0,"additionally, ivis learns a parametric mapping from the high-dimensional space to low-dimensional embedding, facilitating seamless addition of new data points to the mapping function. importantly, we demonstrate that ivis preserves distances in low-dimensional projections, enabling biological interpretation.",{'low - dimensional embedding'},0.0,,,,,
233,6839232.0,"in this paper we introduce a novel method to extract information from such multi-layer networks, where each type of link forms its own layer. using the concept of pareto optimality, community detection in this multi-layer setting is formulated as a multiple criterion optimization problem.",{'community detection'},1.0,type-of,community detection is a type of multiple criterion optimization problem in the multi-layer setting.,community detection,multiple criterion optimization problem ,no
234,6839232.0,"to show how this can be done, we propose a new method of community detection for multi-layer networks. our approach employs multi-objective optimization, taking into account multiple layers of network structure, which is then used to find a community partition.",{'community detection'},1.0,used-for,community detection is used for multi-layer networks.,community detection,multi-layer networks,no
235,6839232.0,,,,is-a,"community detection is a method which employs multi-objective optimization, taking into account multiple layers of network structure, which is then used to find a community partition.",community detection,method,no
236,6787084.0,"this attack is more complex than the original sidelnikov and shestakov but, because it does not rely on the computation of minimum codewords as in [ss92] , it might be applied to other families of codes such as reed-muller codes. this is in particular the case for wild goppa codes [blp10] as shown in the paper [cot14] where this technique was further developed and applied to wild goppa codes defined over quadratic extensions.",{'wild goppa code'},0.0,,,,,
237,10168292.0,"in this paper we will describe and assess a spectral-galerkin channel flow solver based on fourier and shen's chebyshev basis [13] . the solver will consist of parts that scale at worst as n log n , for a 1d problem of size n , and as such as n 3 log n for a 3d box of size n 3 .",{'3d box'},0.0,,,,,
238,47312261.0,"some well-established reduced-rank approaches include the joint domain localized (jdl) algorithm [4, 5] ; the parametric adaptive matched filter (pamf) [6] , including a knowledge-aided version [7] ; the algorithm [8, 9] ; and newer approaches with antenna-pulse selection [10] or amplitude and phase estimation [11] .",{'parametric adaptive match filter'},1.0,is-a,parametric adaptive matched filter is a well-established reduced-rank approach.,parametric adaptive matched filter,well-established reduced-rank approach,no
239,47312261.0,,,,compare,parametric adaptive matched filter is like joint domain localized (jdl) algorithm in that they are both well-established reduced-rank approaches.,parametric adaptive matched filter,joint domain localized (jdl) algorithm,no
240,645845.0,"our focus in this paper is to learn models of human motion from motion capture (mocap) data. more specifically, we are interested in human motion prediction, where we forecast the most likely future 3d poses of a person given their past motion.",{'human motion prediction'},1.0,is-a,human motion prediction is a method which forecasts the most likely future 3d poses of a person given their past motion.,human motion prediction,method,no
241,645845.0,"for example, [10] uses curriculum learning and incorporates representation learning in the architecture, and [18] manually encodes the semantic similarity between different body parts. these approaches benefit from large, publicly available collections of motion capture data [16] , as well as recent advances in the optimization of time-series modelling [9] .",{'curriculum learning'},0.0,,,,,
242,645845.0,"both of our contributions can be implemented using an architecture that is significantly simpler than those in previous work. in particular, we move from the usual multi-layer lstm architectures (long short-term memory) to a single gru (gated recurrent unit), and do not require a spatial encoding layer.","{'long short - term memory', 'gate recurrent unit'}",0.0,,,,,
243,645845.0,"more complex models like mixtures of hmms [33, 34] , latent topic models of visual words [49] or lstms [29] are used in recent methods. although their purpose (action classification from a sequence of poses) is different from ours, this field contains interesting insights for motion prediction, such as the importance of a mathematically sound orientation representation [46, 47] or how learned, compact motion representations improve action recognition accuracy [30] .","{'visual word', 'latent topic model'}",1.0,used-for,latent topic models are used for action classification from a sequence of poses.,latent topic models,action classification from a sequence of poses,no
244,645845.0,,,,compare,latent topic models are like mixtures of hmms in that they are both used for action classification from a sequence of poses.,latent topic models,mixtures of hmms,no
245,645845.0,"another popular use of motion models, specially shortterm ones, is pose tracking. the use of simple linear markovian models [37] or pca models [44] has evolved to locally linear ones like factor analizers [28] , non-linear embeddings like laplacian eigenmaps [38] , isomap [19] , dynamic variants of gaussian process latent variable models (gplvm)",{'gplvm'},0.0,,,,,
246,645845.0,"arikan and forsyth [2] collapse full sequences into nodes in a directed graph, connected with possible transitions between them, and in [24] cluster trees improve the path availability. more recently, motion models based on gplvm have been used for controlling virtual characters in a physical simulator [27] .",{'gplvm'},0.0,,,,,
247,645845.0,"for example, there is a now a large body of work on visual question answering (vqa), i.e. the task of answering natural-language questions by looking at images, based almost exclusively on end-to-end trainable systems with deep cnns for visual processing and deep rnns for language modelling [31, 35, 50] . recently, however, zhou et al.","{'visual question', 'vqa'}",1.0,is-a,"vqa is a task of answering natural-language questions by looking at images, based almost exclusively on end-to-end trainable systems with deep cnns for visual processing and deep rnns for language modelling.",vqa,task,no
248,10238138.0,"abstract-we show that it is possible to identify individual personality traits and measure group performance in a postanesthesia care unit (pacu) using wearable sensors. we instrumented a group of 67 nurses working in the pacu of a boston area hospital with sociometric badges capable of measuring physical activity, speech activity, face-to-face interaction, and physical proximity.",{'sociometric badge'},1.0,used-for,"sociometric badges are used for measuring physical activity, speech activity, face-to-face interaction, and physical proximity.",sociometric badges,"measuring physical activity, speech activity, face-to-face interaction, and physical proximity",no
249,119438821.0,this work was based on the dlm/fd method developed by glowinski et al. [25] (for rigid body motion) and extended to deforming bodies by yu [26] .,{'glowinski'},0.0,,,,,
250,3637558.0,"comparisons against the matlab tensor toolbox show over 10 times speed improvements. thus, these advancements produce significant practical improvements for sparse tensor arithmetic.",{'matlab tensor toolbox'},0.0,,,,,
251,199064556.0,"a two-ray model with an empirically determined ground height was found to be effective at modeling path loss for the 2.7 m while a single-slope model did well for the 1.6 m terminal. similarly, low-height measurements in [26] found two-ray was effective for lamppost heights, while a blockage model was needed for peer-peer links.",{'blockage model'},0.0,,,,,
252,199064556.0,"our work derives its conclusions based on over 3000 continuous wave (cw at 28 ghz) links measured at multiple base locations, collected from 12 streets in manhattan and valparaso, chile. each link measurement consisted of over 30 azimuth scans, slope-intercept fit represents measured path loss in the street canyons with a rms deviation of 7.1 db. median degradation suffered by offsetting the base antenna from the roof edge, as is often done in practical installations, is found to be 15 db at 100 m. we find high effective directional gains are available even in the presence of street-induced scatter, with 90% of locations suffering under 2 db gain reduction.",{'28 ghz'},0.0,,,,,
253,214605856.0,"using the generalized phase retrieval problem as an illustrative example, we show that careful symmetry breaking on the training data can help get rid of the difficulties and significantly improve the learning performance. we also extract and highlight the underlying mathematical principle of the proposed solution, which is directly applicable to other inverse problems.",{'generalized phase retrieval problem'},0.0,,,,,
254,214605856.0,"[tgs + 18], real-valued fourier phase retrieval [sllb17] , 3d surface tangents and normal prediction [hzfg19] , nonrigid structure-from-motion [kl19, wll20] .",{'normal prediction'},0.0,,,,,
255,3247753.0,"the recursive reasoning method combined with reinforcement learning has been adopted in designing agents for double auctions (hu & wellman, 1996; wellman & hu, 1998) . hu and wellman have studied the self-fulfilling bias of learning agents in synchronized double auctions.",{'reinforcement learning'},0.0,,,,,
256,67856497.0,"in order to solve extrinsic calibration problems under such challenging configurations, the proposed solution exploits road markings as static and robust features among the various objects that are present in urban environments. first, this study utilizes road markings that are commonly captured by the two sensor modalities to select informative images for estimating the extrinsic parameters.",{'extrinsic parameter'},0.0,,,,,
257,67856497.0,"in particular, when lidar measurements are non-continuous, the detection of an accurate correspondence between the two modalities is not straightforward. furthermore, this type of calibration is not possible if the two sensors do not provide covisibility at a given moment in time.",{'covisibility'},0.0,,,,,
258,8902220.0,"it is in fact difficult to implement, e.g. linear arithmetic constraints within the language of fol. in this paper we propose a novel class of hybrid srl methods that rely on satisfiability modulo theories, an alternative class of formal languages that allow to describe, and reason over, mixed boolean-numerical objects and constraints.",{'satisfiability modulo theory'},0.0,,,,,
259,8902220.0,"in order to side-step these limitations, researchers in automated reasoning and formal verification have developed more appropriate logical languages that allow to natively reason over mixtures of boolean and numerical variables (or more complex algebraic structures). these languages are grouped under the umbrella term of satisfiability modulo theories (smt)",{'satisfiability modulo theory'},1.0,is-a,satisfiability modulo theory is a term used to describe logical languages that allow to natively reason over mixtures of boolean and numerical variables (or more complex algebraic structures).,satisfiability modulo theory,term,no
260,8902220.0,"most current approaches are direct generalizations of existing srl methods [1] . hybrid markov logic networks [5] extend markov logic by including continuous variables, and allow to embed numerical comparison operators (namely =,  and ) into the constraints by defining an ad hoc translation of said operators to a continuous form amenable to numerical optimization.",{'hybrid markov logic network'},1.0,used-for,"hybrid markov logic networks are used to embed numerical comparison operators (namely =,  and ) into the constraints by defining an ad hoc translation of said operators to a continuous form amenable to numerical optimization.",hybrid markov logic networks,"embed numerical comparison operators (namely =,  and) into the constraints",no
261,132372213.0,"therefore, it is often called machine intelligence (poole, mackworth, & goebel, 1998) to contrast it to human intelligence (russell & norvig, 2010) . the field revolved around the intersection of cognitive science and computer science (tenenbaum, kemp, griffiths, & goodman, 2011) .",{'norvig'},0.0,,,,,
262,132372213.0,"in ai there was always a strong linkage to explainability, and an early example is the advice taker proposed by mccarthy in 1958 as a ""program with common sense"" (mccarthy, 1960) . it was probably the first time proposing common sense reasoning abilities as the key to ai.",{'advice taker'},1.0,is-a,advice taker is a program with common sense reasoning abilities.,advice taker,program with common sense reasoning abilities,no
263,132372213.0,"artificial intelligence (ai) is perhaps the oldest field of computer science and very broad, dealing with all aspects of mimicking cognitive functions for real-world problem solving and building systems that learn and think like people. therefore, it is often called machine intelligence (poole, mackworth, & goebel, 1998) to contrast it to human intelligence (russell & norvig, 2010) .",{'norvig'},0.0,,,,,
264,132372213.0,"ai now raises enormous interest due to the practical successes in machine learning (ml). in ai there was always a strong linkage to explainability, and an early example is the advice taker proposed by mccarthy in 1958 as a ""program with common sense"" (mccarthy, 1960) .",{'advice taker'},1.0,is-a,advice taker is program with common sense. ,advice taker,program with common sense,no
265,132372213.0,"dl is very popular today because they are achieving amazing results even at human level performance (lecun, bengio, & hinton, 2015) . a best practice example is a recent work of the thrun group, where they achieved with a dl approach performance on par with medical doctors, demonstrating that such approaches are able to classify skin cancer with a level of competence comparable to human dermatologists (esteva et al., 2017) .",{'skin cancer'},0.0,,,,,
266,132372213.0,"a best practice example is a recent work of the thrun group, where they achieved with a dl approach performance on par with medical doctors, demonstrating that such approaches are able to classify skin cancer with a level of competence comparable to human dermatologists (esteva et al., 2017) . a further example is the promising results of identifying diabetic retinopathy and related eye diseases (ting et al., 2017) .",{'skin cancer'},0.0,,,,,
267,3970013.0,"we consider a map view composed of regular grids or tiles with each showing topic keywords from documents of the corresponding region. to this end, we present a tilebased spatio-temporally exclusive topic modeling approach called stexnmf, based on a novel nonnegative matrix factorization (nmf) technique.",{'nmf'},0.0,,,,,
268,3970013.0,fig. 2(a) shows the topics extracted using the standard nmf from several sampled tiles of the geo-tagged twitter data of new york city. uninteresting keywords such as 'strong' and 'love' make topics less coherent.,{'nmf'},1.0,used-for,nmf is used to extract topics from several sampled tiles of the geo-tagged twitter data of new york city. ,nmf,extract topics,no
269,3970013.0,stexnmf is based on a novel nonnegative matrix factorization (nmf) [14] technique that leverages the idea of a weighted residual matrix.,{'nmf'},0.0,,,,,
270,204961710.0,"additionally, the algorithm resizes the robot to accommodate it's trajectory tracking error. the algorithm was tested in simulations on gazebo with aerial robots.",{'gazebo'},0.0,,,,,
271,16122894.0,"at present, there are many binarization algorithms, but they are optimal for only specific probability distributions of the data source. overcoming the problem, it is shown in this paper that the presented binarization scheme conserves the entropy of the original data having any probability distribution of m-ary source.",{'binarization algorithm'},1.0,type-of,binarization algorithm is a type of algorithm optimal for specific probability distributions of the data source.,binarization algorithm,algorithm,no
272,16122894.0,the scheme has linear complexity in terms of the length of the input data. the binarization scheme can be implemented in context-based adaptive binary arithmetic coding (cabac) for video and image compression.,{'context - base adaptive binary arithmetic coding'},1.0,used-for,context-based adaptive binary arithmetic coding is used for video and image compression.,context-based adaptive binary arithmetic coding,video and image compression,no
273,16122894.0,"therefore, it would be beneficial if binarization is perfomed on m-ary data source before compression algorithms are applied on it. the process where binarization is followed by compression is most notably found in context-based adaptive binary arithmetic coding (cabac) [20] which is used in h.264/avc video coding standard [21] , high efficiency video coding (hevc)","{'hevc', 'context - base adaptive binary arithmetic coding', 'high efficiency video coding'}",1.0,used-for,context-based adaptive binary arithmetic coding is used for processes where binarization is followed by compression.,context-based adaptive binary arithmetic coding,processes where binarization is followed by compression,no
274,16023231.0,"-distributed systems theory typically works backwards from a bad state of the system (e.g., a state in which an exploit has been used to damage the system) to identify the sequence of events that must have happened to arrive at that state. the system has to be specified in a suitable formalism (e.g., lamport's tla+ [14] or lynch and tuttle's input/output automata [21, 22] ), but in some cases it is possible to conduct an invariant analysis without a full system specification.",{'input / output automata'},0.0,,,,,
275,6848436.0,"this seminal paper, relating symbolic learning to search in a state space, has enabled machine learning to integrate techniques from problem solving, operational research and combinatorics: greedy search in foil, beam search in icl, breadth-first search in aleph, 'a' search in progol, ida (iterative-deepening a) search in mio error [20] and heuristic search [21] . however, as surprising as it may seem, the phase transition framework strongly developped in combinatorics has almost not been imported to the realm of symbolic learning.","{'progol', 'beam search'}",0.0,,,,,
276,6848436.0,"we evaluate classical complete relational learners found in the learning systems aleph [27] , progol [28] and propal [29] : informed search algorithms such as best-first top-down generate-and-test (bestf-tgt), asearch top-down generate-and-test (a-tgt), and non-informed ones, such as breadth-first top-down generate-and-test and data-driven (bf-tgt and bf-tdd), depth-first top-down generate-and-test (df-tgt). we also use a lggbased learner: depth-first bottom-up data-driven (df-bdd).",{'progol'},1.0,is-a,progol is a learning system with classical complete relational learners.,progol,learning system,no
277,6848436.0,,,,compare,progol is like aleph in that they are both learning systems with classical complete relational learners.,progol,aleph,no
278,6848436.0,,,,compare,progol is like propal in that they are both learning systems with classical complete relational learners.,progol,propal,no
279,12043712.0,"usually, the spatial resolution of a face image is at least hundreds of pixels and usually will be tens of thousands. from the statistical viewpoint, it will require tens of thousands of face samples to deal with the face recognition problem.",{'face recognition problem'},0.0,,,,,
280,30494262.0,"as a result, in the delivery phase it is possible to perform linear codes across files with different popularities without resorting to zero-padding or concatenation techniques. we will describe our placement strategy for arbitrary range of parameters.",{'delivery phase'},0.0,,,,,
281,30494262.0,to the best of our knowledge this is the first centralized caching strategy that is specifically tailored for nonuniform file popularity. we will demonstrate the potential of this caching strategy by providing explicit delivery schemes for a small choice of the parameters and comparing its performance with the grouping strategies discussed earlier.,{'nonuniform file popularity'},0.0,,,,,
282,129124.0,"also, taking advantage of properties of this corpus, cross-document inference is applied to obtain more ""informative"" probabilities. to the best of our knowledge, we are the first to apply information retrieval and global inference to semi-supervised learning for event extraction.",{'cross - document inference'},0.0,,,,,
283,129124.0,"yangarber et al., 2007) applied cross-document inference to correct local extraction results for disease name, location and start/end time. mann (2007) encoded specific inference rules to improve extraction of information about ceos (name, start year, end year).",{'cross - document inference'},1.0,used-for,"cross-document inference is used to correct local extraction results for disease name, location and start/end time.",cross-document inference,"correct local extraction results for disease name, location and start/end time",no
284,13175608.0,"alternatively, when the channel images are well aligned, the blur can also be computationally removed by multispectral image deblurring [4] . in this work, we will show in section vii that multispectral images can be restored based on the proposed registration framework and the deblurring method introduced in [4] .",{'deblurring method'},1.0,used-for,deblurring method is used to restore multispectral images.,deblurring method,restore multispectral images,no
285,13175608.0,,,,is-a,deblurring method is a method which computationally removes blur from channel images.,deblurring method,method,no
286,13175608.0,"similarity measures, including sum-of-squareddifferences (ssd), correlation coefficient (cc), correlation ratio (cr), and mutual information (mi), have been widely employed in image registration. however, these measures are not robust when registering two images with spatially-varying local intensities [9] .",{'ssd'},,is-a,ssd is a measure widely employed in image registration that is not robust when registering two images with spatially-varying local intensities.,ssd,measure,no
287,13175608.0,,,,compare,ssd is like correlation coefficient (cc) in that they are both measures widely employed in image registration that are not robust when registering two images with spatially-varying local intensities.,ssd,correlation coefficient (cc),no
288,13175608.0,,,,compare,ssd is like correlation ratio (cr) in that they are both measures widely employed in image registration that are not robust when registering two images with spatially-varying local intensities.,ssd,correlation ratio (cr),no
289,13175608.0,,,,compare,ssd is like mutual information (mi) in that they are both measures widely employed in image registration that are not robust when registering two images with spatially-varying local intensities. ,ssd,mutual information (mi),no
290,13175608.0,"differential evolution [10] , a powerful global optimization algorithm, is then used to find the initial optimal point at the bottom layer of the pyramid. finally newton's method is implemented to successively improve the solution at each layers.",{'differential evolution'},1.0,is-a,differential evolution is a powerful global optimization algorithm used to find the initial optimal point at the bottom layer of the pyramid.,differential evolution,powerful global optimization algorithm ,no
291,13175608.0,"first, the gradient operation weakens the influence of the local intensity that is slowly varying. second, the sparseness measure allows for rapidly varying local intensity.",{'sparseness measure'},0.0,,,,,
292,16199536.0,"fuzzy symbolic dynamics (fsd) may be used for dimensionality reduction of high-dimensional signals, defining nonlinear mapping that may be used for visualization of the trajectories that define the state of the whole system. global visualization of high-dimensional trajectories shows various aspects of signals that are difficult to discover looking at individual components, or to notice observing dynamical visualizations.",{'fuzzy symbolic dynamic'},1.0,used-for,"fuzzy symbolic dynamics is used for dimensionality reduction of high-dimensional signals, defining nonlinear mapping that may be used for visualization of the trajectories that define the state of the whole system.",fuzzy symbolic dynamics,dimensionality reduction of high-dimensional signals,no
293,16199536.0,"this is done with the help of fuzzy symbolic dynamics (fsd). to see the trajectories of the global system state ""probes"", or localized functions that are activated in a different way by the trajectories that pass near their center, are placed in the signal space.",{'fuzzy symbolic dynamic'},0.0,,,,,
294,15067822.0,"in this paper we propose an approach called starry vault for finding a multidimensional structure in data vaults. starry vault builds on the specific features of the data vault model to automate multidimensional modeling, and uses approximate functional dependencies to discover out of data the information necessary to infer the structure of multidimensional hierarchies.",{'approximate functional dependency'},1.0,used-for,approximate functional dependencies are used to discover out of data the information necessary to infer the structure of multidimensional hierarchies.,approximate functional dependencies,discover out of data the information necessary to infer the structure of multidimensional hierarchies,no
295,15067822.0,"in this paper we propose an approach called starry vault aimed at finding a multidimensional structure in data vaults so that their data can be fed into a data warehouse (dw) for olap querying. on the one hand, our approach builds on the specific features of the data vault model to automate multidimensional modeling, on the other it uses approximate functional dependencies [7] to discover out of data the information necessary to infer the structure of multidimensional hierarchies.",{'approximate functional dependency'},1.0,used-for,approximate functional dependencies are used to discover out of data the information necessary to infer the structure of multidimensional hierarchies.,approximate functional dependencies,discover out of data the information necessary to infer the structure of multidimensional hierarchies,no
296,15067822.0,"the basic idea is that of following the functional dependencies (fds) expressed in the source schema to build the multidimensional hierarchies. in the following years, there have been some attempts to obtain multidimensional schemata out of xml source data (e.g., [5] ).",{'source schema'},0.0,,,,,
297,9283805.0,"in this paper, we present intguard, a symbolic execution based tool that can repair integer overflows with high-quality source code repairs. specifically, given the source code of a program, intguard first discovers the location of an integer overflow error by using static source code analysis and satisfiability modulo theories (smt) solving.",{'satisfiability modulo theory'},1.0,type-of,satisfiability modulo theory is a type of solver used to discovers the location of an integer overflow error.,satisfiability modulo theory,solver,no
298,9283805.0,"intguard is based on a conservative novel technique for automated generation of repairs for c source code relying on satisfiability modulo theory (smt) constraint solving. note that intguards goal is not to classify integer overflows, which can result in a memory corruption (e.g., if it is used to determine the size of a heap-buffer).",{'satisfiability modulo theory'},0.0,,,,,
299,9283805.0,"integer overflows have threatened software programs for decades. the usage of different types of tools based on: static analysis integer overflow detection [35, 55, 62] , runtime program repair [2] , benign integer overflow identification [62] , directed and random fuzzing [30, 61] , concolic testing [7] , library support and runtime checks [47, 48] , and repair code transfer [57] have helped to reduce the number of integer overflows.",{'concolic testing'},0.0,,,,,
300,9283805.0,"these tools have seen only little to no adoption in the industry; partly because their benefits are hard to assess in the context of real software projects [45] where there is an urgent need to detect and avoid integer overflow based memory corruptions, which can lead to cras [4] or other security vulnerabilities [60, 62] . it is interesting to note that most of these tools are either only used for integer overflow detection or if they are used for code repair then they do not consider detecting first the integer overflow.",{'integer overflow detection'},0.0,,,,,
301,12322758.0,"motivated by various applications of influence maximization such as viral marketing, babichenko and barman [5] take a computational study for general monotone submodular sender utility functions, but still in the case of binary states of nature. they present an algorithm that computes a (1  1 e  )","{'influence maximization', 'viral marketing'}",1.0,is-a,viral marketing is an application of influence maximization.,viral marketing,application of influence maximization,yes
302,42955338.0,"yet before further considering the nature of interpersonal relationships on facebook, we must address the ambiguous nature of the term friend when discussing sns communication (boyd & ellison, 2007) . though colloquial and 30 communication research 38(1) affective components.",{'ellison'},0.0,,,,,
303,42955338.0,"when countering claims that online communication (i.e., more generally than just sns use) produces negative relational outcomes (kraut et al., 1998; nie et al., 2002) , scholars frequently provide empirical evidence demonstrating beneficial outcomes for the strength of both local and long distance social ties (baym, zhang, & lin, 2004; quanhaase, wellman, witte, & hampton, 2002) . that snss likewise maintain social networks may sound tautological; nevertheless, recent research elaborates mechanisms via which snss foster such connections.",{'sns use'},0.0,,,,,
304,42955338.0,"in addition to ledbetter (2009b) , other empirical evidence suggests that internal attitudinal factors influence attraction to online communication as a space for building social connections. both donath (2007) and tufekci (2008) conceptualized sns use as analogous to social grooming among primates (dunbar, 1998) , advancing the claim that resources devoted to regular, brief contacts facilitate relational ties with other individuals in a social network.",{'sns use'},0.0,,,,,
305,42955338.0,"donath noted that this increased efficiency may facilitate formation of social supernets or social networks that are larger than those sustainable through other communication media. this line of theoretical development resonates with parks' (2006) recent argument that all dyadic relationships are intimately constituted in webs of network ties, with individuals sustaining ties using several communication media (sawhney, 2007; walther & parks, 2002) .",{'social supernet'},0.0,,,,,
306,5149073.0,"for rna biologists seeking information on one or more rna families, rfam provides sequences, alignments, cms, trees and secondary structure images. the set of rfam cms and score thresholds may also be downloaded and used with infernal to identify new family members in other sequence databases and for annotating ncrnas in genomes or metagenomes.",{'infernal'},0.0,,,,,
307,11507577.0,"threat activates our defensive system and biases motor responses (bradley et al., 2001) . given that a threatening or dangerous event is most likely directed toward our body (e.g., the sight of a snake attacking), an association between what we see and what we feel in our body can be quickly established (poliakoff et al., 2007) .",{'snake'},0.0,,,,,
308,6532393.0,two source coding models with secrecy constraints are considered. we start by considering zero-delay perfectly secret lossless transmission of a memoryless source.,{'secrecy constraint'},1.0,type-of,secrecy constraint is a type of constraint found in source coding models.,secrecy constraint,constraint,no
309,6532393.0,this paper has two main sections. we start with zero-delay source coding and include secrecy constraints.,{'secrecy constraint'},0.0,,,,,
310,6532393.0,"wyner introduced the wiretap channel in [3] and showed that it is possible to send information at a positive rate with perfect secrecy as long as eve's channel is a degraded version of the channel to bob. when the channels are clean, two approaches can be found in the literature of secure communication.","{'perfect secrecy', 'wyner', 'wiretap channel'}",0.0,,,,,
311,6532393.0,"merhav combined the two approaches with the wire-tap channel [9] . in [10] , schieler and cuff considered the tradeoff between rate, 0018-9448  2015 ieee.",{'wire - tap channel'},0.0,,,,,
312,6532393.0,"namely, encrypt the output of the entropy coder in the cascade of [1] with the key and decrypt before the entropy decoder at the receiver side. the last contribution of this paper is a proof that the cascade of [1] is still optimal and the described separation scheme is optimal with the secrecy constraints.",{'secrecy constraint'},0.0,,,,,
313,3371562.0,"this adds to the complexity of association rules which makes the apriori approach even more costly [5] , thus new approaches to improving the performance of mining sequential patterns have emerged [12, 18, 21, 19] . another aspect of sequential pattern mining has been the various approaches to handling the period of the sequence, e.g., involving multiple time granularities [6] or allowing for partial periodicity of patterns [10] .",{'mine sequential pattern'},0.0,,,,,
314,30496428.0,"however, a recent study shows evidence of an attempt to generate formative feedback through a cba tool named autolep (tiantian, xiaohong, peijun, yuying, & kuanquan, 2010) . developed for use in computer programming courses, this tool evaluates whether or not students' computer programs meets the required specification (summative assessment) and also dynamically tests the syntax and structure of the programs and provides interactive help (formative feedback) to improve students' learning experiences in programming.",{'autolep'},1.0,type-of,autolep is a type of cba tool developed for use in computer programming courses.,autolep,cba tool,no
315,30496428.0,,,,used-for,autolep is used to evaluate whether or not students' computer programs meet the required specification (summative assessment).,autolep,evaluate whether or not students' computer programs meets the required specification,no
316,30496428.0,,,,used-for,autolep is used to dynamically test the syntax and structure of students' computer programs and provides interactive help (formative feedback) to improve students' learning experiences in programming.,autolep,dynamically test the syntax and structure of students' computer programs,no
317,52878948.0,"representing static data sets, such as images, is a living branch in machine learning and eases downstream tasks, such as classification, regression, or decision making. however, the representation of dynamical systems has received less attention.",{'downstream task'},0.0,,,,,
318,56014250.0,"the correlation dimension, lyapunov exponent, approximate entropy were applied in the field of sleep eeg studies [2] . we know that with the deepening of sleep from the awake state, the brain activity degrees reduction of freedom which suggests that the brain cell is continuing coupling, or the original active part is continuing inacting [3] .",{'approximate entropy'},1.0,is-a,approximate entropy is a method used in the field of sleep eeg studies.,approximate entropy,method,no
319,209997272.0,the network parameters and the dictionary are optimized end-to-end via meta-learning. extensive experiments demonstrate that meta-neighborhoods consistently improved classification and regression performance across various network architectures and datasets.,{'meta - learning'},1.0,used-for,meta-learning is a method used to optimize network parameters and dictionaries end-to-end.,meta-learning,method,no
320,209997272.0,"main contributions first, we derive our approach, meta-neighborhoods, as a generalization of knn. we expand and modify knn in several key ways: (1) instead of using a constant estimator, such as an average of nearest neighbors, we consider a parametric estimator that predicts on neighboring points; (2) we formulate our model as a multi-task framework where the parametric estimator is tuned for every single task (query); (3) to enhance the model flexibility and reduce the neighbor searching cost, we learn neighbors stored in a dictionary and retrieve them from it for every query to fine-tune the estimator; (4) both the dictionary and the estimator are trained end-to-end with model agnostic metalearning (maml)",{'maml'},1.0,used-for,maml is a method used to train dictionaries and estimators end-to-end in the meta-neighborhoods approach.,maml,method,no
321,88482265.0,"the diffusion model, g(x(t), u(t) ; p), represents a convenient and powerful way of representing complex stochastic processes and model-plant mismatch as needed for the filtering and prediction algorithm in nmpc. boiroux et al.",{'diffusion model'},1.0,is-a,diffusion model is a convenient and powerful way of representing complex stochastic processes and model-plant mismatch as needed for the filtering and prediction algorithm in nmpc.,diffusion model,convenient and powerful way of representing complex stochastic processes and model-plant mismatch,no
322,88482265.0,"used in the offline system identification, the online stateand parameter-estimation, and the prediction of the dynamic optimization. the diffusion model, g(x(t), u(t); p), represents a convenient and powerful way of representing complex stochastic processes and model-plant mismatch as needed for the filtering and prediction algorithm in nmpc.",{'diffusion model'},1.0,is-a,diffusion model is a convenient and powerful way of representing complex stochastic processes and model-plant mismatch as needed for the filtering and prediction algorithm in nmpc.,diffusion model,convenient and powerful way of representing complex stochastic processes and model-plant mismatch,no
323,88482265.0,"the diffusion model, g(x(t), u(t); p), represents a convenient and powerful way of representing complex stochastic processes and model-plant mismatch as needed for the filtering and prediction algorithm in nmpc. boiroux et al.",{'diffusion model'},1.0,is-a,diffusion model is a convenient and powerful way of representing complex stochastic processes and model-plant mismatch as needed for the filtering and prediction algorithm in nmpc.,diffusion model,convenient and powerful way of representing complex stochastic processes and model-plant mismatch,no
324,88482265.0,"used in the offline system identification, the online stateand parameter-estimation, and the prediction of the dynamic optimization. the diffusion model, g(x(t), u(t); p), represents a convenient and powerful way of representing complex stochastic processes and model-plant mismatch as needed for the filtering and prediction algorithm in nmpc.",{'diffusion model'},1.0,is-a,diffusion model is a convenient and powerful way of representing complex stochastic processes and model-plant mismatch as needed for the filtering and prediction algorithm in nmpc.,diffusion model,convenient and powerful way of representing complex stochastic processes and model-plant mismatch,no
325,88482265.0,"the diffusion model, g(x(t), u(t); p), represents a convenient and powerful way of representing complex stochastic processes and model-plant mismatch as needed for the filtering and prediction algorithm in nmpc. boiroux et al.",{'diffusion model'},1.0,is-a,diffusion model is a convenient and powerful way of representing complex stochastic processes and model-plant mismatch as needed for the filtering and prediction algorithm in nmpc.,diffusion model,convenient and powerful way of representing complex stochastic processes and model-plant mismatch,no
326,88482265.0,"the diffusion model, g(x(t), u(t); p), represents a convenient and powerful way of representing complex stochastic processes and model-plant mismatch as needed for the filtering and prediction algorithm in nmpc. boiroux et al.",{'diffusion model'},1.0,is-a,diffusion model is a convenient and powerful way of representing complex stochastic processes and model-plant mismatch as needed for the filtering and prediction algorithm in nmpc.,diffusion model,convenient and powerful way of representing complex stochastic processes and model-plant mismatch,no
327,3819419.0,"recently, patch-based prior has shown promising performance in image denoising. one representative example is sparse coding based scheme, which assumes that each patch of an image can be precisely modeled as a sparse linear combination of basic elements.",{'sparse linear combination'},0.0,,,,,
328,3819419.0,"considering that natural images are non-gaussian and image patches are regarded as samples of a multivariate vector, gaussian mixture models (gmms) have emerged as favored prior for natural image patches in various image restoration studies [7] [8] [9] . for instance, zoran and weiss [7] exploited gmm model to learn image patches from clean natural image dataset, and proposed a method which can reconstruct the latent image by maximizing the expected patch log likelihood.","{'expect patch log likelihood', 'latent image'}",0.0,,,,,
329,3819419.0,"the seminal work of nonlocal means (nlm) [1] utilized the nss prior to implement a form of the weighted filtering for image denoising. after this, inspired by the success of the nlm denoising filtering, a flurry of nss based methods [11] [12] [13] [14] [23]",{'nonlocal mean'},0.0,,,,,
330,3819419.0,"dong et al . [25] proposed the nonlocally centralized sparse representation (ncsr) model for image restoration, which obtained sparse coding coefficients estimate of the original image by the principle of nlm [1] , and then according to those estimates, ncsr, centralized the sparse coding coefficients of the observed image to improve the denoising performance.","{'denoise performance', 'ncsr'}",1.0,is-a,"ncsr is a model used for image restoration, which obtained sparse coding coefficients estimate of the original image by the principle of nlm.",ncsr,model,no
331,3819419.0,,,,used-for,ncsr is used to centralize sparse coding coefficients of an observed image to improve the denoising performance.,ncsr,centralize sparse coding coefficients of an observed image,no
332,3819419.0,[39] exploited a patch-snr as a metric to decide whether a noisy patch is denoised using internal priors or external priors. yue et al .,{'noisy patch'},0.0,,,,,
333,3819419.0,"for example, jain and seung [43] proposed to use convolutional neural network (cnn) for natural image denoising and claimed that cnn has similar or even better representation power than markov random field (mrf) model [49] . burger et al .","{'cnn', 'convolutional neural network'}",1.0,used-for,cnn is used for natural image denoising.,cnn,natural image denoising,no
334,3819419.0,,,,compare,cnn is like markov random field except that it has even better representation power for natural image denoising.,cnn,markov random field,no
335,160017440.0,we also propose tractable and efficient mechanisms to train fair classifiers while satisfying this practical consideration. experiments with synthetic and real-world datasets show the effectiveness of our mechanism in enforcing this consideration.,{'fair classifier'},0.0,,,,,
336,5732972.0,"in 1976, fredman 14] came close to resolving this by showing that c(p) 2n + log e(p), and in 1984 kahn and saks 19] showed that c(p) log e(p)= log(11=8) ' 2:1766 log e(p).",{'fredman'},0.0,,,,,
337,5732972.0,"2=3 conjecture apparently originated in a 1968 paper of kislitsyn 22] , in a russian journal. it was also formulated independently by fredman in about 1975, and again by linial 24] in 1984.",{'fredman'},0.0,,,,,
338,405662.0,"faithfulness and markedness play roles analogous to the channel and language models of a noisy-channel system. we show that markedness features improve reconstruction, and can be used efficiently.",{'language model'},0.0,,,,,
339,9840000.0,"in this paper, we study the strongly cancellative sets c l and recovering sets r l that are subsets of points in lattices l, see definition 2.1 and 2.2. on one hand, the study of the former set is motivated by the work of ahlswede, frankl, and fredi [8] and fredman [7] .",{'fredman'},0.0,,,,,
340,3034962.0,"in scrfs [28, 41] , feature functions are defined over segments of observed variables (in our case, any number of consecutive video frames) and their corresponding labels (in our case, letters). the use of such segmental feature functions is useful for gesture modeling, where it is natural to consider the trajectory of some measurement or the statistics of an entire segment.",{'scrfs'},1.0,is-a,scrf is a method in which feature functions are defined over segments of observed variables and their corresponding labels.,scrf,method,no
341,3034962.0,"in natural language processing, semi-markov crfs have been used for named entity recognition [28] , where the labeling is binary. such models have been applied more widely in speech recognition [41] .",{'name entity recognition'},1.0,is-a,named entity recognition is a task in natural language processing where the labeling is binary. ,named entity recognition,task,no
342,43646282.0,"in order to automatically extract the features from the opinions, the approach is based on the processing of textual resources, on the information extraction and on the evaluation of a semantic orientation. more in details, it performs a syntactic analysis, a semantic disambiguation and a contextualization phase and takes into account the meaning express in conversations.",{'semantic orientation'},0.0,,,,,
343,125394.0,"ring oscillator-based physical unclonable function (ro puf) is a potential option to protect the security of sensor nodes because it is able to generate random responses efficiently for a key extraction mechanism, which prevents the non-volatile memory from storing secret keys. in order to deploy ro puf in a wsn, hardware efficiency, randomness, uniqueness, and reliability should be taken into account.",{'ro puf'},1.0,is-a,"ro puf is a potential option to protect the security of sensor nodes because it is able to generate random responses efficiently for a key extraction mechanism, which prevents the non-volatile memory from storing secret keys.",ro puf,potential option to protect the security of sensor nodes,no
344,125394.0,"besides, the resistance to electromagnetic (em) analysis attack is important to guarantee the security of ro puf itself. in this paper, we propose a novel architecture of configurable ro puf based on exclusive-or (xor) gates.",{'configurable ro puf'},1.0,based-on,configurable ro puf is a novel architecture based on exclusive-or (xor) gates.,configurable ro puf,exclusive-or (xor) gates,no
345,38149525.0,"examples of open systems in organisational setting include teleconferencing, lotus notes, intranet, internet. most of the studies that examined open systems did so in mandatory use organisational setting where users are constantly urged to use the system and standardisation between use cases are considered and required by the organisation (bhattacherjee, 1998;",{'bhattacherjee'},0.0,,,,,
346,15328536.0,"interest in the problem increased notably with the publication of the traveling tournament problem (ttp) (easton et al. 2001) , which addresses the design of a schedule to minimize the distances that teams in a sports league must travel.",{'travel tournament problem'},1.0,is-a,traveling tournament problem is a problem which involves the design of a schedule to minimize the distances that teams in a sports league must travel.,traveling tournament problem,problem,no
347,55321840.0,"in addition, they proved that the corrupted-pixel-identification (cpi) algorithm generally out-performs the well established median and sigma filters in noise removal capability and feature preserving ability for white or black impulse and gaussian noise9. however, when both salt (white) and pepper (black) noise are present in the image, the original cpi algorithm fails to perform as in other cases.",{'sigma filter'},0.0,,,,,
348,55321840.0,"the evaluation will be focused on the removal of the salt-and-pepper impulse noise, salt-and-pepper gaussian noise, gray impulse noise and the iterative applications of the modified cpi algorithms. comparisons are made between the original cpi algorithm, modified cpi algorithm, median filter, sigma filter and averaging filter in terms of their mean-square-error (mse), and their visual qualities are also presented.",{'sigma filter'},0.0,,,,,
349,5146446.0,"the canny method, sobel and prewitt filters, and the roberts' cross technique are some examples of edge detection algorithms that are widely used in image processing and machine vision. in this work, these algorithms are implemented using the compute unified device architecture (cuda), open source computer vision (opencv), and matrix laboratory (matlab) platforms.",{'prewitt'},0.0,,,,,
350,5146446.0,"[6] the gpu is now considered a general-purpose platform and is easily programmable. hence, some open-source libraries such as openvidia [7] are now available for improving the gpu-based algorithms.",{'openvidia'},1.0,is-a,openvidia is an open-source library used for improving the gpu-based algorithms.,openvidia,open-source library,no
351,86648117.0,"in this study, we have proposed, designed, and implemented a customizable personalized pain study platform that offers real-time data collection, research participant management, role-based access control, research data anonymization etc. it is also used to investigate pain level detection accuracy using evidence-based continuous learning from the facial expression data, collected from bangladesh, nepal and usa, which yielded about 71% classification accuracy.",{'role - base access control'},0.0,,,,,
352,86648117.0,"it has most of the common software research modules that are needed for a pain research study. these include real-time data collection, research participant management, role-based access control, research data anonymization etc.",{'role - base access control'},1.0,is-a,role-based access control is a common software research module needed for a pain research study.,role-based access control,common software research module,no
353,86648117.0,,,,compare,role-based access control is like real-time data collection in that they are both common software research modules needed for a pain research study.,role-based access control,real-time data collection,no
354,86648117.0,,,,compare,role-based access control is like research participant management in that they are both common software research modules needed for a pain research study.,role-based access control,research participant management,no
355,86648117.0,,,,compare,role-based access control is like research data anonymization in that they are both common software research modules needed for a pain research study.,role-based access control,research data anonymization,no
356,86648117.0,"pain detection and personalization is presented in section iv. the evaluation of the tool, results and platform implementation are presented in section v and vi.",{'pain detection'},0.0,,,,,
357,16611044.0,"from then on, several other projects have adopted a similar approach for task-parallel general-purpose applications (e.g., ompss and its instances cellss [12] , smpss [6] and gpuss [13] ; starpu",{'starpu'},0.0,,,,,
358,16611044.0,"furthermore, in order to build this graph, dague includes a specific language to express how the flow of data circulates between kernels. finally, a portable but not scalable approach is investigated in [25] using supermatrix and libflame to execute dense linear algebra algorithms directly on (small scale) message-passing environments.",{'dague'},1.0,used-for,dague is used to build graphs by including a specific language to express how the flow of data circulates between kernels.,dague,build graphs,no
359,8019028.0,"a phrase-based text representation for web document an augment was also proposed in data mining techniques have been used for text analysis by extracting co occurring terms as descriptive phrases from document collections. however, the effectiveness of the text mining systems using phrases as text representation showed no significant improvement.",{'phrase - base text representation'},0.0,,,,,
360,5329393.0,"after clustering is applied, the most fundamental analysis is to quantitatively compare clusterings. such comparisons are crucial for the evaluation of clustering methods as well as other tasks such as consensus clustering.",{'consensus clustering'},1.0,compare,consensus clustering is like quantitatively comparing clusterings in that they are both tasks used for the evaluation of clustering methods.,consensus clustering,quantitatively comparing clusterings,no
361,5329393.0,,,,is-a,consensus clustering is a task used for the evaluation of clustering methods.,consensus clustering,task used for the evaluation of clustering methods,no
362,5329393.0,"this is particularly common in the field of complex networks in which clustering similarity measures are used to justify the performance of community detection methods (danon et al., 2005; lancichinetti and fortunato, 2009) . as quantitative comparison is a fundamental operation, it plays a key role in many other tasks.",{'community detection method'},0.0,,,,,
363,195874272.0,"such models can be useful for simulation, controller design or diagnosis purposes. recently, progress towards system identification techniques for hybrid systems based on the classical methods presented e.g. in the book of ljung [20] has been made, see [38] and the references therein.",{'ljung'},0.0,,,,,
364,202718986.0,"one key aspect in this is the efficient dense image matching and depth estimation. here, the semi-global matching (sgm) approach has proven to be one of the most widely used algorithms for efficient depth estimation, providing a good trade-off between accuracy and computational complexity.",{'sgm'},1.0,is-a,"sgm is an approach that has proven to be one of the most widely used algorithms for efficient depth estimation, providing a good trade-off between accuracy and computational complexity.",sgm,approach,no
365,202718986.0,"the use of dynamic programming to approximate the energy minimization, by independently aggregating along numerous concentric one-dimensional paths, provides a good trade-off between accuracy and computational complexity. thus, sgm is still one of the most widely used algorithms for efficient imagebased depth estimation from both two-view and multiple-view setups.",{'sgm'},1.0,is-a,sgm is a widely used algorithm for efficient imagebased depth estimation from both two-view and multiple-view setups.,sgm,widely used algorithm,no
366,202718986.0,"we specifically focus on the use of non-fronto-parallel smoothness assumptions allowing for slanted surface reconstruction. in section 3, we give a detailed overview on our methodology, focusing on our adaptation of sgm to be used with multi-image matching for dense depth estimation from oblique aerial imagery, together with the estimation of surface normals and confidence measures.",{'sgm'},0.0,,,,,
367,202718986.0,"(hirschmueller, , 2008 has evolved to a suitable and widely used approach. the accuracy achieved with respect to the computation time needed makes sgm very appealing for both offline and online processing.",{'sgm'},1.0,is-a,sgm is a widely used approach due to the accuracy achieved with respect to the computation time for both offline and online processing.,sgm,widely used approach,no
368,202718986.0,"(2014) as well as gehrig and rabe (2010) show that, when using a fixed stereo setup, sgm can be optimized to run at 16 fps and 14 fps, respectively, on a conventional desktop cpu when utilizing simd instructions and using input images at vga resolution. the most common optimization strategy for the sgm algorithm, however, is to utilize the massively parallel computation infrastructure of modern gpus, achieving real-time frame rates (banz et al., 2011 ).",{'sgm'},0.0,,,,,
369,22321923.0,"attribute grammars are effective for defining the individual phases of language translators and interactive editing environments. schulz's attributed transformations [schulz 1976 ], attribute coupled grammars [ganzinger and giegerich 1984; ganzinger et al. 1986 ], the specification language ssl of the synthesizer generator [reps and teitelbaum 1989 ], higher order attribute grammars [vogt et al.",{'high order attribute grammar'},0.0,,,,,
370,6561482.0,"it can therefore be employed in a wide variety of machine learning problems (clustering, classification, retrieval, segmentation, attention, saliency, labelling, etc.), and can be applied to a wide range of signal types (images, video, audio, biological data, etc.) we show a few such examples.",{'saliency'},1.0,type-of,saliency is a type of machine learning problem.,saliency,machine learning problem,no
371,6561482.0,,,,compare,saliency is like clustering in that they are both machine learning problems.,saliency,clustering,no
372,6561482.0,,,,compare,saliency is like classification in that they are both machine learning problems.,saliency,classification,no
373,6561482.0,,,,compare,saliency is like retrieval in that they are both machine learning problems.,saliency,retrieval,no
374,6561482.0,,,,compare,saliency is like segmentation in that they are both machine learning problems.,saliency,segmentation,no
375,6561482.0,,,,compare,saliency is like attention in that they are both machine learning problems.,saliency,attention,no
376,6561482.0,,,,compare,saliency is like labelling in that they are both machine learning problems.,saliency,labelling,no
377,6561482.0,"what is it that makes those two images more similar than image-c? standard global image-based similarity measures (e.g., mutual information [12] , correlation, ssd, etc.) require prior alignment or prior knowledge of dense correspondences between signals, and are therefore not applicable here.",{'ssd'},1.0,is-a,ssd is a standard global image-based similarity measure which requires prior alignment or prior knowledge of dense correspondences between signals.,ssd,standard global image-based similarity measure,no
378,6561482.0,,,,compare,ssd is like mutual information in that they are both standard global image-based similarity measures which require prior alignment or prior knowledge of dense correspondences between signals.,ssd,mutual information,no
379,6561482.0,,,,compare,ssd is like correlation in that they are both standard global image-based similarity measures which require prior alignment or prior knowledge of dense correspondences between signals.,ssd,correlation,no
380,1499959.0,we then perform an analysis on obtained curves by extracting features points. we have tested our benchmark application on several architectures to highlight architecture parameters and components that influence algorithms performances.,{'architecture parameter'},0.0,,,,,
381,55363875.0,"the key feature in mr image reconstruction is the use of prior information about the signal through the compressibility or sparse representation under an appropriate sparsifying transform such as the wavelet transform and finite-differencing (lustig et al., 2008) . signal reconstruction by taking the sparsity into account is therefore of great interest.",{'mr image reconstruction'},1.0,is-a,mr image reconstruction is a method which uses prior information about the signal through the compressibility or sparse representation under an appropriate sparsifying transform such as the wavelet transform and finite-differencing.,mr image reconstruction,method,no
382,55363875.0,"we propose an adaptive alternating direction method of multipliers, hereinafter aadmm, to solve the non-convex and mixed integer programming problem directly. a matching pursuit procedure and an alternating direction method of multipliers are combined to develop a computationally efficient algorithm to solve the optimization problem.",{'alternate direction method'},0.0,,,,,
383,211077567.0,"however, it is less accurate for coherent sound sources at low frequencies. to improve the reconstruction accuracy of conventional esm and wbh, a sound source identification algorithm based on bayesian compressive sensing (bcs) and esm is proposed.",{'bayesian compressive sensing'},1.0,is-a,bayesian compressive sensing is a technique used in sound source identification algorithms.,bayesian compressive sensing,technique,no
384,211077567.0,"[15] combined the sparsity and cs theory with nah to identify the sound source with fewer microphones. since the assumption of cs technology is the sparsity of the signal, the cs-based nah can reconstruct high-resolution sound sources with less measured values.",{'cs theory'},0.0,,,,,
385,211077567.0,"n. chu et al. [16] combined aeroacoustic imaging with bayesian compressive sensing (bcs) and made a comparison with the conventional beamforming method, such as damas, clean, etc., showing that the bayesian method has a wider dynamic display range and it is more robust.",{'bayesian compressive sensing'},1.0,compare,bayesian compressive sensing is like damas except that it has a wider dynamic display range and it is more robust.,bayesian compressive sensing,damas,no
386,211077567.0,,,,compare,bayesian compressive sensing is like clean except that it has a wider dynamic display range and it is more robust.,bayesian compressive sensing,clean,no
387,14827805.0,"a cappella [7] enables us to define user actions easily, and gt2k [9] , artoolkit [11] , and dart",{'dart'},0.0,,,,,
388,11174139.0,"the later sentences in the discourse contain references to the entities in the preceding sentences, and this fact is often useful, e.g., in caching for language modeling (goodman, 2001) . the indirect influence of the context, however, can be observed even when a sentence is taken as a stand-alone unit, i.e., without its context.",{'language modeling'},0.0,,,,,
389,11174139.0,"yet it is wellknown that for interpreting the sentences the discourse context is often very important. the later sentences in the discourse contain references to the entities in the preceding sentences, and this fact is often useful, e.g., in caching for language modeling (goodman, 2001) .",{'language modeling'},0.0,,,,,
390,981633.0,"no acknowledgment is sent back in order to minimize the delay time of sending out the data burst at the source. after an offset time, the node sends out the data burst following the same routing path of the control packet.",{'offset time'},0.0,,,,,
391,981633.0,"although sophisticated channel reservation schemes such as the last available unused channel with void filling (lauc-vf) [5] scheme are more bandwidth efficient, and in principle can reuse all the idle transmission capacity in the time interval of t off , the system throughput will still degrade significantly if t cp is large. to eliminate the negative impact of control overhead, one may delay the data bursts at the inputs of intermediate nodes to compensate the control packet processing time but fiber delay lines (fdls) are required [2] , [3] .",{'void filling'},0.0,,,,,
392,981633.0,"the obs with horizon [3] and jit [4] channel reservation schemes are not included because these two schemes do not reuse the transmission bandwidth in the time interval of t off between the data burst and control packet. it is therefore not surprising that their throughput performance decreases when t cp increases, i.e., t off increases.",{'burst control packet'},0.0,,,,,
393,4717645.0,abstract. we present a deep model that can accurately produce dense depth maps given an rgb image with known depth at a very sparse set of pixels.,{'deep model'},0.0,,,,,
394,4717645.0,"the model works simultaneously for both indoor/outdoor scenes and produces state-of-the-art dense depth maps at nearly realtime speeds on both the nyuv2 and kitti datasets. we surpass the state-of-the-art for monocular depth estimation even with depth values for only 1 out of every  10000 image pixels, and we outperform other sparse-to-dense depth methods at all sparsity levels.",{'monocular depth estimation'},0.0,,,,,
395,4717645.0,"a regular grid of sparse depth may come from a lower-power depth sensor, while certain interest point sparse patterns such as orb [27] or sift [21] could be output from modern slam systems [23] . in the main body of this work, we will focus on regular grid patterns due to their ease of interpretation and immediate relevance to existing depth sensor hardware, although we detail experiments on orb sparse patterns in the supplementary materials.",{'orb'},1.0,type-of,orb is a type of sparse pattern that can be output from modern slam systems.,orb,sparse pattern,no
396,4717645.0,"such advances have spurred a flurry of research into deep methods for depth estimation, whether through fusing crfs with deep nets [37] , leveraging geometry and stereo consistency [5, 16] , or exploring novel deep architectures [17] . depth in computer vision is often used as a component for performing other perception tasks.",{'deep net'},0.0,,,,,
397,4717645.0,"other multitask vision networks [3, 12, 34 ] also commonly use depth as a complementary output to benefit overall network performance. using depth as an explicit input is also common in computer vision, with plentiful applications in tracking [30, 33] , slam systems [13, 36] and 3d reconstruction/detection [7, 19] .",{'slam system'},1.0,is-a,slam system is an application in computer vision which uses depth as an explicit input.,slam system,application in computer vision,no
398,4717645.0,,,,compare,slam system is like tracking in that they are both applications in computer vision which use depth as an explicit input.,slam system,tracking,no
399,4717645.0,,,,compare,slam system is like 3d reconstruction/detection in that they are both applications in computer vision which use depth as an explicit input.,slam system,3d reconstruction/detection,no
400,34064526.0,"these works all achieve a considerable accuracy in flock detection [6] , behavior analysis [7] , and group monitoring [8] with the help of spatio-temporal techniques. it seems reasonable to do the spatial clustering before forming the temporal sequences, but it also ignores some valuable characters in temporal-spatial methods.",{'flock detection'},0.0,,,,,
401,34064526.0,"their successive works proposed an average accuracy of flock detection up to 85%, which made an impressive effect on real-world implementations. in the following works [8] , [12] , [13] , researchers added more collaborative context information into the grouping problem, and tackled locating, navigating and monitoring scenarios.",{'flock detection'},0.0,,,,,
402,4805588.0,"the derivation of visual features from empirical data provides an important step in elucidating the nature and the specific content of face representations. further, the integrative character of this work sheds new light on the existing concept of face space by rendering it instrumental in image reconstruction.",{'face representation'},0.0,,,,,
403,15225933.0,"bug tracking and source control systems only record the symptoms (e.g., bug reports) and treatments of a bug (e.g., committed changes that fix the bug), but not its root cause. many treatments contain non-essential changes, which are intermingled with root causes.",{'non - essential change'},0.0,,,,,
404,15225933.0,"for example, when a program fails with a ""division by zero"" exception, it does not tell where the zero comes from; a debugger may need to back track the data flow to find the source of the zero. secondly, treatments of a bug (i.e., changes made to fix the bug) may often contain not only treatments for bugs but also non-essential changes (e.g., code reformatting, code refactoring, etc.)",{'non - essential change'},1.0,type-of,"non-essential changes are a type of change made to fix a programming bug, such as code reformatting and code refactoring.",non-essential changes,change,no
405,15225933.0,"their studies mostly focus on faulty versions and all lines changed or deleted (ignoring comment, blank line, and format changes) are implicitly assume to be root causes, which may not be always true. to the best of our knowledge, diffcat proposed by kawrykow and robillard [25] , which flags non-essential changes, may be the work having the closest goal as ours.",{'non - essential change'},0.0,,,,,
406,15225933.0,"in section ii, we present a motivating example. in section iii, we describe some preliminary materials on non-essential changes, and further elaborate the difference of root causes and their treatments.",{'non - essential change'},0.0,,,,,
407,15225933.0,"figure 1 shows an example illustrating the need of root cause identification. it is adapted, for the purpose of presentation in this paper, from a real bug in aspectj from ibugs repository [13] .",{'aspectj'},0.0,,,,,
408,14532392.0,(2013) . gl filter of circular harmonic wavelets are used to extract the features from infrared images.,{'circular harmonic wavelet'},0.0,,,,,
409,14532392.0,"two approaches, color normalization and local binary pattern are used to extract facial features. a novel facial expression recognition system in video sequences based on hough forest algorithm is described in chi-ting et al.",{'local binary pattern'},1.0,is-a,local binary pattern is an approach used to extract facial features.,local binary pattern,approach,no
410,14532392.0,,,,compare,local binary pattern is like color normalization in that they are both approaches used to extract facial features.,local binary pattern,color normalization,no
411,15269942.0,"another example is recursive feature elimination (rfe) which recursively removes genes with smallest ranking criterion, evaluates the resulted nested subsets and optimizes the subset for a given classifi er. such kinds of multivariate methods can remove both irrelevant and redundant genes when searching for an optimal minimum subset of genes for a good classifi er.",{'recursive feature elimination'},1.0,is-a,"recursive feature elimination is a multivariate method which recursively removes genes with smallest ranking criterion, evaluates the resulted nested subsets and optimizes the subset for a given classifier.",recursive feature elimination,multivariate method,no
412,,,,,used-for,recursive feature elimination is used to remove both irrelevant and redundant genes when searching for an optimal minimum subset of genes for a good classifier.,recursive feature elimination,remove both irrelevant and redundant genes when searching for an optimal minimum subset of genes for a good classifier,no
413,15269942.0,"since the within-class variance matrix in flda is singular when p  n -k, we propose a second gene selection method ""algorithm 2"" in such cases by introducing diana (divisive analysis) clustering algorithm (kaufman and rousseeuw, 1990) with (1-pearson correlation) as the distance measure. datta and datta (2003)",{'divisive analysis'},0.0,,,,,
414,43527733.0,"in multisequence alignment based tools, karect depicts excellent error correction rate whereas coral shows better execution time for all data sets. in hybrid based tools, jabba shows better error correction rate and execution time as compared to brownie.",{'karect'},1.0,is-a,karect is a technique used in multisequence alignment based tools which depicts excellent error correction rate.,karect,technique,no
415,43527733.0,,,,compare,karect is like coral in that they are both techniques used in multisequence alignment based tools.,karect,coral,no
416,43527733.0,"[7] hammer (2011), musket (2013), hector (2014) and racer (2013). these tools correct the errors on k-mer incidence.",{'musket'},1.0,is-a,musket is a tool which corrects the errors on k-mer incidence.,musket,tool,no
417,43527733.0,,,,compare,musket is like hammer in that they are both tools which correct the errors on k-mer incidence.,musket,hammer,no
418,43527733.0,,,,compare,musket is like hector in that they are both tools which correct the errors on k-mer incidence.,musket,hector,no
419,43527733.0,,,,compare,musket is like racer in that they are both tools which correct the errors on k-mer incidence.,musket,racer,no
420,43527733.0,"musket and racer are selected from the k-spectrum based category, coral and karect are selected from the multiple sequence alignment categories, and jabba and brownie are selected from the hybrid based category. these tools run on two different computing platforms.","{'musket', 'karect'}",0.0,,,,,
421,43527733.0,"the authors argued that lordec consumes less memory as compared to other tools and error correction rate is 99%. in fiona, used partial suffix array with hierarchical statically method to correct errors in sequencing reads.",{'lordec'},0.0,,,,,
422,15224188.0,"in order to reflect about these problems and to give a possible solution in a real case scenario, we will use a case study familiar in europe: the europeana collection 17 , i.e., the european digital library, a distributed access point to europe's multilingual cultural heritage in a digital form, containing an aggregated form of the content of several dozens of the main digital collections of digital heritage resources. in this paper, we describe some features of europeana and analyse the query results of the current implementation, proposing some reflections on the project in the current phase (section 2).",{'distribute access point'},0.0,,,,,
423,50338.0,"though broadband wireless access technology local multipoint distribution service (lmds) already exists at 28 ghz, it is still unused. this band has been considered as a potential candidate for 5g cellular frequency due to its low atmospheric absorption, and availability of high gain adaptive antennas [3] - [6] .",{'28 ghz'},0.0,,,,,
424,2783386.0,"stasis uses short vectors, looks at word-form rather than lemmata and includes function words, which are normally discarded by other measures. word similarities are computed using an edge-counting measure in a taxonomy and it makes use of word position.",{'word similarity'},1.0,is-a,word similarity is a parameter computed using an edge-counting measure in a taxonomy and it makes use of word position.,word similarity,parameter,no
425,17803220.0,"landay [8] integrated crosspad 1 with notepals but the system requires synchronization to upload notes. in addition, crosspad is not the best system for daily use in current japanese classrooms because of its size and weight.",{'notepal'},0.0,,,,,
426,38711627.0,"this paper presents a distributed cache replacement method based on tile sequence with spatiotemporal feature in access pattern. the method builds a lru stack to storage current hot tiles and their popularities based on the sequential feature when tiles are accessed, then structures tile sequence which embodies both temporal and spatial locality in hot-tile access; moreover, chooses a right tile sequence to be replaced.",{'spatiotemporal feature'},0.0,,,,,
427,8285853.0,"abstract-the information-theoretic capacity of multiple antenna systems was shown to be significantly higher than that of single antenna systems in rayleigh-fading channels. in an attempt to realize this capacity, foschini proposed the layered space-time architecture.",{'layer space - time architecture'},1.0,is-a,layered space-time architecture is a method proposed to realize the information-theoretic capacity of multiple antenna systems.,layered space-time architecture,method,no
428,10169638.0,"these algorithms have many applications in various fields such as genetics (pritchard et al., 2000) , image analysis (fei-fei and perona, 2005; russell et al., 2006; barnard et al., 2003) , survey data processing (erosheva et al., 2007) and social media analysis (airoldi et al., 2007) . most current topic modelling methods are based on the well-known 'bag-of-words' representation; in this approach, a document is represented simply as a bag of words, where words counts are preserved but their order in the original document is ignored.",{'perona'},0.0,,,,,
429,10169638.0,"at the heart of lda-gn is what we call a 'gibbs-newton' (gn) approach for learning the hyper-parameters of a multivariate polya distribution. within lda-gn, the role of gn is to learn the parameters for what amounts to the combination of two distinct multivariate polya distributed data streams that are assumed in the lda model.",{'lda model'},0.0,,,,,
430,57487772.0,"chaos theory is applied in pso algorithm to improve the diversity of the population and particle traversal search, which can effectively improve the pso algorithm convergence speed and accuracy., and svm mode is optimized. through a specific example, its results demonstrate that the chaos pso has a good high efficiency and higher accuracy than the traditional pso applied in svm classifier.",{'pso algorithm'},1.0,is-a,"pso algorithm is method which applies chaos theory to improve the diversity of the population and particle traversal search, which can effectively improve the pso algorithm convergence speed and accuracy.",pso algorithm,method,no
431,67750685.0,we prove that our abstract solution generalises over paxos as well as the fast paxos and flexible paxos algorithms. the surprising result of this analysis is a substantial weakening to the quorum requirements of these widely studied algorithms.,"{'fast paxos', 'paxos'}",0.0,,,,,
432,67750685.0,"furthermore, paxos is usually implemented in the form of multi-paxos, which establishes one participant as the master, introducing a performance bottleneck and increasing latency as all decisions are forwarded via the master. given these limitations, many production systems often opt to sacrifice strong consistency guarantees in favour of performance and high availability [7, 3, 18] .",{'paxos'},0.0,,,,,
433,67750685.0,"whilst compromise is inevitable in practical distributed systems [10] , paxos offers just one point in the space of possible trade-offs. in response, this paper aims to improve performance by offering a generalised solution allowing engineers the flexibility to choose their own trade-offs according to the needs of their particular application and deployment environment.",{'paxos'},0.0,,,,,
434,1986779.0,"for example, pamas [21] presents a mac protocol that conserves energy by turning off radios overhearing cross traffic. an adaptive fidelity energy-conservation algorithm (afeca) that gives a trade off between energy dissipation and data delivery quality according to application requirements is presented in [26] .",{'afeca'},1.0,is-a,afeca is a method that gives a trade off between energy dissipation and data delivery quality according to application requirements.,afeca,method,no
435,16988454.0,"later, mimno et al. compared several language models and proposed author-persona-topic model [19] .",{'language model'},0.0,,,,,
436,14668239.0,"the model assumes that learning of internal (hidden) generative models, which can predict the future and evaluate the precision of that prediction, is of central importance for information extraction. furthermore, the model makes a bridge to goal-oriented systems and builds upon the structural similarity between the architecture of a robust controller and that of the hippocampal entorhinal loop.",{'structural similarity'},0.0,,,,,
437,14668239.0,"connections to reinforcement learning are also established: both the control network, and the network with a hidden model converge to (near) optimal policy under suitable conditions. falsifying predictions, including the role of the feedback connections between neocortical areas are made.",{'reinforcement learning'},0.0,,,,,
438,204106466.0,"in wrapper approaches, using a classification algorithm to assess the candidate channel subsets generated by a search algorithm [11] . for instance, feature selection combined with classification algorithms such as svm classifiers [18] .",{'wrapper approach'},0.0,,,,,
439,9520021.0,"moreover, the implementation of the improved translucent volume rendering method (itvrm) integrating the ivrom model, shearwarp and preintegrated volume rendering algorithm is described, in which the aliasing and staircase effects resulting from undersampling in shear-warp, are avoided by the preintegrated volume rendering technique. this study demonstrates the superiority of the proposed method.",{'shear - warp'},0.0,,,,,
440,1347207.0,the ctl* tableau of [8] builds upon a previous tableau for bundled full computation tree logic (bctl*) [7] .,{'ctl * tableau'},1.0,is-a,ctl* tableau is an extension of a previous tableau for bundled full computation tree logic.,ctl* tableau,extension of a previous tableau for bundled full computation tree logic,no
441,1347207.0,"in this paper we propose a rooted variant 2 of the tableau for bctl* in [7] . although, bctl* has some advantages over ctl* the primary reason we chose to implement a bctl* tableau is that the ctl* tableau of [8] is built from the much simpler bctl* tableau of [7] .",{'ctl * tableau'},0.0,,,,,
442,44182356.0,"this concept is a generalization of the concept of delone (r, r)-systems. in light of the developments in the local theory for crystals that occurred since 1976 and demands in chemistry and crystallography, we believe the local theory for t-bonded sets deserves to be developed to describe materials whose atomic structures is multi-regular ""microporous"" point set.",{'delone'},0.0,,,,,
443,8954251.0,"content-based filtering is the most common type of event filtering in publish/subscribe systems, resulting in a ""contentbased publish/subscribe system"". it views each event notification message as a set of attribute/value pairs, whose values may be examined according to subscriber-given conditions.",{'publish / subscribe system'},0.0,,,,,
444,166228387.0,recently subspace codes have been widely investigated by many authors and different approaches of constructing constant dimension codes have been considered. this paper deals with cdc and it is organized as follows.,{'constant dimension code'},0.0,,,,,
445,11341482.0,"according to our experience, even the 'package-specific-naming' solution may lead to different naming schemes if the atom names were dissimilar before the conversion, or if the ligands come from smiles representations. to avoid these difficulties in assigning equivalent interactions, docking assessments (michino et al., 2009 ) required modelers to submit data in a rigid protein data bank (pdb) template format with defined names and sequential positions of atoms.",{'smile representation'},0.0,,,,,
446,49557232.0,"abstract inductive wireless power transfer (ipt) is a promising technology for remote powering of a wide variety of applications of electronic devices. to design ipt systems with the highest power transfer efficiency and the maximal robustness to coupling factor variations between transmitter and receiver of printed spiral coils (pscs), high quality factors (q-factor) of the utilized pscs are required.",{'print spiral coil'},0.0,,,,,
447,9215048.0,"the simulator includes a simple web-browser interface for specifying and refining a target reaction network as well as visualization tools to represent the network's behavior. the simulator is verified as rapidly solving in seconds (with benchmarks relative to gepasi) some classic biological circuits like the lac operon and qa gene cluster as well as a new circuit, the repressilator, with oscillatory behavior.",{'gepasi'},0.0,,,,,
448,9215048.0,"like gepasi (mendes, 1997) , kinsolver is not constrained by the size of the reaction network and has a menu-based interface, but it differs in the kinds of numerical integration tools available and in having a web interface to give it platform independence. there are three features that separate kinsolver from most other simulators, its platform independence, flexibility in solution procedures, and its capability to simulate efficiently large (10 4 -10 5 ) ensembles of models.",{'gepasi'},1.0,is-a,gepasi is a simulator that is not constrained by the size of the reaction network and has a menu-based interface.,gepasi,simulator,no
449,9215048.0,,,,compare,gepasi is like kinsolver in that they are both simulators that are not constrained by the size of the reaction network and have a menu-based interface.,gepasi,kinsolver,no
450,9215048.0,"some important real examples are used to evaluate the solution procedures of the underlying coupled nonlinear differential equations relative to gepasi (mendes, 1997 ) with a particular focus on simulating model ensembles. the paper concludes with limitations of kinsolver and some needed extensions to the modeling approach, which kinsolver implements.",{'gepasi'},0.0,,,,,
451,86650132.0,"compared with the battery powered electric vehicles, fuel cell vehicles have great superiorities in energy efficiency, endurance mileage, charging speed and climate tolerance. the energy conversion efficiency of the fuel cell vehicle is not limited by carnot cycle, and its energy conversion efficiency can be as high as 60%~70%, which is nearly twice of the ordinary internal combustion engine.",{'energy conversion efficiency'},1.0,is-a,energy conversion efficiency is a measure of energy efficiency for fuel cell vehicles.,energy conversion efficiency,measure of energy efficiency,no
452,35320757.0,[1] and wyner-ziv (wz) [2] .,{'wyner - ziv'},0.0,,,,,
453,35320757.0,brites et al. [3] have stated that reducing the decoder complexity and improving the rd performance can be done by optimizing channel coding techniques and improving the quality of the si.,{'brite'},0.0,,,,,
454,35320757.0,the lanczos interpolation has been implemented for optimizing decomposition based on lossless compression of biomedical images [13] and segmentation of ultrasound breast phantom data [14] . the bicubic interpolation also has been applied for image zooming [15] .,{'bicubic interpolation'},1.0,used-for,bicubic interpolation is used for image zooming.,bicubic interpolation,image zooming,no
455,35320757.0,,,,compare,bicubic interpolation is like lanczos interpolation in that they are both used for image zooming.,bicubic interpolation,lanczos interpolation,no
456,52047968.0,"a variety of clustering algorithms based on moea are emerging [16] , [17] . mock [18] is a typical multiobjective evolutionary clustering algorithm, was proposed by handl and this method applies compactness and connectedness as two objective functions.",{'moea'},0.0,,,,,
457,52047968.0,mopso [21] uses connectivity and cohesion as two objective functions to find the best clustering result. msfca utilizes the global fuzzy compactness and fuzzy separation among the clusters as objective functions and gets the best clustering result in image segmentation [22] .,{'mopso'},1.0,is-a,mopso is a method that uses connectivity and cohesion as two objective functions to find the best clustering result.,mopso,method,no
458,52047968.0,"the first one is the global weight clustering coefficient and the second one is a combination of the classical knn and the minimal cut. however, this approach has the same memory usage problem than spectral clustering.",{'spectral clustering'},1.0,is-a,spectral clustering is an approach that has a memory usage problem.,spectral clustering,approach,no
459,52047968.0,"this paper has two contributions. the first is to combine various distance measures into a clustering algorithm, compactness is the only factor to be considered for objective function setting, we call it multiobjective evolutionary clustering based on combining multiple distance measures(moecdm).",{'evolutionary clustering'},0.0,,,,,
460,58981918.0,"the focus has been on increasing accuracy, in particular for image, speech, and recently text tasks, where deep convolutional neural networks (cnns) are applied. the resulting networks often include millions to billions parameters.",{'deep convolutional neural network'},0.0,,,,,
461,58981918.0,"it is known that dropout improves the test accuracy compared to standard regularizers such as l 1 (tibshirani, 1996) and l 2 (srivastava et al., 2014) . wager et al.",{'dropout'},1.0,compare,dropout is like l 1 except that it has improved test accuracy.,dropout,l 1,no
462,58981918.0,,,,compare,dropout is like l 2 except that it has improved test accuracy.,dropout,l 2,no
463,58981918.0,(2013) proved that dropout is equivalent to an l 2 -type regularizer applied after scaling the inputs. heuristic regularization is not limited to dropout only.,{'dropout'},0.0,,,,,
464,44083468.0,"similarly, bubble rap proposed in [20] combines the betweenness centrality in the ego network with social communities to increase the data forwarding performance in msns. gao et al.",{'bubble rap'},1.0,,bubble rap is a method that combines the betweenness centrality in the ego network with social communities to increase the data forwarding performance in msns.,bubble rap,method,no
465,67872076.0,"based on the construction of wind power-pumped storage combined generator set by using water resources, combined with the power generation of a thermal power unit, a scheduling strategy based on the dynamic kriging model for the integrated strategy of output planning and the economic operation of a wind power-pumped storage-thermal power combined system is proposed. the strategy uses the hypercube sampling method and the particle swarm optimization algorithm after improving the inertia weight to solve the model.",{'inertia weight'},0.0,,,,,
466,1929070.0,"if the measurement uncertainty follows a gaussian probability distribution and the features correspondence between frames is not available, iterative closest point (icp) algorithm can be used to find the translation and rotation between two different frames [1] . if there exists correspondence between different frames, least squares techniques with tools such as: singular value decomposition (svd) and unit quaternion, can be applied to estimate the rigid transformation by minimizing the distance between corresponding points [2] , [10] .","{'icp', 'iterative close point'}",1.0,used-for,icp is used to find the translation and rotation between two different frames when the measurement uncertainty follows a gaussian probability distribution and the features correspondence between frames is not available.,icp,find the translation and rotation between two different frames,no
467,1436159.0,"we map the descriptor vectors into the hamming space in which the hamming metric is used to compare the resulting representations. this way, we reduce the size of the descriptors by representing them as short binary strings and learn descriptor invariance from examples.",{'hamming space'},0.0,,,,,
468,1436159.0,"while helpful, this approach is usually not sufficient to produce truly short descriptors without loss of matching performance. another class [9] , [10] , [11] , [12] takes advantage of training data to learn short binary codes whose distances are small for positive training pairs and large for others.",{'short binary code'},0.0,,,,,
469,1436159.0,"this maps the data into a space of binary strings, greatly reducing their size on the one hand and simplifying their similarity computation (now becoming the hamming metric, which can be computed very efficiently on modern cpus) on the other. another class of locality-sensitive hashing (lsh) techniques and their variants [9] , [13] encode similarity of data points as the collision probability of their binary codes.",{'locality - sensitive hashing'},1.0,is-a,locality-sensitive hashing is a technique used to encode similarity of data points as the collision probability of their binary codes.,locality-sensitive hashing,technique,no
470,16610270.0,"depending on the sources availability and the platform needs, different services are published in and withdrawn from the platform service registry. they are then opportunistically used by the pervasive applications, coded in ipojo.",{'ipojo'},0.0,,,,,
471,9807808.0,in section 3 we demonstrate how units can assist in identifying spreadsheet errors. the header inference framework and the individual spatial-analysis algorithms are described in section 4.,{'spreadsheet error'},0.0,,,,,
472,26259894.0,"given only a total energy reading, such as that collected from a residential meter, energy disaggregation strives to discover the consumption of individual appliances. existing disaggregation algorithms are computationally inefficient and rely heavily on high-resolution ground truth data.",{'energy disaggregation'},1.0,used-for,"energy disaggregation is used to discover the consumption of individual appliances given only a total energy reading, such as that collected from a residential meter.",energy disaggregation,discover the consumption of individual appliances,no
473,26259894.0,"existing disaggregation algorithms are computationally inefficient and rely heavily on high-resolution ground truth data. we introduce a probabilistic framework which infers the energy consumption of individual appliances using a hinge-loss markov random field (hl-mrf), which admits highly scalable inference.",{'hinge - loss markov random field'},0.0,,,,,
474,26259894.0,"smart meters offer a unique opportunity to gather real-time data, learn energy consumption patterns, and ultimately offer actionable insights to consumers. energy disaggregation (also referred to as non-intrusive load monitoring (nilm)) is the process of determining the energy consumption of individual appliances, given only an aggregated energy reading.","{'energy disaggregation', 'nilm'}",1.0,is-a,"energy disaggregation is a process of determining the energy consumption of individual appliances (also referred to as nilm), given only an aggregated energy reading.",energy disaggregation,process,yes
475,26259894.0,"to formulate the inference task we use a hinge-loss markov random field (hl-mrf) [bach et al., 2015] , which allows a flexible probabilistic formulation and admits efficient inference.",{'hinge - loss markov random field'},1.0,used-for,hinge-loss markov random field is used to formulate inference tasks.,hinge-loss markov random field,formulate inference tasks,no
476,26259894.0,,,,is-a,hinge-loss markov random field is an approach which allows a flexible probabilistic formulation and admits efficient inference.,hinge-loss markov random field,approach,no
477,1093643.0,"to avoid mistreating all unknown actors, they proposed the use of free but unreplaceable (once in a lifetime) pseudonyms, which a central authority certifies through blind signature. a couple of years later, doucer put similar ideas to test in p2p networks.",{'blind signature'},0.0,,,,,
478,1093643.0,"however, their approach suffers from ""sybil attacks"". they thus recently enhanced the original trust model so that trust updates internalize the costs of sybil attacks [17] .",{'sybil attack'},0.0,,,,,
479,53250547.0,an image-based visual servo (ibvs) was implemented in [8] to help locating the position of the targeted object. feature models are used in [9] to find the position of known targets.,{'image - base visual servo'},1.0,used-for,image-based visual servo is used to help locate the position of a targeted object.,image-based visual servo,help locate the position of a targeted object,no
480,28699619.0,"[5] use constrained bayesian optimization to tune dnn model hyper-parameters using improvement in terms of wer of the validation set with rtf as the constraint. [6] perform a scalarization of wer and real time factor (rtf) and perform a variation of co-ordinate descent to tune decoder hyper-parameters, but only deal with continuous hyper-parameters.",{'continuous hyper - parameter'},0.0,,,,,
481,15964245.0,"we apply techniques from asynchronous circuit design, based on signal transition graphs (stgs), to modelling, visualising and analysing grns. stgs are a petri net based model that has been extensively used in asynchronous circuit design.",{'signal transition graph'},0.0,,,,,
482,15964245.0,"in this paper, we make a case for using another formalism, viz. signal transition graphs (stgs) [5, 14] , which allows one to capture in a natural way the behaviour of both the circuit and its environment.",{'signal transition graph'},0.0,,,,,
483,9084554.0,"structural similarity has been recognized as a solid argument for evolutionary relationship between proteins 9,10 and hence, prediction of their function. success in protein structure prediction by fold recognition is limited by our ability to identify homologous protein with known three-dimensional structure.",{'structural similarity'},1.0,is-a,"structural similarity is a solid argument for evolutionary relationship between proteins 9,10 and hence, prediction of their function.",structural similarity,"solid argument for evolutionary relationship between proteins 9,10",no
484,201600643.0,many clustering algorithms have been developed for wsns. leach (low energy adaptive clustering hierarchy) [3] is a wellknown distributed clustering algorithm in which chs are selected with some probability and remaining nodes join the nearest ch without considering its residual energy.,{'leach'},1.0,is-a,leach is a wellknown distributed clustering algorithm in which chs are selected with some probability and remaining nodes join the nearest ch without considering its residual energy.,leach,wellknown distributed clustering algorithm,no
485,201600643.0,"however, heed introduces extra communication overhead to compute the communication cost with its neighbors by exchanging large number of messages. many other clustering algorithms have been proposed in the literature [5] - [14] .",{'heed'},1.0,is-a,heed is a clustering algorithm which introduces extra communication overhead to compute the communication cost with its neighbors by exchanging large number of messages.,heed,clustering algorithm,no
486,201600643.0,"however, the algorithm was experimented by assuming single hop communication between the chs and the sink similar to leach [3] . in the present version, we extend the work of bdcp by developing a new multi-hop routing algorithm.",{'leach'},0.0,,,,,
487,45404684.0,"zhang 2] proposed, for the rst time, an algorithm to compute structure and motion from two images using only straight segment matching as the input. he proposed to maximize the overlap in the image between the image segments and the corresponding reconstruction by using epipolar geometry, and as a result, reconstruction computation was not required.",{'epipolar geometry'},0.0,,,,,
488,13975279.0,"regulation is restricted to one enhancer site and one inhibitor site per gene, if several regulating proteins are present at a site they are combined in an or like fashion. bentley [8] invented fractal proteins, gene products that are comprised of subsets of the mandelbrot set.",{'fractal protein'},1.0,is-a,fractal protein is a gene product that is comprised of subsets of the mandelbrot set.,fractal protein,gene product,no
489,210350.0,"in this study, we applied this approach and measured the effect of thc administration on encoding and recall brain function in an fmri study. on the basis of neuropsychological findings, we tested the hypothesis that thc administration affects encoding, resulting in reduced encoding-related brain activity in a memory network including (para)hippocampal and prefrontal areas ( jager et al., 2007; henke, buck, weber, & wieser, 1997) .",{'memory network'},0.0,,,,,
490,13815160.0,"in comparison to reinforcement learning, a motivated learning (ml) agent has multiple value functions, sets its own objectives, solves the minimax problem, is stable, and acts when needed. in contrast, a reinforcement learning (rl) agent typically only has a single value function, relies only on externally set objectives, maximizes its reward (and is therefore unstable), and is always active.",{'reinforcement learning'},1.0,compare,"reinforcement learning is like motivated learning except that it only has a single value function, relies only on externally set objectives, maximizes its reward (and is therefore unstable), and is always active.",reinforcement learning,motivated learning,no
491,3034493.0,its principal aim is to find joint trajectories to allow for a humanoid robot to go from crouch to stand position while minimizing power consumption. q-learning (ql) is used to search for optimal joint paths subject to angular position and torque restrictions.,{'q - learning'},1.0,used-for,q-learning is used to search for optimal joint paths subject to angular position and torque restrictions.,q-learning,search for optimal joint paths subject to angular position and torque restrictions,no
492,51610890.0,"using these data, we created regression models to predict symptoms as measured by the tests and a feature selection analysis was performed. classification models were built to detect reliable absolute changes in the scores predicting symptoms and smoteboost and wracog algorithms were used to overcome class imbalance where needed.",{'smoteboost'},0.0,,,,,
493,10393962.0,"we note that tours having this property can be easily constructed. more generally, in [1, 7, 9] several n p-hard problems, such as max cut, max r -sat and atsp, were studied, and algorithms guaranteed to construct solutions whose quality is at least as good as the average quality of a random solution have been proved to be of large (i.e., bounded from 0, or even close to 1) dominance ratio.",{'max cut'},1.0,is-a,max cut is an n p-hard problem.,max cut,n p-hard problem,no
494,10393962.0,,,,compare,max cut is like max r -sat in that they are both n p-hard problems.,max cut,max r -sat,no
495,10393962.0,,,,compare,max cut is like atsp in that they are both n p-hard problems.,max cut,atsp,no
496,11520594.0,"in segmentation, we apply spectral subtraction to generate time-frequency segments in unvoiced intervals. unvoiced speech segments are subsequently grouped based on frequency characteristics of unvoiced speech using simple thresholding as well as bayesian classification.",{'spectral subtraction'},1.0,used-for,spectral subtraction is used to generate time-frequency segments in unvoiced intervals in segmentation.,spectral subtraction,generate time-frequency segments in unvoiced intervals,no
497,15591672.0,"unlike previous works for ner in the vietnamese language, we use an online learning algorithm, the margin infused relaxed algorithm (mira) (crammer and singer, 2003) , to train the crfs. furthermore, due to the fact that the number of labeled data is small while that of unlabeled data is very large, we treat this problem under the semisupervised learning framework.",{'ner'},0.0,,,,,
498,15591672.0,"one dominant approach for ner is supervised learning with conditional random fields (mccallum and li, 2003) . however, semisupervised learning approaches are also attractive for this task because it is expensive to get a large amount of labeled data.",{'ner'},0.0,,,,,
499,7691234.0,"its use will be contrasted with an application of z combined with predicative programming [6] -which has a built-in notion of timing. -space study: the z notation, extended with a simple notion of space, will be applied in specification, refinement, and proof of space constraints.",{'z notation'},0.0,,,,,
500,202774473.0,"in contrast, we pursue a weakly supervised approach where we leverage an image dataset with region captions that are used to simulate queries during training, thus bypassing the need to collect extra annotations. we demonstrate that training with simulated queries is surprisingly effective under human evaluations.",{'human evaluation'},1.0,used-for,human evaluations are used for training with simulated queries.,human evaluations,training with simulated queries,no
501,9574824.0,"we will discuss health information exchange (hie), which refers to various activities around the mobilization of healthcare information electronically across organizations [5] . data reported to healthcare agencies can be used for quality control and for policy optimization.",{'policy optimization'},0.0,,,,,
502,11501935.0,"existing studies focus on extending univariate stochastic dominance rules to the multivariate case. however, enforcing multivariate stochastic dominance constraints can often be overly conservative in practice.",{'multivariate stochastic dominance constraint'},0.0,,,,,
503,11501935.0,"the rest of the paper is organized as follows. in section 2 we review fundamental concepts related to cvar, ssd, and linear scalarization.",{'ssd'},0.0,,,,,
504,11501935.0,"then we define multivariate cvar relations, and present a general form of optimization problems involving such relations as constraints. section 3 contains theoretical results including optimization representations of cvar, and finite representations of polyhedral cvar and ssd constraints.",{'optimization representation'},0.0,,,,,
505,207930519.0,"egghe, rousseau, and van hooydonk (2000) and more recently osrio (2018) also address various credit systems. i use the notation from osrio (2018) , since osrio and bornmann (2019) assume equal credit to all authors on an article.",{'egghe'},1.0,compare,egghe is like rousseau in that they both address various credit systems.,egghe,rousseau,no
506,207930519.0,,,,compare,egghe is like van hooydonk (2000) in that they both address various credit systems.,egghe,van hooydonk (2000),no
507,207930519.0,,,,compare,egghe is like osrio (2018) in that they both address various credit systems.,egghe,osrio (2018),no
508,2654929.0,"recently, more and more different evolutionary techniques have been developed, especially hybrid evolutionary algorithms. this paper proposes an island based hybrid evolutionary algorithm (ihea) for optimization, which is based on particle swarm optimization (pso), fast evolutionary programming (fep), and estimation of distribution algorithm (eda).",{'fast evolutionary programming'},0.0,,,,,
509,2654929.0,"there is little reason to expect that one can find a uniformly optimal algorithm for solving all optimization problems. this is in accordance with the no free lunch theorem [1] , which explains that for any algorithm, any elevated performance over one class of problems is exactly paid for in performance over another class.",{'free lunch theorem'},0.0,,,,,
510,12033262.0,"the decoder architecture is based on four cordic (coordinate rotation digital computer) units. among these cordic units, three are used in rotation mode and the fourth one is used in vectoring mode.",{'cordic'},0.0,,,,,
511,28400149.0,"we demonstrated that bayesian optimization not only provides better, more efficient classification but is also much faster-the number of iterations it required for reaching optimal predictive performance was the lowest out of the all tested optimization methods. moreover, for the bayesian approach, the choice of parameters in subsequent iterations is directed and justified; therefore, the results obtained by using it are constantly improved and the range of hyperparameters tested provides the best overall performance of support vector machine.",{'bayesian optimization'},0.0,,,,,
512,28400149.0,"in cheminformatics applications, the most popular optimization strategies are grid search [1, 2] and heuristic choice [3, 4] . depending on the problem, they are able to provide high classification accuracy-for example wang et al. obtained 86% of accuracy in the classification of herg potassium channel inhibitors for the heuristic choice of the svm parameters [4] .",{'svm parameter'},0.0,,,,,
513,28400149.0,"[1] were able to evaluate the cytochrome p450 activities with 66-83% of accuracy using grid search method of svm parameters optimization. the need for optimizing svm parameters is undeniable, as classification efficiency can change dramatically for various parameters values.",{'svm parameter'},0.0,,,,,
514,28400149.0,"in recent years, bayesian optimization [5, 6] (including gaussian processes [7] ) and random search-based selection [8] have become more popular [9, 10] . as those approaches were not explored so far in the field of cheminformatics, we analyze their impact on classification accuracy and, more importantly, the speed and ease of use, that these approaches have lent to the optimization of svm hyperparameters in the search for bioactive compounds.",{'bayesian optimization'},0.0,,,,,
515,9289937.0,"in this analogy, minimal unsatisfiable formulas correspond to critically 3-chromatic hypergraphs. therefore it is natural to ask if similar results hold for both problems.",{'minimal unsatisfiable formula'},0.0,,,,,
516,9289937.0,"|v | if there is no isolated vertex. the corresponding bound for cnf formulas appeared in aharoni and linial [4] where they proved that minimal unsatisfiable formula f = (v, c) must satisfy |c|",{'minimal unsatisfiable formula'},0.0,,,,,
517,15432502.0,"we generalize their approach to learn a mapping from 2d poses (including joint angles and foreshortening information) to 3d poses. sampling from this model provides predicted 3d poses ( fig. 1 (d) ), that are appropriate as proposals for a bayesian temporal inference process ( fig. 1 (e) ).",{'2d pose'},0.0,,,,,
518,10857609.0,"however most of this work has been concentrated on english and other european languages. hence, building a named entity recognition (ner) system for south asian languages (sal) is still an open problem because they exhibit characteristics different from english.",{'name entity recognition'},0.0,,,,,
519,10857609.0,"with minimal supervision, they obtained overall f measures between 40 and 70, depending on the languages used. collins (1999) showed that use of unlabelled data for ner can reduce the requirements for supervision to just 7 simple seed rules.",{'ner'},0.0,,,,,
520,10857609.0,(2003) used hmm to create ner for hindi and cebuano. ekbal et al.,{'ner'},0.0,,,,,
521,6677131.0,el gamal in [4] showed that comthis publication was made possible by nprp grant # nprp 79232 344 from the qatar national research fund (a member of qatar foundations). the statements made herein are solely the responsibility of the authors.,{'el gamal'},0.0,,,,,
522,199489469.0,"the uav is also called drone, and thus the three terminologies, uav network, fanet, and drone ad hoc network, are interchangeably used. there are two types of uav networks, as shown in fig. 1 .",{'fanet'},0.0,,,,,
523,199489469.0,"in our work, we introduce a comprehensive survey of 21 topology-based routing protocols, 22 positionbased routing protocols, 5 cluster-based routing protocols, 6 different data forwarding-based routing protocols, and 6 field experiments of routing protocols in uav networks and fanets with their various categories. after discussing network architecture, various routing techniques, and taxonomy of routing protocols in uav networks, we compare the routing protocols qualitatively in terms of their major features, characteristics, and performance.",{'fanet'},0.0,,,,,
524,206930001.0,"like ontonav, the system is human centric considering human capabilities and preferences for navigation services. ontnav and mnisiklis, both semantically enriched indoor navigation systems have their fo cus on one type of locomotion i.e. human being.",{'ontonav'},1.0,is-a,ontonav is a system which is human centric considering human capabilities and preferences for navigation services. ,ontonav,system,no
525,206930001.0,,,,compare,ontnav is like mnisiklis in that they are both semantically enriched indoor navigation systems and have their focus on one type of locomotion i.e. human being.,ontonav,mnisiklis,no
526,17821028.0,"there are a large number of results in the graph theory literature of the form  +  n  , where  q, for a domination parameter . results of this form have previously been obtained for example for the domination number  ",{'domination number'},0.0,,,,,
527,57884.0,"results: we propose a first version of a newly constructed ontology, hupson, as a basis for shared semantics and interoperability of simulations, of models, of algorithms and of other resources in this domain. the ontology is based on the basic formal ontology, and adheres to the mireot principles; the constructed ontology has been evaluated via structural features, competency questions and use case scenarios.",{'basic formal ontology'},0.0,,,,,
528,57884.0,"demo formalizes information only related to discrete systems, kisao is limited in scope to kinetic models and algorithms, teddy deals with classification of dynamic features in simulation and sbo represents model components. there also exists the living human digital library (lhdl) domain ontology [11, 12] that serves as a foundation for coherent annotation of lhdl resources and their retrieval and traceability.",{'kisao'},1.0,is-a,kisao is an approach that is limited in scope to kinetic models and algorithms.,kisao,approach,no
529,57884.0,"the aim of semsim is to create semantic interoperability of biosimulation models by creating machine-readable definitions. while this is a valid approach to creating interoperability and the integration of resources, the problem remains that semantic information is spread among different external sources and an additional tool (e.g. semgen [14] , the ricordo toolkit [13] ) is needed.",{'biosimulation model'},0.0,,,,,
530,11345429.0,how long does it take to solve the elliptic curve discrete logarithm problem (ecdlp) on a given elliptic curve using given hardware? this question was addressed recently for the koblitz curve defined in the certicom challenge ecc2k-130 for a variety of hardware platforms [2] this paper zooms into section 6 of [2] and describes the implementation of the parallel pollard rho algorithm [19] for the synergistic processor elements of the cell broadband engine architecture (cbea) in detail.,{'ecc2k-130'},0.0,,,,,
531,2971325.0,"standard genetic operators are applied to these chromosomes to determine the fittest chromosome which is the one based on which a list scheduling heuristic is applied, the resulting assignment and sequencing gives the shortest schedule length for the original problem. the genetic search, therefore, operates on the problemspace instead of the solution-space as is commonly done.",{'list scheduling heuristic'},0.0,,,,,
532,14991466.0,"some pre-defined annotation databases, such as go (gene ontology), or pathway databases, such as kegg, or ppi (protein-protein interaction) databases, such as hprd (keshava prasad, et al., 2009 ) and intact (aranda, et al., 2010) can be used as a gold-standard description. some annotation tools that integrate these manually curated databases, such as david (huang da, et al., 2009 ) and egan (paquette and tokuyasu, 2010) provide convenient and practical application.",{'hprd'},1.0,type-of,hprd is a type of protein-protein interaction database.,hprd,protein-protein interaction database,no
533,515365.0,"our encoding is interesting for designers of eiffel-style interface specification languages and for researchers working on program verifiers for programs with eiffel-style specifications (for instance, boogie [1] , esc/java [11, 8] , krakatoa [16] , or jive). for concreteness, we present our work in terms of a subset of sequential java and jml.",{'esc / java'},1.0,is-a,esc/java is a program verifier for programs with eiffel-style specifications.,esc/java,program verifier,no
534,515365.0,,,,compare,esc/java is like boogie in that they are both program verifiers for programs with eiffel-style specifications.,esc/java,boogie,no
535,515365.0,,,,compare,esc/java is like krakatoa in that they are both program verifiers for programs with eiffel-style specifications.,esc/java,krakatoa,no
536,515365.0,,,,compare,esc/java is like jive in that they are both program verifiers for programs with eiffel-style specifications.,esc/java,jive,no
537,51869570.0,"in [5] , the impact of reflections on the physical layer security of mmwave systems are experimentally demonstrated. it shows that the eavesdropper can successfully eavesdrop even highly directional signal beams when small-scale reflectors are placed along the direction of the main beam.",{'mmwave system'},0.0,,,,,
538,190001673.0,"xu et al. (2015b,c) apply neural networks only on the shortest dependency path between the entities in the full tree.",{'short dependency path'},0.0,,,,,
539,190001673.0,zhang et al. (2018) apply graph convolutional networks (gcns),"{'gcns', 'graph convolutional network'}",0.0,,,,,
540,190001673.0,"figure 1 shows an example in cross-sentence n-ary relation extraction that the key tokens partial response would be excluded if the model only takes the pruned tree into consideration. ideally, the model should be able to learn how to maintain a balance between including and excluding information in the full tree.",{'cross - sentence n - ary relation extraction'},0.0,,,,,
541,190001673.0,the shortest dependency path between these entities is highlighted in bold (edges and tokens). the root node of the lca subtree of entities is present.,{'short dependency path'},0.0,,,,,
542,190001673.0,the contrast between our model and theirs is reminiscent of the contrast between cnn and rnn. various pruning strategies have also been proposed to distill the dependency information in order to further improve the performance.,{'cnn'},0.0,,,,,
543,190001673.0,"xu et al. (2015b,c) adapt neural models to encode the shortest dependency path.",{'short dependency path'},0.0,,,,,
544,190001673.0,(2015) combine the shortest dependency path and the dependency subtree. zhang et al.,{'short dependency path'},0.0,,,,,
545,190001673.0,"(2018) proposed graph attention networks (gats) to summarize neighborhood states by using masked selfattentional layers (vaswani et al., 2017) . compared to our work, their motivations and network structures are different.",{'gat'},1.0,used-for,gat is used to summarize neighborhood states by using masked selfattentional layers.,gat,summarize neighborhood states,no
546,190001673.0,"compared to our work, their motivations and network structures are different. in particular, each node only attends to its neighbors in gats whereas ag-gcns measure the relatedness among all nodes.",{'gat'},1.0,compare,gat is like ag-gcns except that each node only attends to its neighbors.,gat,ag-gcns,no
547,22688536.0,"here, scale is the number of systems to be developed and variety stems from a diversified range of instructional designs such as varied goals, processes, content, teaching styles, learning styles and, also for elearning systems for 22 indian languages and variants. in this paper, we present a family of software product lines as an approach to address this challenge of modeling a family of instructional designs as well as a family of elearning systems and demonstrate it for the case of adult literacy in india (287 million learners).",{'software product line'},1.0,used-for,software product line is used to address the challenge of modeling a family of instructional designs as well as a family of elearning systems and demonstrate it for the case of adult literacy in india (287 million learners).,software product line,address the challenge of modeling a family of instructional designs,no
548,22688536.0,a domain engineering activity for interactive learning modules and a product line for mobile learning applications are proposed in [57] and [58] . a software product line for m-learning focusing on programming is discussed in [59] and a software product line for games is presented in [60] .,{'software product line'},0.0,,,,,
549,27941462.0,"novel techniques in the field, use ultrasonic transducers and air vortex rings to create focused haptic feedback in mid-air (monnai et al. 2014; gupta et al. 2013 ).",{'air vortex ring'},1.0,used-for,air vortex ring is used to create focused haptic feedback in mid-air.,air vortex ring,create focused haptic feedback in mid-air,no
550,15561849.0,"we review modeling and implementation issues encountered during the development of conceptbase, a prototype deductive object manager supporting the telos object model. significant features include: i)",{'conceptbase'},1.0,is-a,conceptbase is a prototype deductive object manager supporting the telos object model.,conceptbase,prototype deductive object manager supporting the telos object model,no
551,11011017.0,interpolative decomposition (id) of a matrix was introduced first for operator compression [17] . it is designed to approximate spectrally linear integral operators.,{'interpolative decomposition'},1.0,used-for,interpolative decomposition is used to approximate spectrally linear integral operators.,interpolative decomposition,approximate spectrally linear integral operators,no
552,11011017.0,"the class of randomized matrix decomposition algorithms is out of the scope of this paper. cur decomposition [12, 36] of a given matrix a generalizes the id in the sense that both subsets of columns and rows of the original matrix are selected to form the matrices c and r, respectively, such that a  cu r for a low rank matrix u .",{'cur decomposition'},1.0,is-a,"cur decomposition is a generalization of the id in the sense that both subsets of columns and rows of the original matrix are selected to form the matrices c and r, respectively, such that a  cu r for a low rank matrix u.",cur decomposition,generalization of the id,no
553,11011017.0,"in data analysis terms, this decomposition enables us to get sampling of significant data points (rows), as well as significant features (columns). similar to id and unlike this work, cur decompositions are designated to spectrally approximate the original matrix a. randomized versions of cur also exist -see",{'cur decomposition'},1.0,compare,cur decomposition is like id in that they are both designated to spectrally approximate the original matrix a.,cur decomposition,id,no
554,164805212.0,"the authors of [28] , [29] considered a circular disk failure model, assuming that a disaster occurred randomly in a circular disk of a given radius. they evaluated the robustness of connectivity of a network to such a randomly placed disaster based on certain network performance metrics.",{'circular disk failure model'},0.0,,,,,
555,164805212.0,"considering also a circular disk failure model, cao et al. [30] formulated an optimization problem on a twodimensional plane for path planning to minimize the total cable cost under certain constraints on resilience.",{'circular disk failure model'},0.0,,,,,
556,164805212.0,"in [33] , the use of shielded links (e.g., armored telecommunication cables) was considered to enhance the network resilience in risk-prone areas. zhang and modiano [34] gave a method to evaluate the robustness of interdependent networks by obtaining the minimal number of node removals that disconnect the network.",{'interdependent network'},0.0,,,,,
557,41690624.0,"currently, one of the most successful methods are the multi-grid (mg) methods [21, 25, 26] . the robustness of a mg method is often significantly improved when used as a preconditioner in *emails: pawan.kumar@cs.kuleuven.be; kumar.lri@gmail.com a krylov subspace method [22] .",{'krylov subspace method'},0.0,,,,,
558,15449381.0,"gingras & larivire, 2011) about dividing averages or averaging rates by proposing the metrics of the six percentile rank classes in use for the science & engineering indicators: top-1%, top-5%, top-10%, top-25%, top-50%, and bottom-50% as an alternative to using averages (national science board, 2012). elaborated the non-parametric statistics for percentile rank classes, and leydesdorff & bornmann (2011b) then applied a newly defined ""integrated impact indicator"" (i3) to two groups of journals: the set of 65 journals classified in the web of science (wos) as library & information science, and the 48 ""multidisciplinary"" journals, including journals such as science, nature, and pnas. such non-parametric perspectives can lead to statistically significantly different rank-orderings when compared with parametric ones.",{'percentile rank class'},0.0,,,,,
559,54862517.0,"this measure is based on tricolor attenuation model, which describes the relationship of three color channel's attenuation in image when shadow happens. according to this relationship, the cast shadow is removed from the detected moving area, only the target area is left.",{'tricolor attenuation model'},1.0,is-a,tricolor attenuation model is a model which describes the relationship of three color channel's attenuation in image when shadow happens.,tricolor attenuation model,model,no
560,54862517.0,cast shadow with moving target is one of these problems. cast shadow detection is critical for accurate object detection in video streams since shadow points are often misclassified as object points.,{'accurate object detection'},0.0,,,,,
561,126127652.0,"first, we define mean residual between two hesitant fuzzy elements and a new fuzzy complementary judgment matrix and then prove it has additive consistency; on this basis, we gain a new weighted fuzzy complementary judgment matrix. then, the fuzzy complementary judgment matrix is implemented to rank and select alternatives.","{'additive consistency', 'hesitant fuzzy element'}",0.0,,,,,
562,126127652.0,"as an extension of fuzzy set, torra [7] proposed the concept of hesitant fuzzy set in which the membership degree of an element in the domain has a set of possible values between 0 and 1. proposed concept is a powerful tool to deal imprecise and uncertain decision making problem.",{'hesitant fuzzy set'},1.0,is-a,hesitant fuzzy set is a concept in which the membership degree of an element in the domain has a set of possible values between 0 and 1.,hesitant fuzzy set,concept,no
563,126127652.0,"xu et al. [15, 16] introduced some basic concepts of hesitant fuzzy set such as correlation coefficient, entropy, cross entropy and so on and applied them to the multiple attribute decision making.",{'hesitant fuzzy set'},1.0,used-for,hesitant fuzzy set is used for multiple attribute decision making.,hesitant fuzzy set,multiple attribute decision making,no
564,126127652.0,"farhadinia [20, 21] proposed the formula of distance, similarity degree, entropy on hesitant fuzzy set and a new method for ranking alternatives expressed with hesitant fuzzy set. the consistency of the preference relationship will have a direct effect on the rationality of the final ranking of the alternatives, and the lack of consistency will produce the result that is not logical.",{'hesitant fuzzy set'},0.0,,,,,
565,126127652.0,"rank and select alternatives is the purpose of solving multiple attribute decision making problem. at present, the common methods including aggregation operators [26, 27, 28, 29] , topsis [30, 31, 32, 33] , vikor [34, 35] , grey relational analysis [36, 37] the remaining sections of this paper are set up as follows: section 2 reviews and fixes basic concepts; section 3 constructs a new fuzzy complementary judgment matrix and proves it has additive consistency and then it's generalization is generalized; section 4, a new approach to multiple attribute decision making under hesitant fuzzy environment is developed; section 5 provides a numerical example to demonstrate the feasibility and validity of the proposed method and","{'additive consistency', 'hesitant fuzzy environment'}",0.0,,,,,
566,7252150.0,"while warping the boundary layer, special operations, like matting or filtering, are adopted to reduce the boundary effect [3] [7] . however, these methods need several iterations processing.",{'matting'},1.0,is-a,matting is a special operation used to reduce the boundary effect while warping the boundary layer.,matting,special operation,no
567,7252150.0,,,,compare,matting is like filtering in that they are both special operations used to reduce the boundary effect while warping the boundary layer.,matting,filtering,no
568,10333762.0,[9] analyze the performance of carrier sense multiple access (csma)-based broadcast networks in vanet by using tools from stochastic geometry. a theoretical analysis model is presented in [10] to infer the performance of the distributed coordination function (dcf) mac protocol in ieee 802.11p,{'stochastic geometry'},0.0,,,,,
569,10333762.0,"jiang and du [21] proposed a prediction-based tdma mac (ptmac) to eliminate encounter collisions by prediction before the collisions happen, and the two-way traffic and four-way intersections are considered in the protocol. a centralized tdma-based scheduling protocol is proposed in [22] , which takes advantage of roadside units (rsu) to collect channel and vehicles information, and the rsus make scheduling decisions based on the collected information.",{'ptmac'},1.0,used-for,"ptmac is used to eliminate encounter collisions by prediction before the collisions happen, and the two-way traffic and four-way intersections are considered in the protocol.",ptmac,eliminate encounter collisions by prediction before the collisions happen,no
570,9391732.0,"an opportunity of investigation is offered by the use of generally distributed reaction times. in this paper, we describe how general distributions are introduced into blenx, a programming language designed for specifying biological models.",{'blenx'},1.0,is-a,blenx is a programming language designed for specifying biological models.,blenx,programming language designed for specifying biological models,no
571,9391732.0,"2 gives a brief tutorial on blenx [10], a process calculi inspired programming language designed for modeling biological systems, and we comment on how general distributions have been managed. then, sect.",{'blenx'},1.0,is-a,blenx is a process calculi inspired programming language designed for modeling biological systems.,blenx,process calculi inspired programming language designed for modeling biological systems,no
572,13385513.0,"specifically, we assume a zeroforcing (zf) solution constraint to eliminate the residual self-interference. as a consequence, we address the optimal joint design of the zf matrix and the an covariance matrix at the relay node as well as the transmit power at the sources.",{'residual self - interference'},0.0,,,,,
573,2385909.0,"the technique is effective because it maximizes fidelity based on a comprehensive end-to-end system model that accounts for scene statistics, acquisition blurring, sampling, and noise this paper is not about resolution merge, it is about object or images merge. merging of images discussed in this paper can be used in many applications for example, solid property predictions, creating currency, body implant, compression fractures, fast viewing or creative editing.",{'scene statistic'},0.0,,,,,
574,3354196.0,"therefore, it can also improve the packet delivery ratio in vehicular ad hoc networks (vanets) when the mobility of relaying vehicles is unknown. however, in wireless networks, multiple paths are exposed to mutual interference or path coupling, which impairs efficiency.",{'path coupling'},0.0,,,,,
575,3354196.0,"through extensive simulations, we explore the effect of mutual interference on the behavior of node-disjoint paths. it is shown that whether node-disjoint paths are able to improve performance, compared with the single path, is determined by path coupling and the source-destination distance.",{'path coupling'},0.0,,,,,
576,3354196.0,"marina and das proposed aomdv [13] to compute loop-free and link-disjoint paths. incorporating the path accumulation feature of dsr into the extension of aodv, the routing protocol in [14] discovers multiple node-disjoint paths with low overhead.",{'aomdv'},1.0,used-for,aomdv is used to compute loop-free and link-disjoint paths.,aomdv,compute loop-free and link-disjoint paths,no
577,3354196.0,"champ [16] , which is based on dsr, uses cooperative packet caching and shortest multipath routing to enhance robustness against link breakdowns. raghunathan and kumar [17] proposed a distributed loadadaptive multipath routing protocol that converges to the wardrop equilibrium.",{'cooperative packet caching'},0.0,,,,,
578,10467053.0,"abstract: h  controller design for linear systems is a difficult, nonconvex and typically nonsmooth (nondifferentiable) optimization problem when the order of the controller is fixed to be less than that of the open-loop plant, a typical requirement in e.g. embedded aerospace control systems. in this paper we describe a new matlab package called hifoo, aimed at solving fixed-order stabilization and local optimization problems.",{'hifoo'},1.0,is-a,hifoo is a matlab package aimed at solving fixed-order stabilization and local optimization problems.,hifoo,matlab package,no
579,10467053.0,"it depends on a new hybrid algorithm for nonsmooth, nonconvex optimization based on several techniques, namely quasinewton updating, bundling and gradient sampling. the user may request hifoo to optimize one of several objectives, including h  norm, which requires either the control system toolbox for matlab or, for much better performance, the linorm function in the slicot package.",{'hifoo'},1.0,used-for,"hifoo is used to optimize one of several objectives, including h norm, which requires either the control system toolbox for matlab or, for much better performance, the linorm function in the slicot package.",hifoo,optimize one of several objectives,no
580,12404390.0,there are two basic approaches to anomaly detection using system calls; sequence-based approach and frequency-based approach. the former approach keeps track of system call sequences in a database of normal behavior.,{'system sequence'},0.0,,,,,
581,12404390.0,"although stide is a simple and efficient technique, it can be seen that by keeping the order information of the calls, the size of the database can grow linearly with the number of system calls in the trace. some improvements to the stide technique were introduced in [11] and [19] .",{'stide'},0.0,,,,,
582,12404390.0,"al compared stide, ripper, and hmm-based methods in [19] . they concluded that all methods performed adequately, while hmm gave the best accuracy on average.","{'ripper', 'stide'}",0.0,,,,,
583,19016620.0,"in online webcast lectures, however, interaction can be difficult because instructors lack basic awareness information about their remote students. our goal is to better understand the kinds of awareness information that instructors should have if they are to interact frequently and effectively with their students in elearning environments.",{'awareness information'},1.0,type-of,awareness information is a type of information that instructors should have in online webcast lectures if they are to interact frequently and effectively with their students in elearning environments.,awareness information,information,no
584,5941582.0,"in general, a unit is a region of pixels that some bottom-up process provides for further processing. in a crf, these are the ""nodes"", which correspond to pixels or superpixels.",{'superpixel'},0.0,,,,,
585,5941582.0,"this is in contrast to [25] , where node features are always extracted from a predetermined fixed neighborhood of the base superpixel. recent models have also shown how to incorporate information about co-occurring objects and their spatial layouts [12, 11] .",{'node feature'},0.0,,,,,
586,49552729.0,"importantly, team assembly mechanisms have been described as fundamental elements that determine the structure of the collaboration networks and the performance of the teams [11] . is model considers three parameters: ""team size, the fraction of newcomers in new productions, and the tendency of incumbents to repeat previous collaborations.""",{'team assembly mechanism'},1.0,is-a,team assembly mechanism is a fundamental element that determines the structure of the collaboration networks and the performance of the teams.,team assembly mechanism,fundamental element that determines the structure of the collaboration networks and the performance of the teams,no
587,6990534.0,"in 1943, mcculloch and pitts published the idea of a nn that models the architecture of the human brain in order to solve problems [2] . but it took about 45 years until the backpropagation algorithm [3] made useful applications such as handwritten zip code recognition possible [4] .",{'handwritten zip code recognition'},1.0,is-a,handwritten zip code recognition is an application of a nn that models the architecture of the human brain.,handwritten zip code recognition,application of a nn that models the architecture of the human brain,no
588,15907113.0,"one of the key aspects that explains student behavior while watching a video is, evidently, the video itself. numerous studies have attempted to identify optimal mooc video attributes, mostly by looking at measures related to a student's dwelling time: the amount of time students spend watching a video.",{'student dwelling time'},1.0,is-a,student dwelling time is a measure of the amount of time students spend watching a video.,student dwelling time,measure of the amount of time students spend watching a video,no
589,204949688.0,"cases of sep are generation expansion planning (gep) [1] , [2] and transmission expansion planning (tep)",{'sep'},0.0,,,,,
590,204949688.0,"a common aspect in most sep models is the representation of uncertainties, although each model typically focuses on sources of randomness, like renewable energy and load [12] , outages or contingencies [13] , [14] . frequently used frameworks to deal with uncertainties in sep are stochastic optimization [15] , [16] and robust optimization [12] , [17] , both of which can also be combined",{'sep'},1.0,type-of,"sep is a type of model which typically focuses on sources of randomness, like renewable energy and load, outages or contingencies.",sep,model,no
591,4802258.0,"up till now, several manual and semi-automatic methods have been introduced, but the need of fully-automatic segmentation of cells in the endothelium is still in search. this work addresses the problem of automatic delineation of cells in the corneal endothelium images and suggests to use the convolutional neural network (cnn) to classify between cell center, cell body, and cell border in order to achieve precise segmentation.",{'convolutional neural network'},1.0,used-for,"convolutional neural network is used to classify between cell center, cell body, and cell border in order to achieve precise segmentation for the problem of automatic delineation of cells in the corneal endothelium images.",convolutional neural network,"classify between cell center, cell body, and cell border",no
592,4802258.0,"as a final check-up, the visual inspection is shown. the performed experiments revealed the best architecture for cnn.",{'cnn'},0.0,,,,,
593,4802258.0,"while modified hausdorff distance shows 0.14 pixel distance, proving very high accuracy. these findings are confirmed by other metrics and also supported by presented visual inspection of achieved segmentations.",{'modified hausdorff distance'},0.0,,,,,
594,4802258.0,"[33] suggested very similar approach but used a convolutional neural network. finally, [34] trained a feedforward network with statistical information about pixels, in order to classify whether they represent the border or cell body.",{'convolutional neural network'},0.0,,,,,
595,4802258.0,the aim of this article is to present a novel approach for automatic segmentation of the corneal endothelium images. a convolutional neural network tailored to deal with this problem was designed.,{'convolutional neural network'},1.0,used-for,convolutional neural network is used for automatic segmentation of the corneal endothelium images.,convolutional neural network,automatic segmentation of the corneal endothelium images,no
596,6672551.0,"additionally, tau includes its own facilities for analysis of performance data. the paraprof [11] profile analysis tool, for example, provides a full set of graphical tools for evaluation of performance profile data.",{'paraprof'},1.0,is-a,paraprof is a profile analysis tool that provides a full set of graphical tools for evaluation of performance profile data.,paraprof,profile analysis tool,no
597,6672551.0,this executable will then be run by the cdt or ptp launch management system. when execution is complete profile data may be stored automatically in a local perfdmf database and viewed in paraprof.,{'paraprof'},1.0,used-for,paraprof is used to view profile data stored in a local perfdmf database.,paraprof,view profile data stored in a local perfdmf database,no
598,17922688.0,"in addition, in order to support smooth and continuous viewpoint switching, virtual view synthesis is required to generate virtual view frames between different viewpoints and fill the non-captured area, since it is impossible to capture video sequences from all viewpoints with infinite real cameras. in july 2008, mvc is standardized as the multiview high profile in h.264/avc by mpeg 3d audio/video (3dav) group.",{'h.264 / avc'},0.0,,,,,
599,53287815.0,[7] and tang [15] . we solve the linear system of equations ax = b for a low-rank matrix a and a vector b that have some natural sampling assumptions.,{'low - rank matrix'},0.0,,,,,
600,206959485.0,"as the silicon area available for the processing circuitry is very limited in a pixel-perprocessor array, the pes are necessarily very simple. single-bit digital processors were used in [4] and [5], whereas the ""analogic"" approaches reviewed in [6] are based upon the cnn (cellular neural network) concept.",{'cnn'},0.0,,,,,
601,761182.0,"in this paper, we discuss a trilingual application of earlier research on quantitative representations of the discourse structure of texts, derived from measurements of lexical cohesion. the representations are computed by measuring the similarity between vector representations of adjacent text segments, following a proposal in (hearst, 1993) .",{'vector representation'},0.0,,,,,
602,406684.0,"for example, yarowsky [28] performed word sense disambiguation by constructing a sense classifier using the local context of the word and a classifier based on the senses of other occurrences of that word in the same document; riloff and jones [23] classified a noun phrase for geographic locations by considering both the noun phrase itself and the linguistic context in which the noun phrase appears; collins and singer [8] performed named entity classification using both the spelling of the entity itself and the context in which the entity occurs. it is noteworthy that the co-training paradigm has already been used in many domains such as statistical parsing and noun phrase identification [15] , [21] , [24] , [27] .",{'name entity classification'},0.0,,,,,
603,160013866.0,"namely, the relationships between natural language elements with image regions via computing the attention weights between words/questions and image regions. the core idea of the spatial attention mechanism is that every word in captions or every question should only correspond to one or several",{'attention weight'},0.0,,,,,
604,16349522.0,"instead, given a region in an image, the classification problem is to decide if the region contains a vehicle or not. in that sense, it is more similar to the problem of image classification, such as xu et al.",{'image classification'},0.0,,,,,
605,16349522.0,"the method is designed with performance in mind, allowing it to run in scenarios with limited computational power, while still providing good accuracy and robustness. the method combines integral channel features [8] with logistic regression [13] and support vector machine [10, 4] .",{'integral channel feature'},0.0,,,,,
606,5110854.0,"the support vector tracker [22] (denoted as svt afterwards) uses an offline-learned support vector machine as the classifier and embeds it into an optical flow based tracker. recently, struck [18] employed the structural support vector machines to learn the object classifier and achieved the state-of-the-art performance.",{'svt'},0.0,,,,,
607,5110854.0,"avidan's ensemble tracker [15] combines an ensemble of online learned weak classifiers using adaboost to classify pixels in the new frame. in discriminative spatial attention tracking [23] , attention regions (ar) which are locally different from their neighborhoods are selected as discriminative tracking features.",{'discriminative tracking feature'},0.0,,,,,
608,5110854.0,"this process can be done efficiently because the ssd distance map can be computed efficiently using haar-like features and integral images. once the distance map is computed, the local minima locations are used to select negative training examples by means of nonminimal suppression.",{'integral image'},0.0,,,,,
609,1541170.0,"after placing tcsc the investment cost of tcsc and generator rescheduling cost is minimized using particle swarm optimization (pso) and pso-tvac. numerical results on test system, ieee 30 bus and ieee 118 bus systems are presented for illustration purpose and the results are compared with particle swarm optimization (pso) in terms of solution quality.",{'pso - tvac'},1.0,used-for,pso-tvac is used to minimize the investment cost of tcsc and generator rescheduling cost.,pso-tvac,minimize the investment cost of tcsc and generator rescheduling cost,no
610,7823961.0,"to analyze the diffusion process on large graphs, we use the ""mean-field analysis technique"" to determine which initial condition leads to or prevents information or virus outbreak. numerical results show our methodology can accurately predict the behavior of the phase-transition process for various large graphs (e.g., complete graphs, random graphs or power-law graphs).",{'power - law graph'},1.0,type-of,power-law graph is a type of large graph.,power-law graph,large graph,no
611,7823961.0,,,,compare,power-law graph is like complete graph in that they are both types of large graphs.,power-law graph,complete graph,no
612,7823961.0,,,,compare,power-law graph is like random graph in that they are both types of large graphs.,power-law graph,random graph,no
613,7823961.0,"however, the sis model is often too restrictive. to illustrate, consider the case that a diffusion model is used to describe a product adoption [5] , [6] .",{'diffusion model'},1.0,used-for,diffusion model is used to describe a product adoption.,diffusion model,describe a product adoption,no
614,7823961.0,"for viral marketing, the consumer purchase decision process theory [7] suggests that there are five stages until a consumer buys a product and influences others. this motivates us to study and analyze a generalized sis model that allows multi-susceptible states before getting infected.",{'viral marketing'},0.0,,,,,
615,7823961.0,"[18] proposed a model of a multi-stage complex contagion, in which agents at different stages exert different amounts of influence on their neighbors. our work focused on the generalized sis model, in which the phase-transition process is different from the cascade model used in [18] .",{'multi - stage complex contagion'},1.0,is-a,multi-stage complex contagion is a model in which agents at different stages exert different amounts of influence on their neighbors.,multi-stage complex contagion,model,no
616,33512574.0,"particularly, these works are mostly based on heuristics for estimating the privacy attained by slightly modifying the set of frequent itemsets so that an attacker has less information about sensitive rules. in [25] , a cryptographic method is introduced for preserving privacy in horizontally partitioned and distributed databases.",{'sensitive rule'},0.0,,,,,
617,33512574.0,"in [19] , a sanitization method is introduced to sanitize restrictive rules while blocking inference. in [35] a method for mining association rules is introduced in a distributed settings where collusion resistance is provided up to a threshold.",{'mining association rule'},0.0,,,,,
618,13277562.0,"the former is approaches based on matching lexico-syntactic patterns which convey taxonomic relations in a corpus (hearst, 1992; iwanska et al., 2000) , and the latter is statistical approaches based on the distribution of context in corpus (cimiano et al., 2005; yamamoto et al., 2005; sanderson & croft, 1999) .",{'lexico - syntactic pattern'},1.0,used-for,lexico-syntactic patterns are used to convey taxonomic relations in a corpus.,lexico-syntactic patterns,convey taxonomic relations in a corpus,no
619,174803115.0,"in this model the nodes can use quantum processing and communicate using quantum bits (qubits): each edge of the network corresponds to a quantum channel (e.g., an optical fiber if qubits are implemented using photons) of bandwidth o(log n) qubits. their main conclusion was that for many fundamental problems in distributed computing, including the computation of the s-t shortest path in weighted graphs, quantum communication does not offer significant advantages over classical communication.",{'quantum channel'},0.0,,,,,
620,58019925.0,"big data analytics is often associated with cloud computing because the analysis of large data sets in realtime requires a platform like hadoop to store large data sets across a distributed cluster. mapreduce is required to coordinate, combine and process data from multiple sources.",{'mapreduce'},1.0,used-for,"mapreduce is used to coordinate, combine and process data from multiple sources.",mapreduce,"coordinate, combine and process data from multiple sources",no
621,13220773.0,"based on the singularity degree of the psd matrix completion problem, we introduce two new graph parameters. the first parameter is the singularity degree sd(g) of a graph g, which is defined as the largest singularity degree of the matrix completion problem p(g, c) over all edge weights c  e(g).",{'matrix completion problem'},0.0,,,,,
622,9524351.0,"another problem is that musical genre annotation is still performed manually. in such a way, automatic musical genre classification can assist or replace the human user in this process as well as it can provide an important component for a complete music information retrieval system.",{'automatic musical genre classification'},1.0,used-for,automatic musical genre classification is used to assist or replace the human user in the manual process of musical genre annotation,automatic musical genre classification,assist or replace the human user in the manual process of musical genre annotation,no
623,9524351.0,,,,used-for,automatic musical genre classification is used to provide an important component for a complete music information retrieval system.,automatic musical genre classification,provide an important component for a complete music information retrieval system,no
624,9524351.0,"these features are related to the timbral texture, rhythm and pitch. gaussian mixture model and k-nearest neighbor classifiers were used to classify the extracted features.",{'timbral texture'},0.0,,,,,
625,8128430.0,this avoids dealing with noise and outliers but ignores the direct measurements and makes figure 1 : computation of approximate geodesic g with different surface representations by the heat method [7] . column 1: input kinect pointcloud.,{'heat method'},0.0,,,,,
626,8128430.0,"column 2: representation of the surface with a high-resolution mesh obtained with poisson reconstruction [15] (row 1), a low-resolution triangular mesh obtained by quadratic edge collapse [9] of the high-resolution mesh (row 2), and with our subdivision surface (row 3). columns 3 and 4: level lines of the geodesic visualized as cos( g).",{'poisson reconstruction'},1.0,used-for,poisson reconstruction is used to obtain a high-resolution mesh of a surface.,poisson reconstruction,obtain a high-resolution mesh of a surface,no
627,8128430.0,"our subdivision surface is comparable to the surface obtained by poisson reconstruction and faithfully represent geodesics at low and high resolution with 2% of vertices. compressing the poisson mesh by edge collapse looses all the small scale details of the surface and its geodesic, as highlighted by high-frequency level lines of the geodesic.",{'poisson reconstruction'},0.0,,,,,
628,8128430.0,"we focus on laplace-beltrami operator, wave kernel signatures [1] , approximate geodesics [7] and prove its efficacy in the full-pipeline task of shape matching [25] . our experiments show state-of-the-art performance at a fraction of the memory requirements of shape representations with triangular meshes.",{'wave kernel signature'},0.0,,,,,
629,13261162.0,"the rewriting rule automatically gives a functional equation satisfied by the bivariate generating function that counts the permutations by their length and the label of the corresponding node of the tree. these equations are now well understood, and their solutions are always algebraic series.",{'bivariate generating function'},1.0,type-of,bivariate generating function is a type of function that counts the permutations by their length and the label of the corresponding node of the tree.,bivariate generating function,function,no
630,10033012.0,"(2011a) characterize the geometric conditions for the uncertainty sets under which finite adaptability provides good approximations of the adjustable robust solutions. vayanos (2011) split the uncertainty set into hyper-rectangles, assigning to each of them the corresponding later-period adjustable linear and binary variables.",{'finite adaptability'},0.0,,,,,
631,10033012.0,"(2014) apply finite adaptability to two-period decision problems with binary variables. in this setting, the decision maker can choose out of k possible decisions in the second period when the uncertain parameter value is known.",{'finite adaptability'},1.0,used-for,finite adaptability is used for two-period decision problems with binary variables.,finite adaptability,two-period decision problems with binary variables,no
632,162168769.0,"typically, items with highest counts, commonly known as heavy hitters, are of most interest"". this note is an attempt to redefine event counting problem (cf.",{'heavy hitter'},0.0,,,,,
633,6466408.0,"using a recently developed simulation framework that allows assessment of online performance, we empirically evaluate both methods. our results show that balancing exploration and exploitation can substantially and significantly improve the online retrieval performance of both listwise and pairwise approaches.",{'listwise'},1.0,type-of,listwise is a type of approach that shows improved retrieval performance by balancing exploration and exploitation.,listwise,approach,no
634,6466408.0,,,,compare,listwise is like pariwse in that they are both approaches that show improved retrieval performances by balancing exploration and exploitation.,listwise,pairwise,no
635,6466408.0,"(herbrich et al. 1999; joachims 2002) ] and listwise [e.g., softrank )] learning to rank. as in other supervised learning settings, supervised learning to rank methods typically assume that a representative set of training data (including judgments) is available at training time, so that characteristics of the data can be estimated from this set.",{'listwise'},0.0,,,,,
636,6466408.0,these stochastic methods infer feedback using interleaved comparison methods (hofmann et al. 2011b; radlinski and craswell 2010) .,{'interleaved comparison method'},0.0,,,,,
637,61142636.0,"[2] , which is based on minimizing the inter-point distances between two overlapping surfaces. although the icp is an acceptable procedure for the registration of surfaces represented by irregularly distributed points, the utilization of such algorithm requires a large overlap ratio with appropriate geometry among the involved datasets.",{'icp'},1.0,is-a,icp is a procedure for the registration of surfaces represented by irregularly distributed points.,icp,procedure,no
638,61142636.0,,,,is-a,icp is an algorithm which requires a large overlap ratio with appropriate geometry among the involved datasets.,icp,algorithm,no
639,61142636.0,"although the icp is an acceptable procedure for the registration of surfaces represented by irregularly distributed points, the utilization of such algorithm requires a large overlap ratio with appropriate geometry among the involved datasets. these requirements are not exclusive to the icp procedure but valid for any registration method based on the use of the tls point cloud only [3] .",{'icp'},0.0,,,,,
640,61446768.0,"student dropout is a challenging task in higher education [1] and it is reported that about one fourth of students dropped college after their first year [1] [2] [3] . recent study results show that intervention programs can have significant effects on dropout, especially for the first year.",{'dropout'},0.0,,,,,
641,31268871.0,"our results show that paid scales as well as the trivial parallelization using dcuhre. in addition, paid's adaptivity over the indexes m and n of the integrals consistently yields a speedup from 2 up to 4.",{'dcuhre'},0.0,,,,,
642,8314389.0,"we investigate convergence properties of a proposed distributed model predictive control (dmpc) scheme, where agents negotiate to compute an optimal consensus point using an incremental subgradient method based on primal decomposition as described in [1], [2] . the objective of the distributed control strategy is to agree upon and achieve an optimal common output value for a group of agents in the presence of constraints on the agent dynamics using local predictive controllers.",{'agent dynamic'},0.0,,,,,
643,1995031.0,"saewong and rajkumar provided an algorithm to find the optimal speed value for fixed priority assignments [26] , assuming that the speed of the processor can be varied continuously in a given range. in practice, however, processors provide a finite number of discrete speeds.",{'fix priority assignment'},0.0,,,,,
644,33024671.0,"while automata are useful for finding tight complexity bounds, consequence-based algorithms are typically simpler to describe, implement, and optimize. in this paper, we show that consequence-based reasoning can be reduced to the emptiness test of an appropriately built automaton.",{'consequence - base reasoning'},0.0,,,,,
645,13122295.0,"for large lesions that extend anteriorly to a well-aerated sphenoid sinus, trans-nasal, trans-sphenoidal endoscopic approaches may be used. concentric tube robots have been recently used to augment this approach [5] [6] .",{'concentric tube robot'},0.0,,,,,
646,1927860.0,"another popular method, the fast sweeping method (fsm) [40] , uses an alternating gauss-seidel update to speed up the convergence because the method does not rely on a sorting data structure as fmm does. a gauss-seidel update requires reading from and writing to the single memory location, and it is inefficient or prohibited on some of the most efficient parallel architectures.",{'fast sweeping method'},1.0,is-a,fast sweeping method is a method which uses an alternating gauss-seidel update to speed up the convergence because it does not rely on a sorting data structure.,fast sweeping method,method,no
647,1927860.0,,,,compare,fast sweeping method is like fmm except that it does not rely on a sorting data structure.,fast sweeping method,fmm,no
648,1114750.0,"he also made experiments with regular graphs and his experiments showed that interaction topology is important in the efficiency of convention emergence-he conjectured that efficiency depends on the diameter of the graph. in what concerns the number of interactions needed to accomplish consensus, kittock observed a variation with the number of agents of o(n 3 ) for regular graphs and o(nlogn) for fully connected ones.",{'interaction topology'},0.0,,,,,
649,14102427.0,"it turns out that identification of linearisation points is a nontrivial task. some algorithms have simple fixed linearisation points, others have external linearization points that are determined by the execution of other operations, while other yet more complex algorithms have external linearisation points that potentially modify the state representation of the concurrent object.",{'state representation'},0.0,,,,,
650,26420527.0,"recently, transfer distance metric learning (tdm-l) has attracted lots of interests, but most of these methods assume that feature representations for the source and target learning tasks are the same. hence, they are not suitable for the applications, in which the data are from heterogeneous domains (feature spaces, modalities and even semantics).",{'distance metric learning'},0.0,,,,,
651,26420527.0,"these approaches often transform the heterogeneous features into a common subspace, so that the difference between heterogeneous domains is reduced. most of the htl methods are not specially designed for distance metric learning (dml), but we can derive a metric from the learned transformation for each domain.",{'distance metric learning'},0.0,,,,,
652,26420527.0,"then we extract some knowledge fragments from the learned metric for transfer. in this paper, we assume there are abundant unlabeled samples that have feature representations in both of the source and target domains.",{'learn metric'},0.0,,,,,
653,26420527.0,"the main advantages of the proposed htdml are: 1) the source knowledge fragments can be learned offline, we do not have to reuse the original source domain data. hence, the algorithm can be used in the applications where source domain data are invisible.",{'source domain datum'},0.0,,,,,
654,26420527.0,"we conduct experiments on two popular applications: scene classification and object recognition. in addition to the euclidean (eu) and single domain dml baselines, we further compare with several representative heterogeneous transfer learning approaches [wang and mahadevan, 2011;",{'scene classification'},0.0,,,,,
655,2512026.0,""" we explore the effectiveness of this solution in an empirical study of apache security software. we find high heterogeneity of need in that field, and also find that users modifying their own software to be significantly more satisfied than non-innovating users.",{'apache security software'},0.0,,,,,
656,14807747.0,"a randomized decision tree is a probability distribution on the deterministic decision trees that compute f~ the time is measured by averaging. the randomized decision tree complexity, rc(f), is the maximum (over all input settings) average (according to the distribution) number of variables read in the best distribution.",{'deterministic decision tree'},,,,,,
657,6160491.0,"to achieve this goal, we developed an algorithm for generating human-like dhm walking motions, adapting its strides, turning angles, and footprints to laser-scanned 3d as-is environments including slopes and stairs. the dhm motion was generated based only on a motion-capture (mocap) data for flat walking.",{'stride'},0.0,,,,,
658,6160491.0,"in this system, the walking simulation algorithm used only single reference motioncapture (mocap) data for flat walking and enabled a dhm to walk autonomously in as-is and flat indoor environments while adapting its strides and turning angles accordingly. however, the algorithm does not allow the dhm to walk on non-flat terrain surfaces such as slopes and stairs.",{'stride'},0.0,,,,,
659,6160491.0,"therefore, in this research, we develop an algorithm that enables a dhm to walk autonomously even on the non-flat terrain of as-is indoor and outdoor environments. the strides, turning angles and footprints of the dhm can be adapted to different laser-scanned environment models including corridors, slopes, and stairs.",{'stride'},0.0,,,,,
660,1098428.0,"only most recently, several approaches based on probabilistic theory are proposed for global localization, including grid-based approaches (burgard, w. et al, 1996) , topological approaches (kaelbling, l. p. et al, 1996) (simmons, r. & koenig, s., 1995) , monte carlo localization (dellaert, f. et al, 1999) and multihypothesis tracking (jensfelt, p. & kristensen, s., 2001 )",{'monte carlo localization'},1.0,is-a,monte carlo localization is an approach proposed for global localization.,monte carlo localization,approach proposed for global localization,no
661,1098428.0,,,,based-on,monte carlo localization is based on probabilistic theory.,monte carlo localization,probabilistic theory,no
662,1098428.0,,,,compare,monte carlo localization is like grid-based approach in that they are both approaches proposed for global localization.,monte carlo localization,grid-based approach,no
663,1098428.0,,,,compare,monte carlo localization is like topological approach in that they are both approaches proposed for global localization.,monte carlo localization,topological approach,no
664,1098428.0,,,,compare,monte carlo localization is like multihypothesis tracking in that they are both approaches proposed for global localization.,monte carlo localization,multihypothesis tracking,no
665,1098428.0,"(roumeliotis, s.i. & bekey, g.a., 2000) . by representing probability densities with sets of samples and using the sequential monte carlo importance sampling (andrieu, c. & doucet, a., 2002) , monte carlo localization (mcl) can represent non-linear and non-gaussian models well and focus the computational resources on regions with high likelihood.",{'monte carlo localization'},1.0,used-for,monte carlo localization is used to represent non-linear and non-gaussian models and focus the computational resources on regions with high likelihood.,monte carlo localization,represent non-linear and non-gaussian models,no
666,1098428.0,,,,is-a,monte carlo localization is an approach that represents probability densities with sets of samples and uses the sequential monte carlo importance sampling.,monte carlo localization,approach,no
667,18172248.0,[ ij ] is a nonnegative parameter matrix. it is a conjugate prior for the likelihood of t and can be easily analyzed and efficiently sampled since each row of t follows the dirichlet distribution.,{'dirichlet distribution'},0.0,,,,,
668,41270765.0,"han et al. [9] extracted the features of finger width, length, and the palmprint, put these features into a principal component analysis (pca) process to filter meaningful features, and used the generalized learning vector quantization (glvq) approach to verify the identity of persons.",{'generalized learn vector quantization'},1.0,used-for,generalized learning vector quantization is used to verify the identity of persons.,generalized learning vector quantization,verify the identity of persons,no
669,41270765.0,[11] transferred palmprints to line sections. they applied the datum point-invariant characteristics and the line-matching technique to verify palmprint features.,{'palmprint feature'},0.0,,,,,
670,204700972.0,"although some improvements have been proposed (multimodality, climate variations), non-parametric machine learning approaches have been privileged [13] . random forest, support vector machines [4] , [10] , gaussian processes [14] or neural networks [15] are part of the solutions used.",{'random forest'},0.0,,,,,
671,204700972.0,the french agricultural farmer declaration (lpis) allows to extract enough samples to permit supervised training. our proposed rnn architecture can be fed with external data through attention mechanisms [17] .,{'attention mechanism'},0.0,,,,,
672,204916015.0,"our methodology integrates three key components. first, to identify distinct commenting patterns, we use deep embedded clustering to estimate framing information (essential extrinsic features) that clusters users into distinct groups.",{'deep embed clustering'},1.0,used-for,deep embedded clustering is used to estimate framing information (essential extrinsic features) that clusters users into distinct groups.,deep embedded clustering,estimate framing information,no
673,204916015.0,"our methodology integrates three key components to model the collective commenting behavior of youtube viewers. first, to identify distinct commenting patterns over youtube videos, we use deep embedded clustering that partitions groups of videos from a massive youtube dataset into non-overlapping segments.",{'deep embed clustering'},1.0,used-for,deep embedded clustering is used to partition groups of videos from a massive youtube dataset into non-overlapping segments.,deep embedded clustering,partition groups of videos from a massive youtube dataset into non-overlapping segments,no
674,204916015.0,"the second component involves inverse reinforcement learning; we use bayesian revealed preferences to construct a test for utility maximization behavior for individual groups of users and estimate utility functions that rationalize their behavior. finally, we impose behavioral economics constraints stemming from rational inattention to characterize the attention span used by the viewers while commenting.",{'inverse reinforcement learning'},0.0,,,,,
675,2815652.0,"the agentscape middleware is designed to support deployment of agent-based applications on internet-scale distributed systems. with the design of agentscape, three dimensions of scalability are considered: size of distributed system, geographical distance between resources, and number of administrative domains.",{'agentscape middleware'},1.0,used-for,agentscape middleware is used to support deployment of agent-based applications on internet-scale distributed systems.,agentscape middleware,support deployment of agent-based applications on internet-scale distributed systems,no
676,14495917.0,"in another, six similarity measure were assessed, this time for trajectory clustering in outdoor surveillance scenes [24] . in chemical databases, al khalifa et.",{'trajectory clustering'},0.0,,,,,
677,7307346.0,"recently, graph embedding has drawn great attention for dimensionality reduction in hyperspectral imagery. for example, locality preserving projection (lpp) utilizes typical euclidean distance in a heat kernel to create an affinity matrix and projects the high-dimensional data into a lower-dimensional space.",{'lpp'},1.0,used-for,lpp is used to create an affinity matrix and projects the high-dimensional data into a lower-dimensional space.,lpp,create an affinity matrix,no
678,7307346.0,"this strategy contains both unsupervised technologies such as principal component analysis (pca) [7] , the maximum-noise-fraction (mnf) transform and supervised approaches like linear discriminate analysis (lda), and local fisher discriminate analysis (lfda)",{'lfda'},1.0,compare,lfda is like lda in that they are both supervised approaches.,lfda,lda,no
679,7307346.0,"[11] , laplace eigenmap (le) [12] , and locality preserving projection (lpp)",{'lpp'},0.0,,,,,
680,7307346.0,"it was noted that the key of ge is to construct a similarity graph that can reflect the critical information in the original data. besides aforementioned algorithms, some popular graph-based algorithms include unsupervised discriminant projection (udp)",{'unsupervised discriminant projection'},1.0,type-of,unsupervised discriminant projection is a type of graph-based algorithm.,unsupervised discriminant projection,graph-based algorithm,no
681,7307346.0,the remainder of this paper is organized as follows. section 2 reviews the graph-embedding dimensionality reduction framework and the similarity graph in slpp and sgda.,{'sgda'},0.0,,,,,
682,11424916.0,"we propose a change detection algorithm based on significance testing using spatiotemporal features. our method shares foundations with video compression techniques [2, 22] .",{'spatiotemporal feature'},0.0,,,,,
683,11424916.0,"first, given a video containing only ordinary changes, we are interested in finding representations where the spatiotemporal features of the ordinary changes can be captured. then, we use the training examples to extract spatiotemporal signatures of the ordinary change patterns.",{'spatiotemporal feature'},0.0,,,,,
684,11424916.0,"the image pixel space is usually not considered suitable for capturing spatiotemporal features. instead, if we can transform a set of frames containing ordinary changes to another representation space where the pixels are decorrelated, we can capture spatiotemporal signatures.",{'spatiotemporal feature'},0.0,,,,,
685,6412047.0,"it provides real-time, reliable delivery of a packet, while considering energy awareness. in earq, a node estimates the energy cost, delay and reliability of a path to the sink node, based only on information from neighboring nodes.",{'earq'},1.0,is-a,"earq is a method in which a node estimates the energy cost, delay and reliability of a path to the sink node, based only on information from neighboring nodes.",earq,method,no
686,10279438.0,"this is what is named a ""temporal expression"" (or a ""date"") in the most popular annotation schemata (timex2 [9] and timex3 [15, 16] ). all the approaches cited above use this kind of approach to calendar information in texts.",{'timex3'},1.0,compare,timex3 is like timex2 in that they are both popular annotation schemata.,timex3,timex2,no
687,18960840.0,"the most common approaches are the linear inverted pendulum model (lipm) and the zero moment point (zmp) method as in [1, 2] . the problem with the lipm method is that it is a non-minimum phase system [3] , which produces a undershoot response to a step input.",{'lipm'},1.0,is-a,"lipm is a non-minimum phase system, which produces a undershoot response to a step input.",lipm,non-minimum phase system,no
688,202783352.0,the response matrix is a quantized version of a low-rank matrix. querying entries of the response matrix can be seen as a so called 1-bit matrix completion problem [12] .,{'low - rank matrix'},0.0,,,,,
689,7337260.0,"the future belongs to techniques that automatically compose many transformations, as it is done in meta-learning based on search in the model space [4] [5] [6] , learning based on generation of novel features [7, 8] , and deep learning [9] approaches. the recursive sbl (rsbl) approach presented here is inspired by recent successes of the deep learning techniques.",{'meta - learning'},0.0,,,,,
690,61322886.0,"chengliang wang et al [6] have proposed a tailored solution approach to the rule extraction problem which consists of prime program slicing, prime domain variable identifying and data analysis, rule validation. program slicing uses call graph approach to transform a large program into a smaller one that contains only statements relevant to the computation of a given function.",{'program slicing'},0.0,,,,,
691,61322886.0,this author [7] has already proposed a business logic model for web service source control management. there is also a detailed account on the cellular pattern generation for a particular web service that proves to be helpful in evaluating impact analysis once we manually generate the cellular pattern for modified web service.,{'web service source control management'},0.0,,,,,
692,11260110.0,"chemogenomics has emerged as a new discipline to systematically establish target relationships based on the structural and biological similarity of their ligands [3, [11] [12] [13] [14] [15] [16] [17] [18] . however, the success of chemogenomics depends on the availability of bioactivity data for the receptors and their associated ligands.",{'bioactivity datum'},0.0,,,,,
693,3426772.0,"non-premium players comprise the vast majority of f2p players leading to highly imbalanced datasets for prediction in mobile games [14, 23, 27, 32] . erefore, a key challenge for mobile game developers is not only to reduce player churn and increase retention, but also to convert players from non-premium to premium players.",{'player churn'},0.0,,,,,
694,2874113.0,"specifically, it significantly reduces estimation error by combing 1 minimization with iterative support detection and limited-support least-squares. while letting the receiver adc running at a speed as low as 1/16 of the speed of the transmitter dac, we simulated various numbers of multipaths and different measurement snrs.",{'iterative support detection'},0.0,,,,,
695,2874113.0,"the field has exploded since the pioneering work by donoho [4] and candes, romberg and tao [5] . the main idea is to encode a sparse signal by taking its ""incoherent"" linear projections and recover the signal through algorithms such as 1 minimization.",{'romberg'},0.0,,,,,
696,2874113.0,"the pilot design preserves the information of high-resolution channel response during aggressive uniform down-sampling, which means that receiver adc can run at a much lower speed. the estimator is tailored for ofdm channel response; in particular, instead of the generic 1 minimization, iterative support detection (isd)",{'iterative support detection'},0.0,,,,,
697,2874113.0,"section iii relates channel estimation to cs and present the proposed pilot design. in section iv, the estimator based on iterative support detection and limited-support least-squares are introduced.",{'iterative support detection'},0.0,,,,,
698,1728330.0,"using publicly available eeg data sets and tangent space mapping (barachant, bonnet, congedo, & jutten, 2012) as a feature extractor, we demonstrate that mpmlda can significantly outperform state-of-the-art multiclass static and adaptive methods. furthermore, efficient learning rates can be achieved using data from different subjects.","{'feature extractor', 'tangent space mapping'}",1.0,based-on,feature extractor is based on tangent space mapping.,feature extractor,tangent space mapping,yes
699,1728330.0,"in a multiclass bci problem, the most common feature extractors are based on supervised data projections, such as one-against-one common spatial patterns (csp) (blankertz, tomioka, lemm, kawanabe, & mller, 2008; dornhege, blankertz, curio, & mller, 2004) or multiclass csp (mcsp) (grosse-wentrup & buss, 2008) .",{'common spatial pattern'},1.0,type-of,common spatial pattern is a type of supervised data projection.,common spatial pattern,supervised data projection,no
700,1728330.0,,,,compare,common spatial pattern is like multiclass csp in that they are both supervised data projections.,common spatial pattern,multiclass csp,no
701,1728330.0,"(grosse-wentrup & buss, 2008) . another interesting approach that has been introduced recently is tangent space mapping (tsm)",{'tangent space mapping'},0.0,,,,,
702,3155983.0,we discuss a kind of stream semantics called punctuated streams. punctuations in a stream mark the end of substreams allowing us to view an infinite stream as a mixture of finite streams.,{'punctuated stream'},1.0,type-of,punctuated stream is a type of stream semantics.,punctuated stream,stream semantics,no
703,18019612.0,"a learning-based binarization method is proposed in [3] for same-type documents. in this paper, the stroke width is used to evaluate the binarization .this approach can be used for only same type of documents.",{'stroke width'},1.0,used-for,stroke width is used to evaluate learning-based binarization method.,stroke width,evaluate learning-based binarization method,no
704,18019612.0,this approach is regarded as knowledge-guided adaptive thresholding. [7] proposed a text segmentation method based on spectral clustering and the histogram of intensity is used for the object of grouping.,{'spectral clustering'},0.0,,,,,
705,118869358.0,"we would like to call the randomizing procedures or maps as random unitary channels (ruc) in terms of quantum channels. there are several methods for the approximate randomizing quantum states, for examples, [4, 5, 8] : we here adapt the procedure of hayden et al.",{'quantum channel'},0.0,,,,,
706,210843074.0,"the tbsjdpt was put forward and used to provide high-precision positions of the sample plot data. the random forests (rf), support vector regression (svr), and multiple linear regression (mlr) algorithms were used to estimate the fsv.",{'random forest'},1.0,is-a,random forest is an algorithm used to estimate fsv.,random forest,algorithm,no
707,210843074.0,,,,compare,random forest is like support vector regression in that they are both algorithms used to estimate fsv.,random forest,support vector regression,no
708,210843074.0,,,,compare,random forest is like multiple linear regression in that they are both algorithms used to estimate fsv.,random forest,multiple linear regression,no
709,210843074.0,"[42] in southern poland affirmed that the sentinel-2 series could accurately delineate tree species (e.g., beech, oak, birch, alder, and larch) with an overall accuracy above 85%. similarly, pandit et al.",{'birch'},1.0,is-a,birch is a tree species that can be accurately delineated by the sentinel-2 series.,birch,tree species,no
710,210843074.0,,,,compare,birch is like oak in that they are both tree species that can be accurately delineated by the sentinel-2 series.,birch,oak,no
711,210843074.0,,,,compare,birch is like beech in that they are both tree species that can be accurately delineated by the sentinel-2 series.,birch,beech,no
712,210843074.0,,,,compare,birch is like alder in that they are both tree species that can be accurately delineated by the sentinel-2 series.,birch,alder,no
713,210843074.0,,,,compare,birch is like larch in that they are both tree species that can be accurately delineated by the sentinel-2 series.,birch,larch,no
714,210843074.0,"using the random forests (rf) regression algorithm, chrysafis et al. [68] estimated the fsv based on sentinel-2 image, which provided relatively better results (r 2 = 0.63, rmse = 63.11 m 3 ha -1 ) than landsat-8 oli images (r 2 = 0.62,",{'random forest'},1.0,type-of,random forest is a type of regression algorithm used to estimate the fsv based on sentinel-2 image.,random forest,regression algorithm,no
715,4718973.0,this feature of relying the mobility functions on the network entities would indeed eases the deployment of mobility solutions. proxy mobile ipv6 (pmipv6) is considered as a promising network-based mobility management protocol in the next-generation mobile network.,{'proxy mobile ipv6'},1.0,is-a,proxy mobile ipv6 is a promising network-based mobility management protocol in the next-generation mobile network.,proxy mobile ipv6,promising network-based mobility management protocol in the next-generation mobile network,no
716,4718973.0,"host based mobility management protocols including mipv6 [5] , hmipv6 [6] , and fmipv6 [7] , involve the mns in the mobility process and generally introduce a significant network overhead in terms of handoff latency, packet loss, and signaling cost when mns change their point of attachment very frequently.",{'hmipv6'},1.0,is-a,"hmipv6 is a host based mobility management protocol that involves the mns in the mobility process and introduces a significant network overhead in terms of handoff latency, packet loss, and signaling cost when mns change their point of attachment very frequently.",hmipv6,host based mobility management protocol,no
717,4718973.0,,,,compare,hmipv6 is like mipv6 in that they are both host based mobility management protocols.,hmipv6,mipv6,no
718,4718973.0,,,,compare,hmipv6 is like fmipv6 in that they are both host based mobility management protocols.,hmipv6,fmipv6,no
719,16142765.0,"an adaptive microphone array self-calibration method is adopted to overcome the problem of microphone mismatch. for acoustic modeling, neural network acoustic models including maxout neural network [4] and long short term memory with project layers (lstmp)",{'acoustic modeling'},0.0,,,,,
720,16142765.0,"4-gram language model with kneser-ney smoothing is adopted in the first-pass decoding. a language model based on jointly trained recurrent neural network and maximum entropy models (rnnme) is adopted for the second-pass rescoring [14, 15] .",{'language model'},1.0,based-on,language model is based on jointly trained recurrent neural network and maximum entropy models (rnnme) and is used for second-pass rescoring.,language model,jointly trained recurrent neural network and maximum entropy models,no
721,16142765.0,"the msc-based masking is used to suppress the diffused noise, while the pdm-based masking is used to suppress the directional interference not coming from the target direction. the time-frequency masking is performed by filtering the output subband signal of the mvdr beamformer with the said maskers.",{'time - frequency masking'},1.0,is-a,time-frequency masking is a method performed by filtering the output subband signal of the mvdr beamformer with the said maskers.,time-frequency masking,method,no
722,14380735.0,an important vision application is in the domain of object detection and tracking. techniques based on mixture modeling of background remain most popular,{'object detection'},0.0,,,,,
723,1369074.0,"to overcome the limitations of of there is a growing focus on feature based methods, such as sift (lowe 2004) . such methods assume that feature points can be reliably detected and matched in both the image and the template so that there are enough potent matches to estimate a global transformation model, perhaps using ransac (fischler and bolles 1981) .",{'ransac'},0.0,,,,,
724,199490670.0,"first, we derive the video request probability by taking into account video popularity, user preference and the characteristic of video representations. second, based on the acquired request probability, we formulate a cache placement problem with the objective to maximize the cache hit ratio subject to the storage capacity constraints.",{'video representation'},0.0,,,,,
725,199490670.0,xvhu v frqwhqw suhihuhqfh and video representation to improve the cache hit rate of all the users under the mec server.,{'video representation'},0.0,,,,,
726,16085684.0,we also investigate query modeling based on parsimonious language model for building the topic of the query patent. furthermore we utilize the knowledge embedded in ipc classes in our model.,{'parsimonious language model'},0.0,,,,,
727,16085684.0,clef-ip is another important evaluation platform for comparing performance of patent retrieval systems. clef-ip has been running since 2009 and participants have explored standard information retrieval approaches in this domain.,{'clef - ip'},1.0,is-a,clef-ip is an evaluation platform for comparing performance of patent retrieval systems.,clef-ip,evaluation platform for comparing performance of patent retrieval systems,no
728,17062634.0,only passive replication style was implemented since active replication style requires group communication mechanisms that are not supported in the used orb. another approach for corba components replication is studied in [10] .,{'orb'},0.0,,,,,
729,2813337.0,"these networks which allow the incorporation of uncertainty into the inter-gene relationships, are essentially probabilistic generalizations of the standard boolean networks introduced by kauffman [2] . given a probabilistic boolean network, the transition from one state to the next takes place in accordance with certain transition probabilities.",{'probabilistic boolean network'},0.0,,,,,
730,2813337.0,"in section 2, we review the control problem for pbns and recall the solution for the perfect state information case presented in [5] . in section 3, we consider the imperfect information case and present the solution for this problem.",{'pbns'},0.0,,,,,
731,4030281.0,"ponte, h. et al. designed a triangulation measurement sensor that adapts to the size and power of the snake robot using a laser and a black and white camera; the robot can scan an environmental color 3d point cloud when the head is raised, with the robot's posture estimated using the kinematics equation and imu data [16] . ohno, k. et al.",{'ponte'},0.0,,,,,
732,90980578.0,"these have the capacity for phenotyping plants in the natural environment and in a situation close to commercial crop production, and therefore of direct relevance to breeders and agronomists. an additional complexity in this situation is the vector system for transportation of sensing and measuring equipment.",{'vector system'},0.0,,,,,
733,53766533.0,"many different techniques to tackle the slam problem have been presented. there are different approaches to the problem like extended kalman filter slam (ekf), sparse extended information filter (seif), extended information form (eif), fastslam, graphslam.",{'fastslam'},1.0,is-a,fastslam is a technique presented to tackle the slam problem.,fastslam,technique,no
734,53766533.0,,,,compare,fastslam is like extended kalman filter slam in that they are both techniques presented to tackle the slam problem.,fastslam,extended kalman filter slam,no
735,53766533.0,,,,compare,fastslam is like sparse extended information filter in that they are both techniques presented to tackle the slam problem.,fastslam,sparse extended information filter,no
736,53766533.0,,,,compare,fastslam is like extended information form in that they are both techniques presented to tackle the slam problem.,fastslam,extended information form,no
737,53766533.0,,,,compare,fastslam is like graphslam in that they are both techniques presented to tackle the slam problem.,fastslam,graphslam,no
738,53766533.0,this research uses two such common evaluation metrics on the results obtained from popular slam algorithms. this paper utilizes the metrics for evaluation proposed in [4] to evaluate the performance of two popular slam methods: rgb-d slam [8] and rtabmap [9] .,"{'rgb - d slam', 'rtabmap'}",1.0,compare,rgb-d slam is like rtabmap in that they are both popular slam methods.,rgb-d slam,rtabmap,yes
739,53766533.0,,,,is-a,rgb-d slam is a popular slam method. ,rgb-d slam,popular slam method,no
740,53766533.0,,,,is-a,rtabmap is a popular slam method. ,rtabmap,popular slam method,no
741,1540637.0,"[1] . it was shown in [1] that for the multicast networks, the min-cut bound can be achieved using network coding.",{'network coding'},1.0,used-for,network coding is used to achieve the min-cut bound for multicast networks.,network coding,achieve the min-cut bound for multicast networks,no
742,1540637.0,"in [6] , it was shown that the notion of scalar linear solvability of networks can be captured by matroids. specifically, it was shown that a network is scalar linearly solvable only if it is a matroidal network associated with a representable matroid over a finite field.",{'matroidal network'},0.0,,,,,
743,1540637.0,"to show that for any positive integer m  2, there exists a network which has an m dimensional vector linear solution but has no vector linear solution for a message dimension less than m, either one has to give construction of such a network, or equivalently, one can construct a discrete polymatroid such that it is representable if the rank of its every element is allowed to be less than or equal to m, but not representable if the rank of its every element is strictly lesser than m [8] . to the best of our knowledge, neither such a network has been presented in the literature nor it has been shown that for every integer m  2, there do not exist such networks; likewise in the area of matroid theory, no discrete polymatroid having the above mentioned property has been reported nor it has been shown that such a discrete polymatroid does not exist.",{'matroid theory'},0.0,,,,,
744,1540637.0,"the organization of the rest of the letter is as follows. in section ii, we present the formal definitions related to network coding.",{'network coding'},0.0,,,,,
745,18161811.0,"in this paper, we improve cluster stability by the addition of one pause time-based weighting parameter to a well-known weighted clustering algorithm (wca). the wca uses current mobility index of mobile nodes to predict the stability of the network.",{'wca'},1.0,used-for,wca is used to predict the stability of the network.,wca,predict the stability of the network,no
746,18161811.0,"this is also termed as multihop cellular networks [3] [4] [5] . embedded sensors within cell phones create a multihop cellular sensor network (mcsn) scenario [6, 7] .",{'multihop cellular network'},0.0,,,,,
747,18161811.0,"second, cell phone movements follow well-understood human mobility patterns. given the distribution of human mobility patterns, it is possible to approach clustering more intelligently and possibly discover a better clustering methodology for mcsn environments.",{'human mobility pattern'},0.0,,,,,
748,211060143.0,"since stereoscopic image features are still multi-dimensional vectors, which are similar to 2d image, so the related indexing algorithms are often used for stereoscopic vision feature. in some studies, indexing methods are grouped into four classes, including space partitioning, clustering, hashing, and product quantization [10] .",{'product quantization'},1.0,is-a,product quantization is a class into which indexing methods are grouped.,product quantization,class,no
749,211060143.0,,,,compare,product quantization is like space partitioning in that they are both classes into which indexing methods are grouped.,product quantization,space partitioning,no
750,211060143.0,,,,compare,product quantization is like clustering in that they are both classes into which indexing methods are grouped.,product quantization,clustering,no
751,211060143.0,,,,compare,product quantization is like hashing in that they are both classes into which indexing methods are grouped.,product quantization,hashing,no
752,67788211.0,"yet, rf adversarial examples (adexs) with minimal waveform perturbations can cause drastic, targeted misclassification results, particularly against spectrum sensing/survey applications (e.g. bpsk is mistaken for 8-psk). our research on deep learning adexs and proposed defense mechanisms are rf-centric, and incorporate physicalworld, over-the-air (ota) effects.",{'adversarial example'},0.0,,,,,
753,13185193.0,"many existing systems, e.g., araneus [1] , ariadne [20] , tsimmis [11] , just to name a few, have attempted to integrate heterogeneous web sources under a common interface. unfortunately, queries to such systems must be formulated in sql, datalog, or some similar formal language, which render them inaccessible to the average user.",{'tsimmis'},1.0,is-a,tsimmis is a system that attempts to integrate heterogeneous web sources under a common interface.,tsimmis,system,no
754,13185193.0,,,,compare,tsimmis is like araneus in that they are both systems that attempt to integrate heterogeneous web sources under a common interface.,tsimmis,araneus,no
755,13185193.0,,,,compare,tsimmis is like ariadne in that they are both systems that attempt to integrate heterogeneous web sources under a common interface.,tsimmis,ariadne,no
756,14903169.0,"this system can run online via web services such that it can be accessed from any programming environment and the architecture allows each tool to be individually trained. each task, except for discourse parsing, multidps's component tools combines machine learning techniques with heuristics to learn from a manually created corpus (a gold corpus of discourse trees is very difficult to obtain due to the complexity of the task).",{'discourse parsing'},0.0,,,,,
757,3350909.0,"it should be stressed that results (iii) and (iv) came deeply unexpected to the authors. first, this is because the assumptions are already satisfied when k is induced by a system model as powerful as well-structured transition systems or higher-order recursion schemes.",{'high - order recursion scheme'},0.0,,,,,
758,16074470.0,"as a metric for recognizing an underutilized portion of the primary spectrum, here, we consider a threshold on the acceptable level of the imposed interference at the primary receiver caused by the operation of the secondary users. therefore, an under utilized portion of spectrum is defined as a frequency band in which the received interference level is below the interference threshold.",{'secondary user'},0.0,,,,,
759,2783664.0,"however, these interfaces are not adequate for service composition, since one of the assumptions is that there is usually no single service that fully matches a request and therefore several services need to be combined instead. indeed, during automatic composition, an exploratory search is usually required to guess which relevant services can be selected at each step.",{'exploratory search'},1.0,used-for,exploratory search is used to guess which relevant services can be selected at each step during automatic service composition.,exploratory search,guess which relevant services can be selected at each step during automatic service composition,no
760,14076913.0,"with quasi-boolean logics, it is possible to combine different viewpoints into a single system without first resolving their inconsistencies or assigning priorities to them [ec01] . for example, if we are interested in combining two partial viewpoints, each specified using the logic , we can use the product logic",{'product logic'},1.0,used-for,"product logic is used for combining two partial viewpoints, each specified using the logic.",product logic,combining two partial viewpoints,no
761,3197370.0,"however, no determinations of these processing issues have been made in the area of audiovisual speech perception and few have been made in general studies of multimodal processing. research involving non-speech multisensory stimuli in detection tasks has shown evidence for early bimodal interactions (see barutchu et al., 2009; barutchu et al., 2010 for studies using children and adults).",{'detection task'},0.0,,,,,
762,26462466.0,compute intense parts can be realized in the fpga and the control intense parts can be implemented in the cpu. garp was one of the first approaches following this scheme [4] .,{'garp'},0.0,,,,,
763,7966572.0,we used a slightly modified version of the 3.0.1 version of the application where the language model can be turned off. two screenshots of the application are shown in figure 1 .,{'language model'},0.0,,,,,
764,27564951.0,"several classification strategies and features related with the spectrum, prosody and phase have been tested separately and further combined by using different fusion techniques, such as early fusion by means of multi-feature vectors, late fusion of the standalone classifier scores and label fusion via weighted voting. the obtained results show that the applied fusion methods improve the performance of the standalone detectors and provide systems capable of outperforming the baseline systems in terms of uar.","{'late fusion', 'label fusion'}",1.0,is-a,late fusion is a fusion technique used to combine prosody and phase which improves the performance of the standalone detectors and provide systems capable of outperforming the baseline systems in terms of uar.,late fusion,fusion technique,no
765,27564951.0,,,,is-a,label fusion is a fusion technique used to combine prosody and phase which improves the performance of the standalone detectors and provide systems capable of outperforming the baseline systems in terms of uar.,label fusion,fusion technique,no
766,27564951.0,,,,compare,late fusion is like label fusion in that they are both fusion techniques used to combine prosody and phase which improves the performance of the standalone detectors and provide systems capable of outperforming the baseline systems in terms of uar.,late fusion,label fusion,yes
767,27564951.0,,,,compare,label fusion is like early fusion in that they are both fusion techniques used to combine prosody and phase which improves the performance of the standalone detectors and provide systems capable of outperforming the baseline systems in terms of uar.,label fusion,early fusion,no
768,27564951.0,,,,compare,late fusion is like early fusion in that they are both fusion techniques used to combine prosody and phase which improves the performance of the standalone detectors and provide systems capable of outperforming the baseline systems in terms of uar.,late fusion,early fusion,no
769,6663664.0,"our own approach has its roots in earlier work on default logic [13, 14, 17] . the usage of rule-oriented dependency graphs is common to [4, 3, 9] .",{'default logic'},0.0,,,,,
770,729163.0,word sense induction is an unsupervised task to find and characterize different senses of polysemous words. this work investigates two unsupervised approaches that focus on using distributional word statistics to cluster the contextual information of the target words using two different algorithms involving latent dirichlet allocation and spectral clustering.,"{'latent dirichlet allocation', 'spectral clustering'}",0.0,,,,,
771,729163.0,"wsi algorithms can also be used to model the evolution of the senses of a word with time and hence can be much easier to maintain than existing fixed sense inventories like wordnet (miller, 1995) , ontonotes (hovy et al., 2006) etc. automatic sense identification systems also have the potential to generalize well to large amounts of diverse data and hence be useful in various difficult domain independent tasks such as machine translation and information retrieval.",{'machine translation'},1.0,is-a,machine translation is a difficult domain independent task with large amounts of diverse data.,machine translation,difficult domain independent task,no
772,729163.0,,,,compare,machine translation is like information retrieval in that they are both difficult domain independent tasks with large amounts of diverse data.,machine translation,information retrieval,no
773,729163.0,"(2012) proposed bayesian wsi systems which cluster the instances by applying latent dirichlet allocation (lda) (blei et al., 2003) , hierarchical dirichlet processes (hdp) (teh et al., 2006) etc. wherein each occurence of a target word is represented as a 'document' and its surrounding context as the 'observable content'.",{'latent dirichlet allocation'},0.0,,,,,
774,10461982.0,"several new techniques are presented in our algorithm: initially, the court lines are detected and reconstructed. based on the court model, an adaptive search window is designed for locating the minimum region containing a player figure.",{'court model'},0.0,,,,,
775,13756105.0,"the occupancy-regulated extension (ore) algorithm introduced in [15] , relies on the idea of occupancy, i.e., the positions (or anchors) that player can occupy during gameplay; anchors are thus used to iteratively expand the existing content by merging human-authored chunks. sorenson and pasquier [16] proposed a generative system for 2d platformer games in which creation process was driven by generic models of challenge-based fun based on existing theories of game design.",{'occupancy - regulate extension'},1.0,is-a,"occupancy-regulated extension is an algorithm which relies on the idea of occupancy, i.e., the positions (or anchors) that player can occupy during gameplay; anchors are thus used to iteratively expand the existing content by merging human-authored chunks.",occupancy-regulated extension,algorithm,
776,13756105.0,"[19] presented a multi-population genetic algorithm for generating levels by evolving four elements (terrain, enemies, coins and blocks), each one with its own encoding, population, and fitness function; at the end of the evolution the best four elements are combined to build the level. non-negative matrix factorisation (nmf)",{'nmf'},0.0,,,,,
777,17219136.0,"we studied three methods to improve identification of difficult small classes by balancing imbalanced class distribution with data reduction. the new method, neighborhood cleaning rule (ncl), outperformed simple random and one-sided selection methods in experiments with ten data sets.",{'imbalanced class distribution'},0.0,,,,,
778,17219136.0,"the new method, neighborhood cleaning rule (ncl), outperformed simple random and one-sided selection methods in experiments with ten data sets. all reduction methods improved identification of small classes (20-30%), but the differences were insignificant.",{'neighborhood cleaning rule'},1.0,is-a,neighborhood cleaning rule is a method which outperformed simple random and one-sided selection methods.,neighborhood cleaning rule,method,no
779,4012904.0,"consequently, robot controllers for assembly domains are presently engineered to solve a particular task, and cannot easily handle variations in the product or environment. reinforcement learning (rl) is a promising approach for autonomously acquiring robot skills that involve contact-rich dynamics.",{'reinforcement learning'},1.0,is-a,reinforcement learning is a promising approach for autonomously acquiring robot skills that involve contact-rich dynamics.,reinforcement learning,promising approach for autonomously acquiring robot skills that involve contact-rich dynamics,no
780,4012904.0,"prominent approaches for autonomous manipulation are based on either motion planning [3] , [4] , [5] , or reinforcement learning (rl) [6] , [7] , [8] .",{'reinforcement learning'},1.0,compare,reinforcement learning is like motion planning in that they are both bases for approaches for autonomous manipulation.,reinforcement learning,motion planning,no
781,4012904.0,,,,is-a,reinforcement learning is a basis for approaches for autonomous manipulation.,reinforcement learning,basis for approaches for autonomous manipulation,no
782,4012904.0,"the recent work of duan et al. [23] proposed an imitation learning method that trains a nn policy to take as input a reference demonstration, using soft attention.","{'soft attention', 'imitation learning method'}",1.0,used-for,"imitation learning method is used to train a nn policy to take as input a reference demonstration, using soft attention.",imitation learning method,train a nn policy to take as input a reference demonstration,no
783,4012904.0,"designing reward functions for rl is a difficult task and often approached using additional human feedback, e.g. inverse rl and preference based rl [25] , [26] , [27] , [28] , [29] . in contrast, we exploit prior geometric information about the task for reward design.",{'reward function'},0.0,,,,,
784,18222947.0,"new classes of commercial systems may offer some flexibility in this regard [15] , although they are not readily available in testbeds at this time. finally, heller et al. use a model based approach to assess data center routing methods with openflow in [11] .",{'openflow'},0.0,,,,,
785,199668943.0,"the inclusion of metric learning to the baseline pose estimation framework improves the performance by 21% when 3d supervision is limited. in addition, we make use of a person-identity based adversarial loss as additional weak supervision to outperform state-of-the-art whilst using a much smaller network.",{'3d supervision'},0.0,,,,,
786,199668943.0,"therefore, it can be easily extended to train with further un-annotated in-the-wild data. we seek motivation from a recent work in [22] , where image generation in different views via a geometry-aware latent space is used to improve pose-estimation under limited 3d supervision.",{'image generation'},1.0,used-for,image generation is used to improve pose-estimation under limited 3d supervision.,image generation,improve pose-estimation under limited 3d supervision,no
787,199668943.0,"we show that weak supervision in learning the embedding ensures that our model's performance degrades gracefully when 3d supervision is progressively reduced. additionally, we eliminate the subject-specific appearance information from our latent embedding with the help of an adversarial mechanism which leads to further improvements and outperforms the current state-of-the-art [22] .",{'3d supervision'},0.0,,,,,
788,199668943.0,"the formulation of our loss function leads to a view-invariant embedding, and in sec. 5, we demonstrate the richness of our learned embedding to capture human pose structure invariant to viewpoint by way of carefully designed pose retrieval experiments and establish novel benchmarks on human3.6m and mpi-inf-3dhp to facilitate future research.",{'human3.6'},0.0,,,,,
789,67855549.0,"additionally, model-learning is of interest to the reinforcement learning community because of its data-efficiency compared to model-free methods [10] and potential for transfer during continual learning [11] , [12] . hence, learning dynamics models using data, or simply fine-tuning models crafted from prior knowledge, has been approached in several ways.",{'continual learning'},0.0,,,,,
790,27260892.0,"however, their tool operated in the rgb colour space by laying out incremental slices of the rgb colour cube. this layout scheme made colour selection difficult, because the valid colours were dispersed throughout the colour selection area.",{'colour selection'},0.0,,,,,
791,208003485.0,"[33] proposed a rim model to estimate the link irregularity; and based on the model, the author investigated the impact of radio irregularity on mac, routing, and topology control; it indicated that irregularity has larger impact on the routing layer and topology control compared with the mac layer. reijers et al.",{'radio irregularity'},0.0,,,,,
792,10214379.0,"recent work by cs and castelluccia uses a very efficient, additively-homomorphic stream cipher but can also only compute sums. their work does, however, go an additional step and guarantees differential privacy, a much stronger notion of privacy than the one we consider here.",{'differential privacy'},0.0,,,,,
793,3525670.0,"inspired by experimental data, we assume that re-caching is not motivated by a deliberate effort to safeguard specific caches from theft, but by a general desire to cache more. this desire is brought on by stress, which is determined by the presence and dominance of onlookers, and by unsuccessful recovery attempts.",{'onlooker'},0.0,,,,,
794,3525670.0,"our results show that the 'virtual bird' acts as the real birds did; its re-caching reflects whether it has been watched, how dominant its onlooker was, and how close to that onlooker it has cached. this happens even though it cannot attribute mental states, and it has only a single behavioral rule assumed to be previously learned.",{'onlooker'},0.0,,,,,
795,3525670.0,"when caching, corvids bury most of their items far away from onlookers, and behind barriers [4, 11, 12] . furthermore, scrub jays often re-cache their worms later, when they are in private, if they were forced to cache in the presence of others [8, 9, 10, 11, 12] .",{'onlooker'},0.0,,,,,
796,3525670.0,"a scrub jay might infer that other birds intend to steal its worms, and that if others see it caching they will know where its worms are. furthermore, a scrub jay could realize that caching far away from onlookers makes it difficult for them to see its caches, and that re-caching when alone will ensure that they no longer know the locations of its items.",{'onlooker'},0.0,,,,,
797,3525670.0,"to learn this, the birds would have to remember the distances between cache sites and onlookers, and also relate these distances to pilfering rates. this seems cognitively complex, especially for scrub jays in small aviaries [20] , where the effect of distance is likely to be small, and thus, difficult to detect.",{'onlooker'},0.0,,,,,
798,3525670.0,"the first compares caching in front of a conspecific to caching alone, as done in an experiment by emery and clayton [8] ; the second concerns the effects of distance and the dominance of onlookers, as tested by dally, emery and clayton [12] . we show that in both cases, our 'virtual bird' acts as the real birds did.",{'onlooker'},0.0,,,,,
799,11202923.0,"in the report, the characterized devices are completely identical structure except for the dielectrics between the pt and the gan. however, the hydrogen responses are totally different.",{'gan'},0.0,,,,,
800,23253014.0,"in this paper, we propose a depth-based perception pipeline that estimates the position and velocity of people in the environment and categorizes them according to the mobility aids they use: pedestrian, person in wheelchair, person in a wheelchair with a person pushing them, person with crutches and person using a walker. we present a fast region proposal method that feeds a region-based convolutional network (fast r-cnn [1]).",{'fast r - cnn'},1.0,is-a,fast r-cnn is a fast region proposal method that feeds a region-based convolutional network.,fast r-cnn,fast region proposal method,no
801,23253014.0,"[2] address the problem of multi person tracking and detection using a stereo vision system mounted on a mobile platform, integrating visual odometry, depth estimation and pedestrian detection for improved perception. choi et al.",{'pedestrian detection'},0.0,,,,,
802,23253014.0,"[7] , which increases the test-time speed. recently redmon and farhadi [8] proposed an approach that formulates object detection as a regression problem.",{'object detection'},0.0,,,,,
803,13407244.0,genn performs both variable selection and statistical modelling without the computational burden of exhaustively searching all possible variable combinations. genn uses an evolutionary computation algorithm (grammatical evolution) to build neural networks (nn).,{'grammatical evolution'},1.0,is-a,grammatical evolution is an evolutionary computation algorithm used by genn to build neural networks.,grammatical evolution,evolutionary computation algorithm,no
804,54515139.0,"these ellipsoids are computed with linear matrix inequalities (lmis) that guarantee stabilisation with input saturation and persistent perturbations. in particular, two kinds of inescapable ellipsoids are computed when solving a multiobjective optimization problem: the maximum volume inescapable ellipsoids contained inside the validity domain of the ts fuzzy model and the smallest inescapable ellipsoids which guarantee a minimum -norm (upper bound of the 1-norm) of the perturbed system.",{'multiobjective optimization problem'},0.0,,,,,
805,54515139.0,", z p (t) are the premise variables, m ij signifies the degree of membership of the variable z j (t) to rule i (j = 1, 2, . . . , p), u(t)  r nu is the control input vector,   r n  is the disturbance vector, y(t)",{'premise variable'},0.0,,,,,
806,55176461.0,"various image processing tools were implemented using erdas 9.2, arcgis 10.4.1, and envi programs to conduct spatiotemporal change detection over these two images such as band selection, corrections, subset, classification, recoding, accuracy assessment, and change detection analysis. image classification revealed that there are five significant land use/land cover types, including forest, flooded forest, swamp, water, and other lands (i.e. agriculture, sand, roads, settlement, and open areas).",{'image classification'},0.0,,,,,
807,9633354.0,"to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. we present a real-time event detection and filtering system for sports video in this demo.",{'real - time event detection'},0.0,,,,,
808,14781356.0,"the proposed qircc can be dynamically adapted to match any given inner code using exit charts, hence achieving a performance close to the hashing bound. it is demonstrated that our qircc-based optimized design is capable of operating within 0.4 db of the noise limit.",{'exit chart'},0.0,,,,,
809,9651335.0,"explicit mpc [4] [5] [6] 37] might offer an appealing solution as it precomputes a piecewise affine state feedback for discrete-time systems off-line. still, the explicit control law often leads to a complex description consisting of many affine feedbacks, which also cannot realize the high sampling rates typically needed for motion systems of considerable size, although recent research is focussed on decreasing the implementation complexity of mpc, see for instance [15, 16, 20, 23, 26] and the references therein.",{'affine feedback'},0.0,,,,,
810,11387463.0,"in mt, one can intuitively interpret this attention mechanism as inducing an alignment between source and target sentences, as first proposed by bahdanau et al. (2015) .",{'attention mechanism'},1.0,used-for,attention mechanism is used for inducing an alignment between source and target sentences in mt.,attention mechanism,inducing an alignment between source and target sentences in mt,no
811,11387463.0,"attention-based encoder-decoder models for mt have been actively investigated in recent years. some researchers have studied how to improve attention mechanisms (luong et al., 2015;",{'attention mechanism'},0.0,,,,,
812,11387463.0,data huang et al. (2016) use object detections obtained with the rcnn of girshick et al.,{'object detection'},0.0,,,,,
813,208139185.0,"the bijective bwt (bbwt) is a bijective variant of it. although it is known that the bwt can be constructed in linear time for integer alphabets by using a linear time suffix array construction algorithm, it was up to now only conjectured that the bbwt can also be constructed in linear time.",{'bijective variant'},0.0,,,,,
814,208139185.0,"in this article, we present a linear time algorithm computing the bbwt. the main idea is to adapt the suffix array construction algorithm sais [18] to compute the circular suffix array of the lyndon factors.",{'suffix array construction algorithm'},1.0,used-for,suffix array construction algorithm is used to compute the circular suffix array of the lyndon factors.,suffix array construction algorithm,compute the circular suffix array of the lyndon factors,no
815,4014687.0,"also, similarly to the standard closed-loop case (forssell and ljung, 1999 ), a noise model that is in the model set must   this work was supported by the swedish research council under contracts 2015-05285 and 2016-06079.k be estimated to obtain consistent estimates; for this reason, two-stage methods (van den hof and schrama, 1993) are also considered in the aforementioned works, which do not have this requirement.",{'ljung'},0.0,,,,,
816,198145748.0,"in this paper, a new algorithm is proposed to design reliable dna codes. this algorithm combines the bat algorithm and pso algorithm.","{'bat algorithm', 'pso algorithm'}",1.0,compare,bat algorithm is like pso algorithm in that they are both used in an algorithm proposed to design reliable dna codes.,bat algorithm,pso algorithm,yes
817,198145748.0,"thus, it is called bpson for short. a bat algorithm is used to overcome pso fall into the local optimal solution and enhance global search ability.",{'bat algorithm'},1.0,used-for,bat algorithm is used to overcome pso fall into the local optimal solution and enhance global search ability,bat algorithm,overcome pso fall into the local optimal solution,no
818,198145748.0,"arita combines similarity, h-measure, hamming distance, and gc content as constraints of genetic algorithms [22] . shin proposed a multi-objective evolutionary algorithm based on six constraints and improved the algorithm [23] , [24] .",{'multi - objective evolutionary algorithm'},1.0,compare,multi-objective evolutionary algorithm is like arita algorithm except that it is based on six constraints.,multi-objective evolutionary algorithm,arita algorithm,no
819,198145748.0,"other research work also considered different constraints, but they eventually turned the multiobjective problem into a single-objective problem by adding weights. thus, xu et al.",{'multiobjective problem'},1.0,is-a,multiobjective problem is a problem that was eventually turned into a single-objective problem by adding weights. ,multiobjective problem,problem,no
820,198145748.0,"in this paper, a hybrid bat algorithm based on fast nondominated sorting was proposed to optimize dna codes. the bat algorithm is a new bio-heuristic intelligent optimization algorithm proposed by yang [31] .",{'bat algorithm'},1.0,based-on,bat algorithm is based on fast nondominated sorting and was proposed to optimize dna codes.,bat algorithm,fast nondominated sorting,no
821,198145748.0,,,,is-a,bat algorithm is a new bio-heuristic intelligent optimization algorithm proposed by yang.,bat algorithm,new bio-heuristic intelligent optimization algorithm proposed by yang,no
822,198145748.0,"at the same time, the bat individual coordinates the exploration and mining of the algorithm by adjusting the variation of the acoustic pulse frequency and the impulse loudness, which enhances the search ability and robustness of the algorithm. since its introduction, the bat algorithm has attracted the attention of many scholars.",{'bat algorithm'},0.0,,,,,
823,16025427.0,i discuss some practical modifications of multinet for the purpose of manual annotation. multinet elements are compared to the elements of the deep linguistic layer of pdt.,{'multinet'},0.0,,,,,
824,62196833.0,"abstract-this paper conducts an empirical investigation on the errors in english-chinese translation memories in computer-aided translation (cat) and shows that the intention of error occurrence and the statistical difference in three common types: fixed expressions, omissions and symbols. it reveals that the translation errors in sentence pairs of translation memories reach as high as over 14%, and among all the errors in target texts punctuation errors account for nearly 46%.",{'sentence pair'},0.0,,,,,
825,62196833.0,"it is distinct from both traditional translation and machine translation (james & anastasia, 2000) . wherein human translators play key parts and the computer serves as a powerful assistant to improve translation efficiency as well as quality.",{'machine translation'},0.0,,,,,
826,13756046.0,"specifically, cd-cnn features in decomposing the mobile data into location domain and communication domain, and adopts a joint learning framework that combines two convolutional neural networks with a feature balancing scheme. moreover, cd-cnn employs a three-step algorithm for training, in which the co-training step is of great value to partially supervised cross-domain learning.",{'convolutional neural network'},0.0,,,,,
827,18228350.0,"sentence compression has historically been addressed in a generative framework, where transformation rules are learnt from parsed corpora of sentences aligned with manually compressed versions, using ideas adapted from statistical machine translation. the compression rules learnt are typically syntactic tree-to-tree transformations (knight and marcu, 2000; galley and mckeown, 2007; riezler et al., 2003; cohn and lapata, 2009; nomoto, 2008) of some variety.",{'statistical machine translation'},0.0,,,,,
828,18228350.0,"(smith and eisner, 2006) and integer linear programming. quasi-synchronous grammars aim to relax the isomorphism constraints of synchronous grammars, in this case by generating a loose alignment between parse trees.","{'quasi - synchronous grammar', 'synchronous grammar'}",1.0,used-for,quasi-synchronous grammars are used to relax the isomorphism constraints of synchronous grammars by generating a loose alignment between parse trees.,quasi-synchronous grammars,relax the isomorphism constraints of synchronous grammars,no
829,13121936.0,"the projected processing requirements of an lte ue on the sb3500 are presented with the expected number of cores needed for the data rates analyzed. the down-sampling filter used for the initial synchronization and for the fine synchronization, fft block, channel estimation for each reference symbol, mimo detector and the crc block are included in this analysis.",{'mimo detector'},0.0,,,,,
830,5619726.0,"[3] , the theory of planned behavior (tpb) [4] , the technology acceptance model (tam)",{'plan behavior'},0.0,,,,,
831,5619726.0,[6] and the unified theory of acceptance and use of technology (utaut) [7] .,"{'utaut', 'unified theory'}",0.0,,,,,
832,5619726.0,"these studies provide useful insights and implications for understanding an individual's intention of using e-government services. they also have identified a number of factors that determine the adoption of e-government services, such as usefulness, ease of use, perceived risk, trustworthiness, compatibility, external influence, internet safety, interpersonal influence, relative advantage, image and facilitating conditions, see for example [8] , [9] , [10] .",{'individual intention'},0.0,,,,,
833,5619726.0,"to date, there has been little research exploring factors that affect the adoption of e-government services by citizens in developing countries, especially in the arab world [23] . despite the fact that the researchers have investigated factors that determine the adoption of e-government services by adapting the unified theory of acceptance and use of technology (utaut) model [24] , there has been little research that has explored other factors that might influence the take-up of government online services in developing countries, such as kuwait.",{'unified theory'},0.0,,,,,
834,208909916.0,"the corpus is based on the allen institute for artificial intelligence diagrams (ai2d) dataset, a collection of diagrams with crowd-sourced descriptions, which was originally developed for computational tasks such as automatic diagram understanding and visual question answering. building on the segmentation of diagram layouts in ai2d, the ai2d-rst corpus presents a new multi-layer annotation schema that provides a rich description of their multimodal structure.",{'visual question'},0.0,,,,,
835,208909916.0,"building on the segmentation of diagram layouts in ai2d, the ai2d-rst corpus presents a new multi-layer annotation schema that provides a rich description of their multimodal structure. annotated by trained experts, the layers describe (1) the grouping of diagram elements into perceptual units, (2) the connections set up by diagrammatic elements such as arrows and lines, and (3) the discourse relations between diagram elements, which are described using rhetorical structure theory (rst).",{'rhetorical structure theory'},1.0,used-for,rhetorical structure theory is used to describe the discourse relations between diagram elements of a multi-layer annotation schema.,rhetorical structure theory,describe the discourse relations between diagram elements of a multi-layer annotation schema,no
836,32472717.0,"brin and page (1998) , the founders of the gigantic search engine google at stanford university, devised a creative way of ranking the importance of each web page by taking into account both the importance of the web pages linked to the web page and the number of links the web page receives. this underlying technique called pagerank is a uniquely democratic system of leveraging the hyperlink structure of the web pages.",{'pagerank'},1.0,is-a,pagerank is a uniquely democratic system of leveraging the hyperlink structure of the web pages.,pagerank,uniquely democratic system of leveraging the hyperlink structure of the web pages,no
837,32472717.0,,,,used-for,pagerank is used for ranking the importance of each web page by taking into account both the importance of the web pages linked to the web page and the number of links the web page receives.,pagerank,ranking the importance of each web page,no
838,2986916.0,"pipecheck accommodates more microarchitectural features than those we model in this work, such as instruction reordering. however, it requires microarchitectures to be specified axiomatically, and hence is not directly compatible with the operational model that we use in this work.",{'pipecheck'},1.0,is-a,"pipecheck is a model that accommodates microarchitectural features, such as instruction reordering. ",pipecheck,model,no
839,2986916.0,,,,compare,"pipecheck is like operational model except that it accommodates more microarchitectural features, and requires microarchitectures to be specified axiomatically.",pipecheck,operational model,no
840,2986916.0,"with a formal model of concurrency in the underlying hardware and the programming language, it is possible to prove the correctness of compiler mappings for concurrency primitives, and this has been done for mappings of c/c\+\+11 to x86 [6] and power [5, 21] processors. our work represents the first correctness proof of compiler mappings targeting a concrete gpu architecture.",{'c / c++11'},0.0,,,,,
841,854201.0,in dimensionless form. it is perhaps worth clarifying what we mean by 'nonlinear diffusion' as the term is ambiguous.,{'nonlinear diffusion'},0.0,,,,,
842,18788439.0,"to alleviate this problem and facilitate modeling, many gui programs have been created, such as openalea [11] , celldesigner [12] , vcell [13] and e-cell [14] . however these modeling programs have some limitations.",{'celldesigner'},1.0,compare,celldesigner is like openalea in that they are both gui programs that facilitate modeling.,celldesigner,openalea,no
843,18788439.0,,,,compare,celldesigner is like vcell in that they are both gui programs that facilitate modeling.,celldesigner,vcell,no
844,18788439.0,,,,compare,celldesigner is like e-cell in that they are both gui programs that facilitate modeling.,celldesigner,e-cell,no
845,18788439.0,,,,is-a,celldesigner is a gui program that facilitates modeling.,celldesigner,gui program that facilitates modeling,no
846,18788439.0,"for example, openalea does not cater to general modeling needs and is specialized for solving plant modeling problems. celldesigner allows gui modeling of biochemical networks, but it requires an external mathematical package (copasi) for simulating networks or fitting parameters.","{'celldesigner', 'copasi'}",1.0,is-a,"celldesigner is a program that allows gui modeling of biochemical networks, but requires an external mathematical package (copasi) for simulating networks or fitting parameters.",celldesigner,program,no
847,18788439.0,,,,used-for,copasi is a mathematical package used for simulating networks or fitting parameters.,copasi,mathematical package,no
848,4640794.0,saxe et al. (2014) examined the effect of random initialization on the dynamics of learning in deep linear networks.,{'deep linear network'},0.0,,,,,
849,12158180.0,"in the graal compiler for java, we take a different approach: we use snippets of java code to express semantics in a high-level, architecture-independent way. two important restrictions make snippets feasible in practice: they are compiler specific, and they are explicitly prepared and specialized.",{'graal compiler'},0.0,,,,,
850,12158180.0,"despite the inadequacy of maxine snippets, the appeal of the snippet concept remained. we carefully analyzed the deficiencies and addressed them in a new implementation of snippets for the graal compiler.",{'graal compiler'},0.0,,,,,
851,12158180.0,"rpython can be executed by standard python interpreters. such execution is slow; therefore, a translation process is necessary to achieve high performance.",{'rpython'},1.0,is-a,rpython is a language that can be executed by standard python interpreters and requires a translation process to achieve high performance.,rpython,language,no
852,12158180.0,"system code functions are written in rpython and must be parsed by the front end before inserting them into the graph. according to rigo and pedroni [2006] , the translation process for the python interpreter prototype takes about 39 minutes, 10 minutes of which is accounted for by the lowering transformation.",{'rpython'},1.0,used-for,rpython is used to write system code functions and must be parsed by the front end before inserting them into the graph.,rpython,write system code functions,no
853,9019102.0,"the first results regarding information-theoretic security where obtained under a rather weak security criterion where the measures of security appeared as quantities regularized in blocklength. the notion of security was improved in [12] , [24] , where first results were proven using so-called strong security criteria.",{'blocklength'},0.0,,,,,
854,18673693.0,"one of the main reasons for the tentative usage of modern learning methods is the fact that most of the various software packages for more advanced analysis require expert knowledge in the area of statistics and often even expertise in programming. popular examples are graphical tools, like weka [30] and rapidminer [31] , or statistical learning environments, like r [32] .",{'weka'},0.0,,,,,
855,64197204.0,"in this study, an extreme learning machine is also used on feature extraction process and have a result in a higher accuracy up to 92.1% on average [6] . kurniawan et al (2011) is also tried to improve the performance of asr using contour analysis and neural network validation.",{'extreme learn machine'},0.0,,,,,
856,4559136.0,"this, as well as other fairness notions can be defined through a set of axioms, see [3] . for a rich literature on concepts of fairness and some interesting applications, the reader is referred to [4] , [5] , [6] , [7] , [9] , [8] and the references there in.",{'fairness notion'},0.0,,,,,
857,1122361.0,"this is largely due to the fact that most existing computer vision algorithms such as epipolar geometry [9] and sfm [26, 6] make use of the global shutter pinhole camera model which does not account for the so-called rolling shutter effect caused by camera motion. unlike a gs camera where the photo-sensor is exposed fully at the same moment, the photo-sensor of a rs camera is exposed in a scanline-byscanline fashion due to the exposure/readout modes of the low-cost cmos sensor.",{'epipolar geometry'},1.0,is-a,epipolar geometry is a computer vision algorithm that makes use of the global shutter pinhole camera model which does not account for the so-called rolling shutter effect caused by camera motion.,epipolar geometry,computer vision algorithm,no
858,1122361.0,,,,compare,epipolar geometry is like sfm in that they are both computer vision algorithms that make use of the global shutter pinhole camera model which does not account for the so-called rolling shutter effect caused by camera motion.,epipolar geometry,sfm,no
859,1122361.0,"[11] proposed a bundle adjustment algorithm for rs cameras. in [15] , a large-scale bundle adjustment with a generalized camera model is proposed and applied to 3d reconstructions from images collected with a rig of rs cameras.",{'generalized camera model'},1.0,part-of,generalized camera model is part of a large-scale bundle adjustment proposed and applied to 3d reconstructions from images collected with a rig of rs cameras.,generalized camera model,a large-scale bundle adjustment,no
860,1122361.0,[5] presented the first work to solve the relative pose estimation problem for rs cameras. they tackled the discrete two-frame relative pose estimation problem by introducing the concept of generalized essential matrix to account for camera velocities.,{'generalized essential matrix'},1.0,is-a,generalized essential matrix is a concept used to account for camera velocities in the discrete two-frame relative pose estimation problem.,generalized essential matrix,concept,no
861,17466802.0,"recent globus extension proposals contain a software component, called gara [9] , which handles resource reservation. currently in globus, resource allocation is made possible by a software component called gram [4] .",{'gara'},1.0,is-a,gara is a software component which handles resource reservation,gara,software component,no
862,17466802.0,next section introduces the concept of computational reflection. section 3 describes the strega software architecture.,{'computational reflection'},0.0,,,,,
863,52020469.0,"while the literature during the 1970-90s was focused on stability and asymptotic performance, new tools for analysis of the transient behavior have recently emerged. in particular, statistical theory for tail and concentration bounds has seen a dramatic development during the last twenty years, with numerous applications in fields like machine learning, compressed sensing, network routing and pattern recognition and is now taught in regular university curriculum.",{'compress sensing'},1.0,is-a,compressed sensing is an application of statistical theory for tail and concentration bounds.,compressed sensing,application of statistical theory for tail and concentration bounds,no
864,199064205.0,"however, this demands a place recognition technique that is scalable on an ever growing dataset. to this end, we propose a novel place recognition technique that can be efficiently retrained and compressed, such that the recognition of new queries can exploit all available data (including recent changes) without suffering from visible growth in computational cost.",{'place recognition technique'},0.0,,,,,
865,199064205.0,"recently, posenet [21] used a convolution neural network (cnn) to learn this mapping, with further improvements using lstms to address overfitting [41] , uncertainty prediction [19] and inclusion of geometric constraints [20] . mapnet [7] showed that a representation of the map can be learned as a network and then used for vl.",{'posenet'},1.0,is-a,"posenet is a method that uses lstms to address overfitting, uncertainty prediction and inclusion of geometric constraints.",posenet,method,no
866,16348051.0,discriminative features are extracted from these two face representations for the automatic facial expression recognition. based on these features we develop a novel algorithm for automatic classification of emotional expressions in the face .,{'face representation'},0.0,,,,,
867,16348051.0,"zhou and et. al proposed an unsupervised temporal segmentation and clustering algorithm, aligned cluster analysis (aca) for dynamic facial event analysis, and a multi-subject correspondence algorithm for matching expressions [17] .",{'align cluster analysis'},1.0,used-for,aligned cluster analysis is used for dynamic facial event analysis.,aligned cluster analysis,dynamic facial event analysis,no
868,14442709.0,"another application of file block classification is the detection of data hidden in locations that are not pointed to by the file system or residual data (e.g., in memory dumps or swap files and temporary files). a review of file carving techniques [9] underscores the importance of block classification in creating novel file carving solutions.",{'file block classification'},1.0,used-for,"file block classification is used for the detection of data hidden in locations that are not pointed to by the file system or residual data (e.g., in memory dumps or swap files and temporary files).",file block classification,the detection of data hidden in locations that are not pointed to by the file system or residual data,no
869,9311721.0,"on the other hand, there also exist a series of research work on stream data classification, which can be categorized into two types: single model classification and ensemble classification. the former method incrementally updates their model by only learning from the latest data such vfdt and cvfdt [12] [13] .",{'vfdt'},0.0,,,,,
870,2558839.0,"in fact, the process of program repair remains to be the least automated in system development. when talking about repairing, the cost is usually taken into account.",{'program repair'},1.0,is-a,program repair is a process that remains to be the least automated in system development.,program repair,process,no
871,2558839.0,"thus, without taking repair cost into consideration, research work in program repair is not likely to be useful in practice. this work is to develop techniques for repair suggestions of programs with a cost concept against graphical state-transition specifications.",{'program repair'},0.0,,,,,
872,17096301.0,"prior to john's study [48] , almost all analyses of bumps had been restricted to 1d networks. wilson and cowan established the existence of 1d bumps numerically [53, 54] , and amari subsequently constructed an exact bump solution for a 1d scalar neural field equation with a heaviside firing rate function [1] .",{'heaviside firing rate function'},0.0,,,,,
873,38594267.0,"they write [l] : ""if a function is to satisfy the strict avalanche criterion, then each of its output bits should change with a probability of one half whenever a single input bit e is complemented to t."" the cryptographic significance of the sac is highlighted by considering the situation where a cryptographer needs some ""complex"" mapping f of n bits onto one bit.",{'strict avalanche criterion'},0.0,,,,,
874,1556949.0,"in more recent work, cohen-steiner et al. [16] have extended persistent homology in such a way that essential homology classes also have finite persistences.",{'persistent homology'},0.0,,,,,
875,1556949.0,"the authors then use persistent homology to identify homology classes in the blowup complex which correspond to a same homology class in the given topological space. the persistent homology algorithm produces a complete set of generators for the relevant homology group, which forms a basis for the group.",{'persistent homology'},1.0,used-for,persistent homology is used to identify homology classes in the blowup complex which correspond to a same homology class in the given topological space.,persistent homology,identify homology classes in the blowup complex,no
876,1556949.0,,,,is-a,"persistent homology is an algorithm that produces a complete set of generators for the relevant homology group, which forms a basis for the group.",persistent homology,algorithm,no
877,59292849.0,"the first group of methods use the a priori approach. in this approach, the moop is transformed into a single-objective optimization by adopting a preference vector, generated by some higher-level information.",{'single - objective optimization'},0.0,,,,,
878,59292849.0,"2017; khamel, ouelaa, and bouacha 2012; tebassi et al. 2016) , where a desirability function transforms multi-response turning problems into a single-objective optimization problem.",{'single - objective optimization problem'},0.0,,,,,
879,59292849.0,"to the best of the present authors' knowledge, there are only a limited number of studies on the moo of turning operations. most of the research is focused on single-objective optimization, or where an moo is converted to a single objective by following the a priori method, as mentioned earlier.",{'single - objective optimization'},0.0,,,,,
880,59292849.0,"in one study by durn, barrientos, and consalter (2007) , the production rate and production cost of turning operations were optimized by using genetic algorithms, and a pareto-optimal front was obtained. sultana and dhar (2010) minimized cutting temperature and cutting force in turning aisi-4320 steel by using an moo algorithm based on genetic algorithms (gas), subject to keeping the surface roughness less than a constant value.",{'pareto - optimal'},0.0,,,,,
881,59292849.0,the modified distance method (mdm) is based on evolutionary computations generated the pareto-optimal front from the objective function equations. the best solution from the non-dominated set was selected by using the hierarchical optimization method.,{'pareto - optimal'},0.0,,,,,
882,59292849.0,"a non-dominated sorted genetic algorithm (nsga-ii) was employed in ganesan and mohankumar (2013) to find the optimal cutting parameters in cnc turning by optimizing three objective functions, minimum operating time, minimum production cost and minimum tool wear, expressed with mathematical equations. in a study by thepsonthi and zel (2014) , the cutting force and tool wear of a high performance micro-milling process were generated by running 2d finite element simulations (in deform-2d software).",{'nsga'},0.0,,,,,
883,59292849.0,"the experiments were adopted to find two mathematical expressions for material removal rate and surface roughness, where nsga-ii obtained the optimal solutions in terms of cutting parameters. a later study (satyanarayana, reddy, and ruthvik nitin 2017) optimized tool wear and tool temperature by conducting a three level full factorial (27 experiments).",{'nsga'},0.0,,,,,
884,59292849.0,"the pareto-optimal front was obtained from the non-dominated solutions of a five level factorial experiment (125 experiments). in addition, the results were compared with a metamodel-based moo (ego) with a total of 80 experiments (64 initial and 16 validation experiments).",{'pareto - optimal'},0.0,,,,,
885,59292849.0,"the strength pareto evolutionary algorithm spea2 was employed as the multi-objective optimizer and the pareto-optimal front was found after 17 generations. without the use of the metamodel proposed in the current work, the optimization process took about two weeks.",{'pareto - optimal'},0.0,,,,,
886,59292849.0,the best metamodelling method for each objective is selected by using two performance metrics. the moo is performed on the selected metamodels with the same algorithm (spea2) and the trade-off front is obtained.,{'spea2'},0.0,,,,,
887,59292849.0,"in section 4, the spea2 and the parameters in the algorithm are presented and the overall moop is formulated. in section 5, parameter settings for the metamodelling methods are described and the results are presented and discussed.",{'spea2'},0.0,,,,,
888,27268078.0,"taxonomic concepts are drawn from the vertebrate taxonomy ontology (vto). this knowledge of comparative biodiversity is linked to potentially relevant developmental genetic mechanisms by importing associations of genes to phenotypic effects and gene expression locations from zebrafish (zfin [2] ), mouse (mgi [3] ), xenopus (xenbase [4] ), and human (human phenotype ontology project [5] ).",{'vertebrate taxonomy ontology'},0.0,,,,,
889,601685.0,"an o(n log n) time algorithm for the mwc with fixed length overlaps problem was designed and used for mapping spliced rnas on a genome [14] , but the fixed bound on overlaps remains a limitation. to raise this limitation, we formulate the mwc with proportional length overlaps problem (mwc-plo) and exhibit the first chaining algorithms allowing for overlaps that are proportional to the fragment lengths, and whose chain weight function accounts for overlap.",{'mwc'},0.0,,,,,
890,5941579.0,"based on the network weather service, our system uses nonparametric statistical forecasts of request-response times to automatically determine message timeouts. by choosing a timeout based on predicted network performance, the methodology improves application and grid service performance as extraneous and overly-long timeouts are avoided.",{'network weather service'},0.0,,,,,
891,5941579.0,"to do so, many rely on short-term, statistical forecasts of resource performance generated by the network weather service (nws) [17, 16] -a grid performance data management and forecasting service.","{'nws', 'network weather service'}",1.0,is-a,nws is a grid performance data management and forecasting service.,nws,grid performance data management and forecasting service,no
892,5941579.0,,,,used-for,"nws is used to generate short-term, statistical forecasts of resource performance.",nws,"generate short-term, statistical forecasts of resource performance",no
893,5941579.0,"that is, they are customized software components that exploit application-specific characteristics to mitigate the negative performance effects of grid dynamism. tools such as the apples parameter sweep template [6, 5] generalize this approach to incorporate information that is common *",{'apple parameter sweep template'},1.0,is-a,apple parameter sweep template is a tool used to generalize the grid dynamism approach to incorporate information that is common.,apple parameter sweep template,tool,no
894,20569590.0,wireless ad hoc network routing protocols have been proposed for routing protocols in wsn. some of them were proactive and designed for static network like destination sequenced distance vector (dsdv),{'dsdv'},0.0,,,,,
895,20569590.0,"[3] , some were reactive and designed for mobile network like dynamic source routing (dsr) [4] , and some was hybrid protocol like ad hoc on demand distance vector (aodv)",{'demand distance vector'},0.0,,,,,
896,20569590.0,"due to the ordinary manner of leach-mobile protocol, in which sensor node membership is determined during two consecutive frames, the packet will be considered loss in twofold whenever each sensor node moves out from its cluster. although leach-mobile support mobility in wsn and outperform leach in mobility centric environment, leach-mobile has high packet loss and high power consumption.",{'leach - mobile protocol'},1.0,is-a,leach-mobile protocol is a method in which sensor node membership is determined during two consecutive frames.,leach-mobile protocol,method,no
897,40832991.0,"to apply reinforcement learning efficiently in such environments, it is necessary to construct an appropriate state space of percepts. these can be roughly divided into two groups: off-line and on-line methods.",{'reinforcement learning'},0.0,,,,,
898,3978550.0,"to this end, several schemes have been proposed over the last few years to speed up the block propagation, most notably the compact block protocol (bip 152). despite this, we show experimental evidence that nodes that have recently joined the network may need about ten days until this protocol becomes 90% effective.",{'block propagation'},0.0,,,,,
899,3978550.0,"our experiments show that falafelsync helps intermittently connected nodes to maintain better consistency with more stable nodes, thereby showing promise for improving block propagation in the broader network. in the process, we have also developed an effective logging mechanism for bitcoin nodes which we release for public use.",{'block propagation'},0.0,,,,,
900,5073976.0,"related work. in the context of ttethernet networks with multiple hops, steiner [18] proposed an approach based on satisfiability modulo theory (smt) to address the problem of schedule synthesis.",{'satisfiability modulo theory'},0.0,,,,,
901,12813291.0,"as illustrated in figure 3 , a hard particle model is a gas model in which t wo adjacent v ertices cannot be simultaneously occupied by cells. actually, the correspondence between directed animals and hard particle models is not only a motivation for studying animals.",{'gas model'},0.0,,,,,
902,12813291.0,"since i was not able to prove them \combinatorially"", i tried to extend dhar's method, and discovered that the main open problems on two-dimensional lattices were equivalent to the solution of a gas model. although i could only solve this model in some special cases | t h us proving the two conjectures |",{'gas model'},0.0,,,,,
903,12813291.0,"t h a t t h e general correspondence between directed animals and gas models is worth being presented, and could maybe lead in the future to the solution of certain other open questions.",{'gas model'},0.0,,,,,
904,196060618.0,uncertainty is a common problem faced by animals and humans alike in their day to day decision making. this uncertainty can be grouped into either expected or unexpected uncertainty based on the nature of the variability (yu and dayan) .,{'dayan'},0.0,,,,,
905,196060618.0,"experiments involving non-stationary environments often have a cue indicating change in environment. however, some tasks like the serial reversal task have a reward distribution that varies with the environmental context.",{'reward distribution'},0.0,,,,,
906,195748751.0,"to effectively remove the stains and restore the covered original contents of chinese paintings, a novel method based on poisson editing is proposed by exploiting the information inside the degradations of selected three feature bands as the auxiliary information to guide the restoration since the selected feature bands captured fewer stains and could expose the covered information. to make the poisson editing suitable for stain removal, the feature bands were also exploited to search for the optimal patch for the pixels in the stain region, and the searched patch was used to construct the color constraint on the original poisson editing to ensure the restoration of the original color of paintings.",{'poisson editing'},0.0,,,,,
907,2874048.0,"here, targeting could mean giving free (or price discounted) samples of a product and the desired outcome may be to get as many customers to buy the product as possible. in this talk we take a data mining perspective and we discuss what (and how) can be learned from the available traces of past propagations.",{'data mining perspective'},0.0,,,,,
908,18249295.0,"users can query any of 2048 fully sequenced organisms, including 1678 bacteria, 255 eukaryotes and 115 archaea. in addition, they can tailor protphylo to a particular kind of biological question by choosing among four main orthology inference methods based either on pairwise sequence comparisons (one-way best hits and best reciprocal hits) or clustering of orthologous proteins across multiple species (orthomcl and eggnog).",{'eggnog'},0.0,,,,,
909,43887.0,"recent research [1] and deployment experience [4] suggest that this level of resource use is not practical or economical; and even full link padding is still vulnerable [33] . thus, until we have a proven and convenient design for traffic shaping or low-latency mixing that improves anonymity against a realistic adversary, we leave these strategies out.",{'link padding'},0.0,,,,,
910,43887.0,"systems like babel [28] , mixmaster [36] , and mixminion [15] have tried to maximize anonymity at the cost of introducing comparatively large and variable latencies. because of this decision, these highlatency networks resist strong global adversaries, but introduce too much lag for interactive tasks like web browsing, internet chat, or ssh connections.",{'mixminion'},1.0,is-a,mixminion is a highlatency network used to maximize anonymity at the cost of introducing comparatively large and variable latencies.,mixminion,highlatency network,no
911,43887.0,,,,compare,mixminion is like babel in that they are both highlatency networks used to maximize anonymity at the cost of introducing comparatively large and variable latencies.,mixminion,babel,no
912,43887.0,,,,compare,mixminion is like mixmaster in that they are both highlatency networks used to maximize anonymity at the cost of introducing comparatively large and variable latencies.,mixminion,mixmaster,no
913,43887.0,"they also provide more convenient mail delivery than the high-latency anonymous email networks, because the remote mail server provides explicit and timely delivery confirmation. but because these designs typically involve many packets that must be delivered quickly, it is difficult for them to prevent an attacker who can eavesdrop both ends of the communication from correlating the timing and volume of traffic entering the anonymity network with traffic leaving it [45] .",{'anonymity network'},0.0,,,,,
914,43887.0,"as with a single-hop proxy, this approach aggregates users into larger anonymity sets, but again an attacker only needs to observe both ends of the cascade to bridge all the system's traffic. the java anon proxy's design calls for padding between end users and the head of the cascade [7] .",{'large anonymity set'},0.0,,,,,
915,43887.0,"systems like freedom and the original onion routing build circuits all at once, using a layered ""onion"" of publickey encrypted messages, each layer of which provides session keys and the address of the next server in the circuit. tor as described herein, tarzan, morphmix, cebolla [9] , and rennhard's anonymity network [44] build circuits in stages, extending them one hop at a time.","{'morphmix', 'tarzan'}",1.0,is-a,"morphmix is a system that builds circuits in stages, extending them one hop at a time.",morphmix,system that builds circuits in stages,no
916,43887.0,,,,compare,"morphmix is like tor in that they are both systems that build circuits in stages, extending them one hop at a time.",morphmix,tor,no
917,43887.0,,,,compare,"morphmix is like tarzan in that they are both systems that build circuits in stages, extending them one hop at a time.",morphmix,tarzan,yes
918,43887.0,,,,compare,"morphmix is like cebolla in that they are both systems that build circuits in stages, extending them one hop at a time.",morphmix,cebolla,no
919,43887.0,,,,compare,"morphmix is like rennhard's anonymity network in that they are both systems that build circuits in stages, extending them one hop at a time.",morphmix,rennhard's anonymity network,no
920,43887.0,,,,compare,"morphmix is like freedom except that it builds circuits in stages, extending them one hop at a time.",morphmix,freedom,no
921,43887.0,,,,compare,"tarzan is like freedom except that it builds circuits in stages, extending them one hop at a time.",tarzan,freedom,no
922,43887.0,"tarzan and morphmix allow unknown users to run servers, and use a limited resource (like ip addresses) to prevent an attacker from controlling too much of the network. crowds suggests requiring written, notarized requests from potential crowd members.","{'morphmix', 'tarzan'}",1.0,compare,"tarzan is like morphmix in that they both allow unknown users to run servers, and use a limited resource (like ip addresses) to prevent an attacker from controlling too much of the network.",tarzan,morphmix,yes
923,43887.0,"his design differs from ours in three ways. first, goldberg suggests that alice should manually hunt down a current location of the service via gnutella; our approach makes lookup transparent to the user, as well as faster and more robust.",{'gnutella'},1.0,used-for,gnutella is used to hunt down the current location of a service.,gnutella,hunt down the current location of a service,no
924,27046686.0,[11] and wireless nanosensor networks (wnsns) [12] constitute two clear examples of applications with stringent size constraints that would greatly benefit from ultra-short-range wireless communications.,{'wireless nanosensor network'},1.0,is-a,wireless nanosensor network is an application with stringent size constraints that would greatly benefit from ultra-short-range wireless communications.,wireless nanosensor network,application with stringent size constraints,no
925,202094040.0,"there are various devices of this type like raspberry pi, beaglebone, phidget, intel edison and arduino. the latter one is an inexpensive singleboard micro-controller (arduino online) and is considered as the flagship open source hardware.",{'phidget'},0.0,,,,,
926,131763462.0,"there are many empirical studies exploring whether coverage is effective in measuring the fault-revealing ability of tests and whether some criteria are better than others. the basic setup of such experiments is to base on a set of test suites, collect both the coverage and fault-revealing data (typically through mutation testing [27] , [28] , [29] , [30] , [31] , [32] ), and then perform a correlation analysis of the two.",{'mutation testing'},1.0,used-for,mutation testing is used to collect coverage and fault-revealing data.,mutation testing,collect coverage and fault-revealing data,no
927,44752838.0,"detection of newsworthy events is an area of research which can be readily applied to the early stages of the journalistic lifecycle. in the past, event detection from unstructured text has been used for applications from first story detection (fsd)",{'story detection'},0.0,,,,,
928,44752838.0,"a specialised form of message-pivot event detection is first story detection (fsd). fsd in a stream-based setting stores a stream of news stories, each represented as a vector of terms, and compares a new story, i.e., one not yet stored, to all stored stories.",{'story detection'},0.0,,,,,
929,44752838.0,the latter creates a keyword graph of documents or messages and uses community detection methods analogous to those used for social network analysis to discover and describe events [25] . chen et al.,{'community detection method'},0.0,,,,,
930,44752838.0,twical is presented in [20] as the first open domain event extraction and categorisation tool for twitter. the system is based on an annotated corpus of events in twitter which are used as training data for sequence level models.,{'open domain event extraction'},0.0,,,,,
931,52194354.0,"it costs a large amount of time and limits a successful application of nn for huge sample data. in the last decade, hinton, le cun and other researchers proposed some new neural networks [28] - [31] , such as dbn (deep belief nets)",{'deep belief net'},0.0,,,,,
932,52194354.0,"[30] and faster-rcnn [31] . and they made a breakthrough in pattern recognition, phonetic classification and object detection.",{'object detection'},0.0,,,,,
933,52194354.0,"it has less computation time than bgd and has the ability to choose a better descent direction than sgd. moreover, some regulation measures, such as l 1 /l 2 regulation [38] , [39] , were proposed to improve generalization ability of nn.",{'sgd'},0.0,,,,,
934,52194354.0,"in section ii, the preliminary study of mgd nn mainly includes the structure of mgd nn, the cost function choosing of bgd, sgd and mgd nns, regularization strategy and back forward. in section iii, a benchmark test simulation platform of a turbofan engine is clarified.",{'sgd'},0.0,,,,,
935,34645794.0,"in this work, we propose a new method for the fusion of multiple classifiers' outputs or decision labels based on a supervised learning approach. our method treats the classifier outputs simply as the input to a second-level classifier, and in particular exploit random forest (rf) algorithm trained on large number of tuples of rankedoutputs obtained from individual classifiers to make prediction on final class decision.",{'random forest'},0.0,,,,,
936,69500908.0,"the tool has a client-server architecture. the client is based on a 3d browser, e.g., for xml3d, while the server is built of several services enabling 3d content creation.",{'xml3d'},0.0,,,,,
937,202661191.0,"in computational logic, [3] introduces dlek (dynamic logic of explicit beliefs and knowledge) as a logical formalization of soar (state operator and result) architecture [7] , which is one of the most popular cognitive architectures.",{'soar'},1.0,is-a,soar is a popular cognitive architecture in computational logic.,soar,popular cognitive architecture,no
938,3493020.0,"it has been shown that the method can be applied successfully to complex fluids when scale separation occurs and we can assume that the statistical influence of the microscale can be controlled on the macroscale. our dg-md hybrid method combines the following advantages (i) for macroscopic flow equations the dg method is applied which allows more flexible discretization including per-cell momentum conservation, (ii) the reduced order techniques are included in order to control the number of needed but computationally expensive md simulations.",{'dg method'},0.0,,,,,
939,18461193.0,"for example, although gps receivers are available for mote-scale devices, they are still relatively expensive [6] . the cricket location-support system requires customized hardware with ultrasonic sensors [7] .",{'cricket location - support system'},1.0,is-a,cricket location-support system is a system which requires customized hardware with ultrasonic sensors.,cricket location-support system,system,no
940,18461193.0,"in section ii, we review other mwsn research that has recently appeared in the literature. in section iii, we describe the radio interferometric positioning system and radio interferometric angle-of-arrival estimation, key components of our proposed navigation system.",{'radio interferometric positioning system'},0.0,,,,,
941,14868284.0,"prior to this study, however, rates and patterns of region-wide ground deformation in wuhan were little known. here we employ multi-temporal sar interferometry to detect and characterize spatiotemporal variations of ground deformation in major metropolitan areas in wuhan.",{'ground deformation'},0.0,,,,,
942,14868284.0,"as one of the most populous cities in china, wuhan city has experienced a rapid urban expansion over the past decades. consequently, various types of geohazards relevant to ground deformation have been frequently occurring in wuhan metropolitan areas, due to anthropogenic activities (e.g., groundwater pumping, tunnel excavation) and/or natural geological processes (e.g., alluvial soil consolidation, karst collapse and surface water loading)",{'ground deformation'},0.0,,,,,
943,14868284.0,"to overcome the limitations of conventional insar methods, in recent years some advanced insar approaches have been developed based on time-series interferometric analysis of multi-temporal sar acquisitions over the same areas, herein referred to as multi-temporal insar (mt-insar) techniques. the mt-insar techniques, mainly involving persistent scatterer insar (psi) methods [23] [24] [25] and small baseline subset (sbas) methods [26] [27] [28] , identify and exploit a subset of image pixels which maintain a high coherence level over the study period, allowing the average rates and temporal evolutions of ground deformation to be estimated with millimeter-level accuracy.",{'ground deformation'},0.0,,,,,
944,14868284.0,"the stamps (stanford method for persistent scatterer) approach [24, 33] is applied to 12 terrasar-x images acquired from october 2009 to august 2010 to retrieve and characterize spatiotemporal variations of ground deformation in major metropolitan areas in wuhan. moreover, a comparison between insar-based results and in situ data is carried out to validate the insar observations.",{'ground deformation'},0.0,,,,,
945,52990764.0,"in this study, in order to address this issue, lloyd's algorithm, which functions as a bridge between random and structural aps deployments, is investigated for analyzing coverage probability in a network. the link distance distribution is modeled as a mixture of weibull distributions and its parameters are obtained by using the expectation-maximization (em) algorithm for each iteration of lloyd's algorithm.",{'coverage probability'},0.0,,,,,
946,52990764.0,"field measurements show that the coverage probability lies in practice between the traditional hexagonal model and the independent ppp approach. this is mainly due to the fact that network operators have still control on bs/ap deployment in a deterministic way [3, 4] , which creates intentional repulsion between bss/aps.",{'coverage probability'},0.0,,,,,
947,52990764.0,"field measurements show that the coverage probability lies in practice between the traditional hexagonal model and the independent ppp approach. this is mainly due to the fact that network operators have still control on bs/ap deployment in a deterministic way [3, 4] , which creates intentional repulsion between bss/aps.",{'coverage probability'},0.0,,,,,
948,12566533.0,"in addition, since usually for most sites, multiple aerial images are missing, our goal was to provide a solution even with the minimum available data, like a single panchromatic image and an elevation map, contrary to approaches that were designed to process multiple aerial images or multispectral information and cadastral maps (like in [17] , [24] , and [25] ), which much eases the scene's classification. moreover, contrary to [26] , the here proposed variational framework does not require dense imagematching processes and a priori given 3-d line segments or a rough segmentation.",{'scene classification'},0.0,,,,,
949,38651328.0,"in addition to the aforementioned, an shm is capable of carrying several features such as mobile phone sensing (mps) that extends the system to the capabilities of smartphones (e.g., gps, accelerometers, cameras etc). wsn consist an effective tool with shm applications that requires extensive research prior deployment.",{'mobile phone sensing'},1.0,is-a,"mobile phone sensing is a feature carried by shm that extends the system to the capabilities of smartphones (e.g., gps, accelerometers, cameras etc). ",mobile phone sensing,feature,no
950,3401098.0,two algorithms -stochastic dynamic programming (sdp) algorithm and greedy algorithm (benchmark algorithm) -are applied to derive the pricing and electricity procurement policy. a pareto front of the multiobjective optimization is derived.,{'multiobjective optimization'},0.0,,,,,
951,820887.0,"in particular, researchers have begun to use the resting-state functional magnetic resonance imaging (rsfmri) to characterize functional brain network at a voxel-wise spatial resolution (7) . in the voxel-wise network, each voxel corresponds to a node, and the edge between two nodes is defined by functional connectivity, which is the temporal correlation of spontaneous fluctuations of blood oxygenation level-dependent (bold) signals between any two nodes (8) .",{'functional brain network'},0.0,,,,,
952,820887.0,"in addition, we also evaluate the test-retest reliability and other factors that may influence degree metrics, including global signal regression (gsr), head motions, network types (unweighted and weighted), and connectivity thresholds, as well as testing the sensitivity in group-statistic comparisons. the comprehensive assessment will prove the reliability of our method as a new tool for the degree-based analysis.",{'global signal regression'},0.0,,,,,
953,30575033.0,"in this case, the stride is the total number of threads, obtained via get_global_size. a thread calls process_node to process a node given the current level, with nodes to be processed during the next frontier being pushed to out_nodes.",{'stride'},0.0,,,,,
954,51943713.0,"the effectiveness of this pricing procedure can be attributed to the adaptation of techniques such as bidirectional labeling, the ng-neighbourhood, and heuristic pricing using dynamically reduced networks and relaxed dominance. the cutting component of the branch-and-price-and-cut adds violated subset-row inequalities to strengthen the linear relaxation.",{'subset - row inequality'},0.0,,,,,
955,208579400.0,"this frames the exploration-exploitation dilemma, typically studied using the multi-armed bandit problems [5] [6] [7] [8] , which imagine a gambler in front of a row of slot machines, learning the reward distributions of each option independently. solutions to the problem propose different policies for how to learn about which arms are better to play (exploration), while also playing known high-value arms to maximize reward (exploitation).","{'multi - armed bandit problem', 'reward distribution'}",1.0,used-for,multi-armed bandit problem is used to study the exploration-exploitation dilemma.,multi-armed bandit problem,study the exploration-exploitation dilemma,no
956,,,,,is-a,"multi-armed bandit problem is a problem which imagines a gambler in front of a row of slot machines, learning the reward distributions of each option independently.",multi-armed bandit problem,problem,no
957,208579400.0,"this highlights an intriguing gap between human and machine learning, where traditional approaches to reinforcement learning typically learn about the distribution of rewards for each state independently 4 . such an approach falls short in more realistic scenarios where the size of the problem space is far larger than the search horizon, and it becomes infeasible to observe all possible options 11, 12 .",{'reinforcement learning'},0.0,,,,,
958,14661734.0,"abstract-consider a two-way communication scenario where two single-antenna nodes, operating under full-duplex mode, exchange information to one another through the aid of a (full-duplex) multi-antenna relay, and there is another singleantenna node who intends to eavesdrop. the relay employs artificial noise (an) to interfere the eavesdropper's channel, and amplify-forward (af) alamouti-based rank-two beamforming to establish the two-way communication links of the legitimate nodes.",{'eavesdropper channel'},0.0,,,,,
959,14661734.0,"our problem is to optimize the rank-two beamformer and an covariance for sum secrecy rate maximization (ssrm). this ssrm problem is nonconvex, and we develop an efficient solution approach using semidefinite relaxation (sdr) and minorization-maximization (mm).",{'semidefinite relaxation'},1.0,is-a,semidefinite relaxation is used to develop an efficient solution approach to optimize the rank-two beamformer and a covariance for sum secrecy rate maximization.,semidefinite relaxation,develop an efficient solution approach to optimize the rank-two beamformer,no
960,,,,,compare,semidefinite relaxation is like minorization-maximization in that they are both used to develop an efficient solution approach to optimize the rank-two beamformer and a covariance for sum secrecy rate maximization.,semidefinite relaxation,minorization-maximization,no
961,14661734.0,"apart from phy security, another emerging application of full duplexity is swipt. swipt is a means of using rf signals to achieve dual transmission of information and energy; readers are referred to the recent magazine paper [15] for a more complete treatment of this kind of technique.",{'swipt'},1.0,is-a,swipt is a means of using rf signals to achieve dual transmission of information and energy.,swipt,means of using rf signals to achieve dual transmission of information and energy,no
962,14661734.0,,,,compare,swipt is like phy security in that they are both applications of full duplexity.,swipt,phy security,no
963,458987.0,"representative examples of some uav-sar instruments are nanosar (imsar co., springville, ut, usa), microasar [6] (artemis, inc., hauppauge, ny, usa) and minisar (sandia nat. labs, albuquerque, nm, usa).",{'microasar'},1.0,is-a,microasar is a uav-sar instrument.,microasar,uav-sar instrument,no
964,458987.0,,,,compare,microasar is like nanosar in that they are both uav-sar instruments.,microasar,nanosar,no
965,458987.0,,,,compare,microasar is like minisar in that they are both uav-sar instruments.,microasar,minisar,no
966,1192563.0,"results: we introduce a class of string kernels, called mismatch kernels, for use with support vector machines (svms) in a discriminative approach to the problem of protein classification and remote homology detection. these kernels measure sequence similarity based on shared occurrences of fixed-length patterns in the data, allowing for mutations between patterns.",{'string kernel'},0.0,,,,,
967,203951859.0,"the rapid emergence of standardized robust noninvasive imaging methods and infrastructure for big data analysis over the years has promoted the advent of a variety of large-scale neuroimaging studies. different initiatives aim to understand the variability, development and anatomical layout of the human brain in e.g. neurodegeneration (adni [1] , oasis [2, 3] ), psychiatric diseases (la5c [4] ), neurodevelopmental disorders (abide [5] , miriad [6] ) or within populations (rotterdam study [7] , human connectome project [8] , ukbiobank [9] , rhineland study [10] ).",{'human connectome project'},0.0,,,,,
968,214605748.0,"the core task of metric learning consists in learning a metric from high-dimensional data, such that the distance between two points, as measured by this metric, reflects their semantic similarity. such a task can be of crucial importance in several applications including image retrieval, zero-shot learning or person reidentification, among other tasks.","{'zero - shot learning', 'person reidentification'}",1.0,compare,zero-shot learning is like person reidentification in that they are both applications of the core task of metric learning.,zero-shot learning,person reidentification,yes
969,214605748.0,,,,compare,zero-shot learning is like image retrieval in that they are both applications of the core task of metric learning.,zero-shot learning,image retrieval,no
970,214605748.0,"popular pairwise losses include triplet loss and its derivatives [3, 7, 23, 24, 43] , contrastive loss and its derivatives [5, 33] , neighborhood component analysis and its derivatives [4, 15, 36] , among others. however, such modifications are often heuristic-based, and come at the price of an increased complexity and additional hyper-parameters, impeding the potential applicability of these methods to real-world problems.",{'triplet loss'},1.0,type-of,triplet loss is a type of pairwise loss.,triplet loss,pairwise loss,no
971,214605748.0,,,,compare,triplet loss is like contrastive loss in that they are both types of pairwise loss.,triplet loss,contrastive loss,no
972,214605748.0,,,,compare,triplet loss is like neighborhood component analysis in that they are both types of pairwise loss.,triplet loss,neighborhood component analysis,no
973,5732535.0,"dialogue strategies are typically inferred from data using reinforcement learning (rl), which requires on the order of thousands of dialogues to achieve good performance. therefore, it is no longer feasible to rely on data collected with real users.",{'reinforcement learning'},0.0,,,,,
974,10164018.0,"(2017) proposed a sentence salience estimation framework known as vaesum based on a neural generative model called variational auto-encoders (vaes) (kingma and welling, 2014; rezende et al., 2014) .",{'variational auto - encoder'},1.0,is-a,variational auto-encoder is a neural generative model for which a sentence salience estimation framework known as vaesum is based on. ,variational auto-encoder,neural generative model,no
975,10164018.0,"existing datasets from duc 3 and tac 4 are not appropriate. therefore, we introduce a new dataset for ra-mds.",{'duc'},0.0,,,,,
976,11100134.0,"some authors parameterize the manifold of closed-loop configurations at each possible contact state [3, 6, 8] , while others enforce loop closure implicitly by adding nonlinear equality constraints at collocation points along the trajectory [11] . parameterization is manageable for a small number of contact states (e.g., left foot, right foot, and two foot support) but is challenging and tedious when hands, knees, and elbows may be involved in contact.",{'loop closure'},0.0,,,,,
977,20950328.0,"in [16] , authors propose a power saving mobicast routing protocol for uwsns to mitigate the energy hole problem, which is caused by the ocean current and non-uniform deployment of sensor nodes. to overcome the energy hole problem 3-d zone of relevance (3-d zor t ), 3-d zone of forwarding (3-d zof t+1 ) and an apple peel technique is introduced.",{'mobicast routing protocol'},1.0,used-for,"mobicast routing protocol is used for uwsns to mitigate the energy hole problem, which is caused by the ocean current and non-uniform deployment of sensor nodes.",mobicast routing protocol,uwsns,no
978,20950328.0,a geographic and opportunistic routing protocol (gedar) based on depth-adjustment control strategy for recovery of void nodes is proposed by the authors in [17] . gedar uses greedy forwarding strategy for finding the neighbors and adjust the depth of void nodes either by buoyancybased or winch-based.,{'gedar'},1.0,is-a,gedar is a geographic and opportunistic routing protocol based on depth-adjustment control strategy for recovery of void nodes.,gedar,geographic and opportunistic routing protocol,no
979,20950328.0,"in order to alleviate the energy hole problem, a mobile sinkbased adaptive immune energy-efficient clustering protocol (msieep) is proposed in [19] . the adaptive immune algorithm (aia) based on energy dissipated is used to find the favorable number of cluster heads (chs); moreover, aia is also used to supervise the mobile sink about their sojourn location.",{'adaptive immune algorithm'},1.0,based-on,adaptive immune algorithm is based on energy dissipated.,adaptive immune algorithm,energy dissipated,no
980,20950328.0,,,,used-for,adaptive immune algorithm is used to find the favorable number of cluster heads and supervise the mobile sink about their sojourn location.,adaptive immune algorithm,find the favorable number of cluster heads,no
981,20950328.0,"however, due to erroneous location information the algorithm results in low packet delivery ratio. a weighted rendezvous planning (wrp) algorithm based on rendezvous points (rps) is presented in [21] to reduce the traveling path and energy hole problem.",{'weighted rendezvous planning'},1.0,is-a,weighted rendezvous planning is an algorithm based on rendezvous points.,weighted rendezvous planning,algorithm based on rendezvous points,no
982,20950328.0,,,,used-for,weighted rendezvous planning is used to reduce the traveling path and energy hole problem.,weighted rendezvous planning,educe the traveling path and energy hole problem,no
983,15878323.0,"the developers of the igraph-lite system (ferres et al., 2007) released a corpus of descriptions for over 500 graphs collected from statistics canada, but these descriptions were generated automatically by their system and not written by human authors. additionally, the descriptions contained in their corpus focus on the quantitative data presented in the graphics rather than the high-level message, and tend to vary only slightly between graphs.",{'igraph - lite system'},0.0,,,,,
984,17478335.0,the classes delay-fpt and total-fpt recently have been introduced into parameterized complexity in order to capture the notion of efficiently solvable parameterized enumeration problems. in this paper we focus on ordered enumeration and will show how to obtain delay-fpt and total-fpt enumeration algorithms for several important problems.,{'parameterized complexity'},1.0,used-for,parameterized complexity is used to capture the notion of efficiently solvable parameterized enumeration problems.,parameterized complexity,capture the notion of efficiently solvable parameterized enumeration problems,no
985,51971239.0,"the traditional distributed detection framework comprises of a group of spatially distributed nodes which acquire the observations regarding the phenomenon of interest and send them to the fusion center (fc) where a global decision is made. however, in many scenarios a centralized fc may not be available or in large networks, the fc can become an information bottleneck that may cause degradation of system performance, and may even lead to system failure.",{'information bottleneck'},0.0,,,,,
986,59553834.0,"in recent years, its related researches have been advanced due to the introduction of nested arrays and co-prime arrays. however, these nlas require one or even many adjacent antennas whose spacing is the half wavelength of the incident source.","{'nested array', 'co - prime array'}",0.0,,,,,
987,59553834.0,"in this way, the aperture of nla array is larger than ula, and the angular measurement accuracy will be improved under the same number of arrays. as a typical nla, the minimum redundancy array (mra) can effectively extend the array aperture [11] , [12] .",{'minimum redundancy array'},1.0,used-for,minimum redundancy array is used to extend the array aperture.,minimum redundancy array,extend the array aperture,no
988,59553834.0,"in addition to mra, nested arrays [13] - [15] and co-prime arrays",{'nest array'},0.0,,,,,
989,59553834.0,"these algorithms are to build a smv model, and then solve the doa estimation problem by sparse reconstruction algorithms such as norm optimization [21] , [22] , orthogonal matching pursuit (omp) [23] and sparse bayesian learning (sbl) methods [24] .","{'orthogonal matching pursuit', 'omp'}",1.0,is-a,omp is a sparse reconstruction algorithm used to solve the doa estimation problem.,omp,sparse reconstruction algorithm,no
990,59553834.0,,,,compare,omp is like sparse bayesian learning in that they are both sparse reconstruction algorithms used to solve the doa estimation problem.,omp,sparse bayesian learning,no
991,59553834.0,"compared with the mra, nested array and co-prime array, this array has larger antenna spacing, so it can further expand the array aperture under the same number of antennas to improve the accuracy of doa estimation. meanwhile, because the spacing of array elements is much larger than half wavelength, it is suitable for high frequency incident sources and reduces the influence of mutual coupling on doa estimation performance.",{'co - prime array'},0.0,,,,,
992,17827202.0,"in coco, the philosophy is to provide meaningful and quantitative performance measures. the test functions are comprehensible, modeling well-identified di culties encountered in real-world problems such as ill-conditionning, multi-modality, non-separability, skewness and the lack of a structure that can be exploited.",{'coco'},1.0,is-a,coco is a method in which the philosophy is to provide meaningful and quantitative performance measures.,coco,method,no
993,17827202.0,we choose possible default values for the parameters in section 4 and give some implementation details and complexity measures in section 5 where we also illustrate how the transformation can be applied in coco. we sum up in section 6.,{'coco'},0.0,,,,,
994,4948107.0,"researchers have proposed numerous community detection algorithms, which are mainly divided into two categories according to whether they allow overlapping, i.e., disjoint-community detection and overlapping-community detection. for disjoint-community detection, modularity optimization, 5, 6 spectralclustering, 7, 8 hierarchical-clustering, 9 and label-propagation methods are proposed.",{'modularity optimization'},0.0,,,,,
995,7809949.0,"composition, unlike programmable networks, provides non trivial specialization, yet, unlike active networks, can be very efficient and secure. a work that is very similar in spirit to the proposed architecture is that of virtual overlay networks (von) [5] .",{'programmable network'},1.0,compare,programmable networks is like composition except that it does not provide non trivial specialization.,programmable networks,composition,no
996,212633704.0,"leveraging the power of deep learning, many methods have been proposed for multichannel speech separation (mcss), including time-frequency (t-f) masking [2] [3] [4] [5] , integration of t-f masking and beamforming [6, 7] , and end-to-end approaches [8] . t-f masking based methods formulate speech separation as a supervised learning task in frequency domain.",{'speech separation'},1.0,is-a,speech separation is a supervised learning task in frequency domain in t-f masking based methods.,speech separation,supervised learning task,no
997,212633704.0,"a single-channel time-domain state-of-the-art approach, referred as sc-conv-tasnet [9] , replaces the short time fourier transform (stft)inverse stft with an encoder-decoder structure. under the supervision from clean waveforms of speakers, sc-conv-tasnet's encoder learns to construct an audio representation that optimized for speech separation.",{'speech separation'},0.0,,,,,
998,33444937.0,"the search of all available information of research interests costs researchers a lot of time and efforts. although, several database collections are currently available, such as the pathguide (bader, 2006) and nar database collection (fernndez-surez, 2013) .",{'pathguide'},1.0,is-a,pathguide is a database collection for the search of all available information of research interests.,pathguide,database collection,no
999,33444937.0,,,,compare,pathguide is like nar in that they are both database collections for the search of all available information of research interests.,pathguide,nar,no
